# Linear Model Extensions {#lme}

  This chapter covers several techniques for expanding the linear regression framework covered in Chapter \@ref(lm) to test hypotheses with more nuance and complexity.

## Model Comparisons

  Assuming it is warranted by the research objective, it is sometimes helpful to subset data and compare coefficients between models to determine how the strength of associations between predictors and the response compares between cohorts. This is a common approach in pay equity studies, as it clearly highlights differences in how a particular factor such as job level, job profile, or geography impacts compensation for male vs. female employees or across ethnic cohorts.
  
  To illustrate, let's fit a multiple linear regression model to understand drivers of YTD sales for salespeople with overtime relative to those without overtime.

```{r, message = FALSE, warning = FALSE}

# Load library
library(dplyr)

# Load employee data
employees <- read.csv("https://raw.githubusercontent.com/crstarbuck/peopleanalytics_book/master/data/employees.csv")

# Subset employees data frame; leads are only applicable for those in sales positions
data <- subset(employees, job_title %in% c('Sales Executive', 'Sales Representative'))

# Partition data into overtime and non-overtime groups
data_ot <- subset(data, overtime == 'Yes')
data_nonot <- subset(data, overtime == 'No')

# Regress transformed YTD sales on a combination of predictors for overtime and non-overtime groups
mlm.fit.ot <- lm(sqrt(ytd_sales) ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_ot)
mlm.fit.nonot <- lm(sqrt(ytd_sales) ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_nonot)

```

```{r mlm-ot, out.width = "100%", echo = FALSE, fig.cap = 'Regression of square root transformed YTD sales onto multiple predictors for salespeople with overtime.', fig.align = 'center'}

# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.ot)

```

```{r mlm-nonot, out.width = "100%", echo = FALSE, fig.cap = 'Regression of square root transformed YTD sales onto multiple predictors for salespeople without overtime.', fig.align = 'center'}

# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.nonot)

```

  Since we are comparing two models, we need not scale the variables since comparing a specific predictor's relationship with the response in the overtime model can be juxtaposed against the same predictor in the non-overtime model using the original units of measurement.
  
  Based on the output shown in figures in Figure \@ref(fig:mlm-ot) and in Figure \@ref(fig:mlm-nonot), the model for salespeople who worked overtime explains more variance in square root transformed `ytd_sales` ($R^2$ = .73) relative to the model for salespeople without overtime ($R^2$ = .69).
  
  We can see that `engagement` has a larger effect on the transformed response among salespeople who worked overtime ($\beta$ = 13.17, $t$(113) = 2.88, $p$ < .01) relative to those who worked no overtime ($\beta$ = 9.85, $t$(286) = 3.99, $p$ < .001). In addition, `job_lvl` has a stronger association with the response in the overtime group ($\beta$ = 35.98, $t$(113) = 7.57, $p$ < .01) relative to the non-overtime group ($\beta$ = 33.14, $t$(286) = 11.04, $p$ < .001). Given that the intercept (average square root of `ytd_sales` when the values of all predictors are set to 0) is higher for the non-overtime group ($\beta$ = 132.34, $t$(286) = 15.27, $p$ < .001) than for the overtime group ($\beta$ = 121.82, $t$(113) = 8.25, $p$ < .001), differences in the coefficients on `job_lvl` may indicate that one's job level is a proxy for skill and capacity to sell more in fewer hours.
  
## Hierarchical Regression
  
  A multiple model approach can also be useful for understanding the incremental value a given variable -- or set of variables -- provides above and beyond a set of control variables. **Hierarchical regression** is a method by which variables are added to the model in steps and changes in model statistics are evaluated after each step. Let's use hierarchical regression to test the hypothesis below.
  
  **H1:** Among salespeople who work overtime, engagement has a significant positive relationship with YTD sales after controlling for job level, stock option level, and organization tenure.
  
```{r hier-ctrl, out.width = "100%", echo = FALSE, fig.cap = 'Regression of square root transformed YTD sales onto control variables.', fig.align = 'center'}

# Regress transformed YTD sales on a combination of predictors for overtime and non-overtime groups
mlm.fit.ot <- lm(sqrt(ytd_sales) ~ job_lvl + stock_opt_lvl + org_tenure, data_ot)

# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.ot)

```

```{r hier-main, out.width = "100%", echo = FALSE, fig.cap = 'Regression of square root transformed YTD sales onto control and main variables.', fig.align = 'center'}

# Regress transformed YTD sales on a combination of predictors for overtime and non-overtime groups
mlm.fit.ot <- lm(sqrt(ytd_sales) ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_ot)

# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.ot)

```

  Comparing Figure \@ref(fig:hier-ctrl) to Figure \@ref(fig:hier-main), we can determine that the addition of `engagement` to the control set explains an additional 2% of the variance in YTD sales ($\Delta R^2 = .69 - .67 = .02$). 
  
  In addition, Figure \@ref(fig:hier-ctrl) shows that without `engagement` in the model, `stock_opt_lvl` is not significant. This is a good reminder that regression does not examine bivariate relationships of each predictor with the response *independent of other variables*; rather, the relationships among all variables in the model impact which predictors emerge as having a statistical association with the response.
  
## Multilevel Models

  The models covered thus far have focused only on observation-level effects. That is, there has been an inherent assumption that predictor variables have *fixed* effects on the outcome and these effects do not vary based on group(s) to which the observations belong. These models are sometimes referred to as **fixed effects** models.
  
  It is often the case, however, that the strength and nature of predictors' effects on an outcome vary across categorical dimensions. For example, estimating the number of requisitions that can be filled by a Talent Acquisition team over a certain period may require inputs such as the number of recruiters and position backfill expectations based on attrition assumptions. However, the model should probably account for how these factors impact recruiter productivity at the intersections of group-level factors such as geography, job family, and job level as well. Estimates for recruiters focused on filling executive-level positions in geographies with a limited talent pool or fiercely competitive labor market will look quite different relative to recruiters focused on entry-level, low-skilled positions that are location agnostic. Failure to incorporate these group-level effects may result in inaccurate estimates or incorrectly concluding that variables are not significant in explaining why recruiters vary in the number of requisitions they can fill.
  
  You may wonder how this concept is different from simply including dummy-coded variables in the model to reflect the groups to which individual observations belong. The difference is that the average value of $Y$ when all predictors are set to 0 -- namely the $Y$-intercept $\beta_0$ -- does not vary by group with dummy-coded categorical variables. In a multilevel model, the intercept is *random* rather than *fixed* for each group. Group-level effects can also be modeled for select -- or all -- $X$ variables in addition to varying $\beta_0$ for each group.
  
  Consider a linear model constructed to test hypothesized relationships of every $X$ variable with an outcome $Y$. This is the equivalent of building $G$ independent models, where $G$ is the number of groups, using data subsetted for the respective group:
  
  $$ Y_G = \beta_{G0} + \beta_{G1} X_1 + \beta_{G2} X_2 + {...} + \beta_{Gp} X_p + \epsilon $$
  
  In this case, it is easy to consider wrapping the `lm()` function within a `for` loop that iterates through each $G$ group, filtering to each of the respective group's data in turn. However, if we hypothesize that the effects of only *certain* variables depend on the $G$ group, we need to estimate both group-level *and* observation-level effects within the same model. A multilevel model featuring this mixture of fixed and random effects is known as a **mixed effects** model. This is also known as **Hierarchical Linear Modeling (HLM)**, which is materially different from Hierarchical Linear Regression (HLR) covered in the prior section, which compared nested regression models. 
  
  A model in which group-level effects are hypothesized for $\beta_0$ and $X_1$ and observation-level effects are hypothesized for all other predictors is expressed as:
  
  $$ Y_G = \beta_{G0} + \beta_{G1} X_1 + \beta_2 X_2 + {...} + \beta_p X_p + \epsilon $$

  To fit a linear mixed effects model in R, we can leverage the `lmer()` function from the `lmerTest` package. Let's demonstrate how to fit a model to understand the random effects of `stock_opt_lvl` and fixed effects of `engagement`, `job_lvl`, and `org_tenure` on `sqrt(ytd_sales)`: 

```{r, message = FALSE, warning = FALSE}

# Load library
library(lmerTest)

# Fit linear mixed model
lme.fit <- lmerTest::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)

# Summarize model results
summary(lme.fit)

```  
  
  The results of `lmer()` contain sections for both fixed and random effects. Consistent with the interpretation of general linear model output, we can see that the fixed effects of each predictor are statistically significant. The key difference here is that the variance shown for the intercept of the random effects model is large. This indicates that there are meaningful differences in the relationships between predictors and `sqrt(ytd_sales)` across the levels of `stock_opt_lvl` that would be missed without a mixed model that accounts for these group-level effects.
  
  For a more comprehensive treatment on multilevel models, see Gelman and Hill (2006).
  
## Polynomial Regression

  Linear regression is a powerful approach to understanding the relative strength of predictors' associations with a response variable. While linear models have advantages in interpretation, inference, and implementation simplicity, the linearity assumption often limits predictive power since this assumption is often a poor approximation of actual relationships in the data. In this section, we will discuss how to extend the linear regression framework and relax linear model assumptions to handle non-linear relationships.
  
  In a people analytics context, many data sets are cross-sectional and time-invariant, meaning they represent data collected at a single point in time. However, data collected across multiple points in time (time series data) are needed for forecasting future values of a dependent variable (e.g., workforce planning model that estimates hires by month).
  
  There is often a seasonality element inherent in the relationship between time and the outcome that is being estimated, which requires accounting for time-variant features (e.g., monthly attrition rate assumptions). **Seasonality** is the variation that occurs at regular intervals within a year. For example, companies with an annual bonus often experience a seasonal spike in voluntary attrition following bonus payouts (beginning in March for many organizations). Accounting for seasonality in models helps reduce error, but it requires estimating a more complex set of model coefficients relative to a more naive linear projection.
  
  The simple linear regression equation, $Y = \beta_0 + \beta_1 X + \epsilon$, can be easily extended to include higher order polynomial terms and achieve a more flexible fit. This is known as **polynomial regression**.
  
  * Quadratic (2nd Order Polynomial) Regression Equation: $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \epsilon$
  * Cubic (3nd Order Polynomial) Regression Equation: $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \epsilon$
  
  Figure \@ref(fig:poly-fun) illustrates how higher-order polynomial functions can fit more curvilinear trends relative to a simple linear projection.
  
```{r poly-fun, out.width = "100%", echo = FALSE, fig.cap = 'Left: Linear turnover trend for $y = .75x + 3.5$. Middle: Quadratic turnover trend for $y = 7.3x - .53x^2 - 6.97$. Right: Cubic turnover trend for $y = -12.48x + 2.47x^2 - .13x^3 + 31.01$.', fig.align = 'center', message = FALSE, warning = FALSE}

# Load library
library(ggplot2)

# Initialize empty data frame
poly_data = NULL
  
# Generate turnover relationships having quadratic and cubic relationships with months
for (i in 1:12){

  poly_data <- rbind(poly_data, cbind.data.frame(
                     month = i, 
                     attrition_lin = .75*i + 3.5,
                     attrition_quad = 7.3*i - .53*i^2 - 6.97,
                     attrition_cube = -12.48*i + 2.47*i^2 - .13*i^3 + 31.01))
}

# Visualize linear trend
p_lin <- ggplot2::ggplot(poly_data, aes(x = month, y = attrition_lin * .01)) + 
         ggplot2::labs(title = 'Linear', x = 'Month', y = 'Turnover Rate') + 
         ggplot2::geom_line() +
         ggplot2::scale_x_continuous(breaks = 1:12) +
         ggplot2::scale_y_continuous(labels = scales::percent) +
         ggplot2::theme_bw() +
         ggplot2::theme(plot.title = element_text(hjust = 0.5))

# Visualize quadratic trend
p_quad <- ggplot2::ggplot(poly_data, aes(x = month, y = attrition_quad * .01)) + 
          ggplot2::labs(title = 'Quadratic', x = 'Month', y = 'Turnover Rate') + 
          ggplot2::geom_line() +
          ggplot2::scale_x_continuous(breaks = 1:12) +
          ggplot2::scale_y_continuous(labels = scales::percent) +
          ggplot2::theme_bw() +
          ggplot2::theme(plot.title = element_text(hjust = 0.5))

# Visualize cubic trend
p_cube <- ggplot2::ggplot(poly_data, aes(x = month, y = attrition_cube * .01)) + 
          ggplot2::labs(title = 'Cubic', x = 'Month', y = 'Turnover Rate') + 
          ggplot2::geom_line() +
          ggplot2::scale_x_continuous(breaks = 1:12) +
          ggplot2::scale_y_continuous(labels = scales::percent) +
          ggplot2::theme_bw() +
          ggplot2::theme(plot.title = element_text(hjust = 0.5))

# Display distribution visualizations
ggpubr::ggarrange(p_lin, p_quad, p_cube, ncol = 3, nrow = 1)

```

  It is important to note that adding higher order terms to the regression equation usually increases $R^2$ due to a more flexible fit to the data, but the additional coefficients are not necessarily significant. $R^2$ will approach 1 as the power of $x$ approaches $n-1$ since the fit line will connect every data point. However, a model that results in a perfect -- or near perfect -- fit is likely too flexible to generalize well to other data. This problem is known as overfitting and will be covered in Chapter \@ref(pred-mod). As a general rule, it is best not to add polynomial terms beyond the second or third orders to protect against overfitting the model.
  
  Comparing the Adjusted $R^2$ for models with higher-order terms to one with only linear terms will help in determining whether higher-order polynomials add value to the model in explaining incremental variance in the response. Evaluating whether the coefficients on higher-order polynomials are statistically significant is important in determining *which variables* are contributing to any observed increases in Adjusted $R^2$.
  
  Let's demonstrate how to fit a regression model with polynomial terms in R using the `turnover_trends` dataset. First, we will subset this data frame to level 4 People Scientists who work remotely, based on the notion that turnover varies by `level` and `remote`, and then visualize the turnover trend to understand month-over-month variation across years.
  
```{r ps-turnover-trends, out.width = "100%", echo = FALSE, fig.cap = 'Year 1-5 turnover trends for level 4 People Scientists, stratified by remote (dark grey line) vs. non-remote (light grey line).', fig.align = 'center', message = FALSE, warning = FALSE}

# Load employee data
turnover <- read.csv("https://raw.githubusercontent.com/crstarbuck/peopleanalytics_book/master/data/turnover_trends.csv")

# Subset data
ps_turnover <- subset(turnover, job == 'People Scientist' & level == 4)

p_ps_yr1 <- ggplot2::ggplot(data = subset(ps_turnover, year == 1), aes(x = month, y = turnover_rate, colour = remote)) + 
            ggplot2::geom_line() +
            ggplot2::geom_point() +
            ggplot2::scale_x_continuous(breaks = 1:12) +
            ggplot2::scale_y_continuous(breaks = 1:10) +
            ggplot2::scale_color_manual(values=c("#B8BDBF", "#595959")) +
            ggplot2::labs(title = "Year 1", x = "Month", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "none") +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_yr2 <- ggplot2::ggplot(data = subset(ps_turnover, year == 2), aes(x = month, y = turnover_rate, colour = remote)) + 
            ggplot2::geom_line() +
            ggplot2::geom_point() +
            ggplot2::scale_x_continuous(breaks = 1:12) +
            ggplot2::scale_y_continuous(breaks = 1:10) +
            ggplot2::scale_color_manual(values=c("#B8BDBF", "#595959")) +
            ggplot2::labs(title = "Year 2", x = "Month", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "none") +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_yr3 <- ggplot2::ggplot(data = subset(ps_turnover, year == 3), aes(x = month, y = turnover_rate, colour = remote)) + 
            ggplot2::geom_line() +
            ggplot2::geom_point() +
            ggplot2::scale_x_continuous(breaks = 1:12) +
            ggplot2::scale_y_continuous(breaks = 1:10) +
            ggplot2::scale_color_manual(values=c("#B8BDBF", "#595959")) +
            ggplot2::labs(title = "Year 3", x = "Month", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "none") +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_yr4 <- ggplot2::ggplot(data = subset(ps_turnover, year == 4), aes(x = month, y = turnover_rate, colour = remote)) + 
            ggplot2::geom_line() +
            ggplot2::geom_point() +
            ggplot2::scale_x_continuous(breaks = 1:12) +
            ggplot2::scale_y_continuous(breaks = 1:10) +
            ggplot2::scale_color_manual(values=c("#B8BDBF", "#595959")) +
            ggplot2::labs(title = "Year 4", x = "Month", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "none") +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_yr5 <- ggplot2::ggplot(data = subset(ps_turnover, year == 5), aes(x = month, y = turnover_rate, colour = remote)) + 
            ggplot2::geom_line() +
            ggplot2::geom_point() +
            ggplot2::scale_x_continuous(breaks = 1:12) +
            ggplot2::scale_y_continuous(breaks = 1:10) +
            ggplot2::scale_color_manual(values = c("#B8BDBF", "#595959")) +
            ggplot2::labs(title = "Year 5", x = "Month", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "none") +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

# Display distribution visualizations
ggpubr::ggarrange(p_ps_yr1, p_ps_yr2, p_ps_yr3, p_ps_yr4, p_ps_yr5, ncol = 3, nrow = 2)

```
  
  As we can see in Figure \@ref(fig:ps-turnover-trends), the relationship between month and turnover rate is non-linear, and level 4 People Scientists who work remotely leave at lower rates relative to those who do not work remotely. There is a clear seasonal pattern that is consistent across all five years as well as remote vs. non-remote groups; namely, there is a spike in turnover between March and June as well as later in the year (November/December). Fitting a model to these data will require non-linear terms.
  
  Adding polynomial terms requires an indicator variable `I()` in which the value of $x$ is raised to the desired order (e.g., $x^2$ = `I(x^2)`). Let's start by fitting linear, quadratic, and cubic regression models (to compare performance) using only `month` as a predictor. Notice that the shape of the trends resemble the cubic function shown in Figure \@ref(fig:poly-fun) in that there are two discernible inflection points at which the trend reverses directions.

```{r, message = FALSE, warning = FALSE}

# Fit linear, quadratic, and cubic models to ps_turnover data
ps.lin.fit <- lm(turnover_rate ~ month, data = ps_turnover)
ps.quad.fit <- lm(turnover_rate ~ month + I(month^2), data = ps_turnover)
ps.cube.fit <- lm(turnover_rate ~ month + I(month^2) + I(month^3), data = ps_turnover)

```

```{r ps-lm-mnth-output, out.width = "100%", echo = FALSE, fig.cap = 'Linear model output for regression of turnover rate onto month.', fig.align = 'center', message = FALSE, warning = FALSE}

# Load library
library(flextable)

# Produce tabular summary of regression model output
flextable::as_flextable(ps.lin.fit)

```  

```{r ps-quad-mnth-output, out.width = "100%", echo = FALSE, fig.cap = 'Quadratic model output for regression of turnover rate onto month.', fig.align = 'center', message = FALSE, warning = FALSE}

# Produce tabular summary of regression model output
flextable::as_flextable(ps.quad.fit)

```

```{r ps-cube-mnth-output, out.width = "100%", echo = FALSE, fig.cap = 'Cubic model output for regression of turnover rate onto month.', fig.align = 'center', message = FALSE, warning = FALSE}

# Produce tabular summary of regression model output
flextable::as_flextable(ps.cube.fit)

```

  The linear ($F(1,118)$ = .71, $p$ = .40) and quadratic ($F(2,117)$ = 1.18, $p$ = .31) models are not significant. However, as expected based on the shape of the turnover trend, the cubic model is significant ($F(3,116)$ = 6.30, $p$ < .001) and the linear (`month`), quadratic (`I(month^2)`), and cubic (`I(month^3)`) terms all provide significant information in estimating turnover rates ($p$ < .001).
  
  While the cubic model achieved statistical significance at the $p$ < .001 level, 86% of the variance in monthly turnover rates remains unexplained (1 - $R^2$ = .86). To improve the performance of the model, our model needs to reflect the fact that turnover varies as a function of `year` and `remote` in addition to `month`.

```{r turnover-pred, out.width = "100%", echo = FALSE, fig.cap = 'Linear, quadratic, and cubic model fit (red dashed line) to remote (dark grey points) and non-remote (light grey points) groups.', fig.align = 'center', message = FALSE, warning = FALSE}

# Apply models to predict people scientist turnover rates for each month in year 1
ps_lin_pred <- data.frame(month = 1:12,
                          turnover_rate = predict(ps.lin.fit, subset(ps_turnover, year == 1, select = c(month, turnover_rate))))
ps_quad_pred <- data.frame(month = 1:12,
                           turnover_rate = predict(ps.quad.fit, subset(ps_turnover, year == 1, select = c(month, turnover_rate))))
ps_cube_pred <- data.frame(month = 1:12,
                           turnover_rate = predict(ps.cube.fit, subset(ps_turnover, year == 1, select = c(month, turnover_rate))))

# Plot data against regression line
p_ps_lin <- ggplot2::ggplot(data = ps_turnover, aes(x = month, y = turnover_rate, color = remote)) + 
            ggplot2::geom_point() +
            ggplot2::scale_x_continuous(breaks = 1:12) +
            ggplot2::geom_function(fun = function(x) {ps.lin.fit$coefficients[[2]]*x + ps.lin.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
            ggplot2::scale_color_manual(values = c("#B8BDBF", "#595959")) +
            ggplot2::labs(title = "Linear", x = "Month", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::theme(legend.position = "none") +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_quad <- ggplot2::ggplot(data = ps_turnover, aes(x = month, y = turnover_rate, color = remote)) + 
             ggplot2::geom_point() +
             ggplot2::scale_x_continuous(breaks = 1:12) +
             ggplot2::geom_function(fun = function(x) {ps.quad.fit$coefficients[[2]]*x + ps.quad.fit$coefficients[[3]]*x^2 + ps.quad.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
             ggplot2::scale_color_manual(values = c("#B8BDBF", "#595959")) +
             ggplot2::labs(title = "Quadratic", x = "Month", y = "Turnover Rate") +
             ggplot2::theme_bw() +
             ggplot2::theme(legend.position = "none") +
             ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_cube <- ggplot2::ggplot(data = ps_turnover, aes(x = month, y = turnover_rate, color = remote)) + 
             ggplot2::geom_point() +
             ggplot2::scale_x_continuous(breaks = 1:12) +
             ggplot2::geom_function(fun = function(x) {ps.cube.fit$coefficients[[2]]*x + ps.cube.fit$coefficients[[3]]*x^2 + ps.cube.fit$coefficients[[4]]*x^3 + ps.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
             ggplot2::scale_color_manual(values = c("#B8BDBF", "#595959")) +
             ggplot2::labs(title = "Cubic", x = "Month", y = "Turnover Rate") +
             ggplot2::theme_bw() +
             ggplot2::theme(legend.position = "none") +
             ggplot2::theme(plot.title = element_text(hjust = 0.5))

# Display distribution visualizations
ggpubr::ggarrange(p_ps_lin, p_ps_quad, p_ps_cube, ncol = 3, nrow = 1)

```

  As shown in Figure \@ref(fig:turnover-pred), the multidimensional data vary widely around estimates produced by the two-dimensional models (i.e., `turnover_rate` predicted on the basis of `month`). While the cubic regression model reflects the seasonality in month-over-month turnover, there are notable differences between remote and non-remote turnover rates as well as differences across years.

  Let's add `remote` to the cubic regression model to see how performance changes.

```{r ps-cube-mnthrem-output, out.width = "100%", fig.cap = 'Cubic model output for regression of turnover rate onto month and remote.', fig.align = 'center', message = FALSE, warning = FALSE}

# Fit linear, quadratic, and cubic models to ps_turnover df
ps.cube.fit <- lm(turnover_rate ~ month + I(month^2) + I(month^3) + remote, data = ps_turnover)

# Produce tabular summary of regression model output
flextable::as_flextable(ps.cube.fit)

```

  As shown in Figure \@ref(fig:ps-cube-mnthrem-output), accounting for remote status increases explained variance by 21% (.35 - .14). In addition to the change in explained variance $\Delta R^2$, the coefficient on `remote` is statistically significant ($\beta$ = -1.64, $t$(115) = -6.09, $p$ < .001). On average, the turnover rate for remote People Scientists is 1.64% lower than the turnover rate for non-remote People Scientists.

  Next, let's include `year` in the model since turnover rates also vary along this dimension.

```{r ps-cube-yrmnthrem-output1, out.width = "100%", fig.cap = 'Cubic model output for regression of turnover rate onto year, month, and remote.', fig.align = 'center', message = FALSE, warning = FALSE}

# Fit linear, quadratic, and cubic models to ps_turnover df
ps.cube.fit <- lm(turnover_rate ~ year + month + I(month^2) + I(month^3) + remote, data = ps_turnover)

# Produce tabular summary of regression model output
flextable::as_flextable(ps.cube.fit)

```

  Explained variance increases to 62% by adding `year` to the model. While the coefficient on `year` is statistically significant ($\beta$ = .66, $t$(114) = 8.93, $p$ < .001), the change in attrition by year is not linear. Visualizing the distribution of turnover rates by year will provide evidence that a linear year-over-year growth factor will result in some large residuals since it will not capture the more complex trend present in these data.
  
```{r ps-turnover-yrly-dist, out.width = "100%", echo = FALSE, fig.cap = 'Turnover rate distribution by year for remote (left) and non-remote (right) groups. Red dashed line reflects linear relationship between year and turnover rate, with $y$-intercept lowered by 1.64 for remote group.', fig.align = 'center', message = FALSE, warning = FALSE}

# Model linear relationship between year and turnover rate, grouped by remote vs. non-remote
ps.lin.fit <- lm(turnover_rate ~ year + remote, data = ps_turnover)

# Build plots to visualize turnover rate distribution across years, grouped by remote status
p_ps_rem <- ggplot2::ggplot(data = subset(ps_turnover, remote == 'Yes'), aes(x = year, y = turnover_rate, group = year)) + 
            ggplot2::labs(title = "Remote", x = "Year", y = "Turnover Rate") +
            ggplot2::theme_bw() +
            ggplot2::geom_point(color = "#B8BDBF") +
            ggplot2::geom_function(fun = function(x) {ps.lin.fit$coefficients[[2]]*x + ps.lin.fit$coefficients[[3]] + ps.lin.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
            ggplot2::scale_color_manual(values=c("#B8BDBF", "#595959")) +
            ggplot2::theme(plot.title = element_text(hjust = 0.5))

p_ps_nrem <- ggplot2::ggplot(data = subset(ps_turnover, remote == 'No'), aes(x = year, y = turnover_rate, group = year)) + 
             ggplot2::labs(title = "Non-Remote", x = "Year", y = "Turnover Rate") +
             ggplot2::theme_bw() +
             ggplot2::geom_point(color = "#B8BDBF") +
             ggplot2::geom_function(fun = function(x) {ps.lin.fit$coefficients[[2]]*x + ps.lin.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
             ggplot2::theme(plot.title = element_text(hjust = 0.5))

# Display distribution visualizations
ggpubr::ggarrange(p_ps_rem, p_ps_nrem, ncol = 2, nrow = 1)

``` 

  Given the cubic nature of the change in turnover year-over-year, let's add quadratic and cubic terms for `year` to examine changes in model performance:

```{r ps-cube-yrmnthrem2-output, out.width = "100%", echo = FALSE, fig.cap = 'Cubic model output for regression of turnover rate onto year, month, and remote.', fig.align = 'center', message = FALSE, warning = FALSE}

# Fit linear, quadratic, and cubic models to ps_turnover df
ps.cube.fit <- lm(turnover_rate ~ year + I(year^2) + I(year^3) + month + I(month^2) + I(month^3) + remote, data = ps_turnover)

# Produce tabular summary of regression model output
flextable::as_flextable(ps.cube.fit)

```

  The inclusion of higher-order polynomials on `year` result in a perfect fit to these data ($R^2$ = 1). This indicates that the slope of the relationship between `month` and `turnover_rate` is perfectly consistent across years and within remote and non-remote groups.
  
  Our resulting equation for estimating `turnover_rate` on the basis of a combination of linear and non-linear values of `year`, `month`, and `remote` is defined by:
  
  $$ \hat y = -1.87 + 5.91year - 2.71year^2 + .36year^3 + 2.41month - .41month^2 + .02month^3 - 1.64remote + \epsilon $$

  The performance of this model may initially seem like a cause for celebration, but the probability is low that this model would estimate future turnover with such a high degree of accuracy. While these data were generated with a goal to simplify illustrations and facilitate a working knowledge of polynomial regression mechanics, data which conform to such a constant pattern of seasonality across multiple years is a highly improbable situation in practice. As stated earlier in this chapter, a model that results in a perfect fit is likely too flexible to generalize well to other data, and methods of evaluating how well models are likely to perform on future data will be covered in Chapter \@ref(pred-mod).

## Review Questions

1. What are some people analytics applications for comparing output from several regression models?

2. What modeling technique is appropriate for understanding an independent variable's contribution to a model's $R^2$ beyond a set of control variables?

3. In the context of Hierarchical Linear Regression, what is the indicator that $\Delta{R^2}$ is statistically significant when evaluating whether a particular independent variable provides meaningful information beyond a set of controls?

4. What are some examples of hypotheses that would warrant a linear mixed effects model over a general linear model?

5. What are the differences between Hierarchical Linear Modeling (HLM), which is also referred to as multilevel or mixed effects modeling, and Hierarchical Linear Regression (HLR)?

6. In what ways does polynomial regression differ from linear regression?

7. Why is it important to evaluate the nature of relationships at various levels of a categorical or time variable?

8. What shape characterizes a quadratic function?

9. If the coefficient on the cubic term is not statistically significant ($p$ >= .05) in a cubic regression model, but the linear and quadratic terms are statistically significant ($p$ < .05), what does this indicate about the model's fit to the data?

10. Why might adding higher-order polynomial terms to a model be problematic, even though the additional terms increase the model's $R^2$?