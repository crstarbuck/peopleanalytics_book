# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- paste('engagement =~ engagement_1 + engagement_2 + engagement_3
retention =~ retention_1 + retention_2 + retention_3')
# Fit and summarize the model
cfa.fit <- cfa(model, data = survey_dat)
summary(cfa.fit, fit.measures = TRUE)
# Load library
library(ggally)
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(survey_dat)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("engagement_1", "engagement_2", "engagement_3", "retention_1", "retention_2", "retention_3")))
View(survey_dat)
names(survey_dat$engagement_1) <- "eng_1"
View(survey_dat)
names(survey_dat)['engagement_1'] <- "eng_1"
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("engagement_1", "engagement_2", "engagement_3", "retention_1", "retention_2", "retention_3")))
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Visualize path diagram
graph_sem(model = cfa.fit)
library(tidySEM)
install.packages("tidySEM", dependencies = TRUE)
install.packages("tidySEM", dependencies = TRUE)
install.packages("tidySEM", dependencies = TRUE)
install.packages("tidySEM", dependencies = TRUE)
# Load library
library(tidySEM)
# Load library
library(tidySEM)
install.packages("lavaanPlot", dependencies = TRUE)
# Load library
library(lavaanPlot)
# Visualize path diagram
lavaanPlot(model = fit1, labels = labels1, coefs = TRUE, stand = TRUE, sig = 0.05)
# Visualize path diagram
lavaanPlot(model = cfa.fit, labels = labels1, coefs = TRUE, stand = TRUE, sig = 0.05)
# Visualize path diagram
lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE, sig = 0.05)
# Visualize path diagram
lavaanPlot::lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE)
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Load library
library(lavaan)
# Model specification; each line represents a separate latent factor
model <- paste('engagement =~ eng_1 + eng_2 + eng_3
retention =~ ret_1 + ret_2 + ret_3')
# Load library
library(lavaan)
# Model specification; each line represents a separate latent factor
model <- paste('engagement =~ eng_1 + eng_2 + eng_3
retention =~ ret_1 + ret_2 + ret_3')
# Fit the model
cfa.fit <- lavaan::cfa(model, data = survey_dat)
# Load library
library(lavaanPlot)
# Visualize path diagram
lavaanPlot::lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE)
# Summarize the model
summary(cfa.fit, fit.measures = TRUE)
libary(factanal)
install.packages("factanal", dependencies = TRUE)
View(survey_dat)
# Fit model using three factors and varimax factor rotation
efa.fit <- factanal(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), 3, rotation = 'varimax')
# Load library
library(factanal)
# Load library
library(factanal)
library(psych)
# Load library
library(factanal)
# Fit model using three factors and varimax factor rotation
efa.fit <- factanal(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), 3, rotation = 'varimax')
load <- efa.fit$loadings[,1:2]
load
install.packages("stats", dependencies = TRUE)
install.packages("stats", dependencies = TRUE)
install.packages("stats", dependencies = TRUE)
install.packages("stats", dependencies = TRUE)
# Load library
library(stats)
# Fit model using three factors and varimax factor rotation
efa.fit <- stats::factanal(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), 3, rotation = 'varimax')
load <- efa.fit$loadings[,1:2]
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotation = 'varimax')
# Load library
library(psych)
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotation = 'varimax')
?factor.pa
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3)
load <- efa.fit$loadings[,1:2]
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotate = 'varimax')
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::fa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotate = 'varimax')
efa.fit
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::fa(survey_dat, nfactors = 3, rotate = 'varimax')
eigen(cor(survey_dat))
# Load library
library(nFactors)
install.packages("nFactors", dependencies = TRUE)
# Load library
library(nFactors)
# Load library
library(nFactors)
ap <- parallel(subject = nrow(survey_dat),var = ncol(survey_dat), rep = 100,cent = .05)
ap
ns <- nFactors::nScree(x = ev$values, aparallel = ap$eigen$qevpea)
# Retrieve eigenvalues
ev <- eigen(cor(survey_dat))
ap <- parallel(subject = nrow(survey_dat),var = ncol(survey_dat), rep = 100, cent = .05)
ns <- nFactors::nScree(x = ev$values, aparallel = ap$eigen$qevpea)
plotnScree(ns)
?bartlett.test
psych::KMO(survey_dat)
# Bartlett's Test of Sphericity
psych::cortest.bartlett(cor(survey_dat), nrow(survey_dat))
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Create scree plot
ggplot2::qplot(c(1:4), var_explained) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = pca$sdev^2 / sum(pca$sdev^2)
# Create scree plot
ggplot2::qplot(c(1:4), var_explained) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Create scree plot
ggplot2::qplot(c(1:4), pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
?qplot
# Create scree plot
qplot(c(1:4), pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Create scree plot
ggplot2::qplot(pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
pca_var
# Create scree plot
ggplot2::qplot(pca, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
pca
length(pca)
nrow(pca)
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = pca$sdev^2 / sum(pca$sdev^2)
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = pca$sdev^2 / sum(pca$sdev^2)
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
$ggplot2::ylim(0, 1) +
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = pca$sdev^2 / sum(pca$sdev^2)
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
#ggplot2::ylim(0, 1) +
ggplot2::theme_bw()
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
#ggplot2::ylim(0, 1) +
ggplot2::theme_bw()
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
#ggplot2::ylim(0, 1) +
ggplot2::theme_bw()
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::ylim(0, 1) +
ggplot2::theme_bw()
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::ylim(0, 1) +
ggplot2::theme_bw()
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::ylim(0, 100) +
ggplot2::theme_bw()
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
#gplot2::ylim(0, 100) +
ggplot2::theme_bw()
# Principal axis factoring using 19 factors and oblimin rotation
efa.fit.19 <- psych::fa(survey_dat, nfactors = 19, rotate = 'oblimin')
# Principal axis factoring using 19 factors and oblimin rotation
psych::fa(survey_dat, nfactors = 19, rotate = 'oblimin')
?scree
scree(survey_dat, pc=FALSE)
eigen(cor(survey_dat))
# Compute eigenvalues
eigen(cor(survey_dat))
# Compute eigenvalues
ev <- eigen(cor(survey_dat))
# Display eigenvalues
ev$values
# Principal axis factoring using 19 factors and oblimin rotation
psych::fa(survey_dat, nfactors = 19, rotate = 'oblimin')
# Principal axis factoring using 19 factors and oblimin rotation
efa.fit <- psych::fa(survey_dat, nfactors = 19, rotate = 'oblimin')
efa.fit$scores
efa.fit$loadings
efa.fit$factors
efa.fit$STATISTIC
# Display factor loadings
efa.fit$loadings
psych::scree(mydata, pc=FALSE)
psych::scree(survey_dat, pc=FALSE)
# Compute eigenvalues
ev <- eigen(cor(survey_dat))
# Display eigenvalues
ev$values
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(psych)
# Kaiser-Meyer-Olkin (KMO) statistic
psych::KMO(survey_dat)
# Bartlett's Test of Sphericity
psych::cortest.bartlett(cor(survey_dat), nrow(survey_dat))
# Produce scree plot
psych::scree(survey_dat, pc = FALSE)
# Bartlett's Test of Sphericity
psych::cortest.bartlett(cor(survey_dat), nrow(survey_dat))
# Load library
library(psych)
# Kaiser-Meyer-Olkin (KMO) statistic
psych::KMO(survey_dat)
# Produce scree plot
psych::scree(survey_dat, pc = FALSE)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::theme_bw()
# Principal axis factoring using 19 factors and oblimin rotation
efa.fit.19 <- psych::fa(survey_dat, nfactors = 19, rotate = 'oblimin')
# Display factor loadings
efa.fit.19$loadings
# Principal axis factoring using 1 factors and oblimin rotation
efa.fit.1 <- psych::fa(survey_dat, nfactors = 1, rotate = 'oblimin')
# Display factor loadings
efa.fit.1$loadings
# Principal axis factoring using 19 factors and oblimin rotation
efa.fit.19 <- psych::fa(survey_dat, nfactors = 3, rotate = 'oblimin')
# Display factor loadings
efa.fit.19$loadings
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(psych)
# Kaiser-Meyer-Olkin (KMO) statistic
psych::KMO(survey_dat)
# Bartlett's Test of Sphericity
psych::cortest.bartlett(cor(survey_dat), nrow(survey_dat))
# Produce scree plot
psych::scree(survey_dat, pc = FALSE)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:12, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::theme_bw()
# Principal axis factoring using 12 factors and oblimin rotation
efa.fit.12 <- psych::fa(survey_dat, nfactors = 12, rotate = 'oblimin')
# Display factor loadings
efa.fit.12$loadings
# Principal axis factoring using 12 factors and oblimin rotation
efa.fit.12 <- psych::fa(survey_dat, nfactors = 12, rotate = 'oblimin')
# Display factor loadings
efa.fit.12$loadings
efa.fit.12$scores
# Principal axis factoring using 4 factors and oblimin rotation
efa.fit.4 <- psych::fa(survey_dat, nfactors = 4, rotate = 'oblimin')
# Display factor loadings
efa.fit.4$loadings
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Load library
library(lavaan)
# Model specification; each line represents a separate latent factor
model <- paste('engagement =~ eng_1 + eng_2 + eng_3
retention =~ ret_1 + ret_2 + ret_3')
# Fit the model
cfa.fit <- lavaan::cfa(model, data = survey_dat)
# Load library
library(lavaanPlot)
# Visualize path diagram
lavaanPlot::lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE)
# Summarize the model
summary(cfa.fit, fit.measures = TRUE)
length(pca_var)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:length(pca_var), pca_var) +
ggplot2::geom_line() +
ggplot2::scale_x_continuous(breaks = 1:length(pca_var)) +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::theme_bw()
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(psych)
# Kaiser-Meyer-Olkin (KMO) statistic
psych::KMO(survey_dat)
# Bartlett's Test of Sphericity
psych::cortest.bartlett(cor(survey_dat), nrow(survey_dat))
# Produce scree plot
psych::scree(survey_dat, pc = FALSE)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = (pca$sdev^2 / sum(pca$sdev^2)) * 100
# Create scree plot
ggplot2::qplot(1:length(pca_var), pca_var) +
ggplot2::geom_line() +
ggplot2::scale_x_continuous(breaks = 1:length(pca_var)) +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained (%)") +
ggplot2::theme_bw()
# Principal axis factoring using 12 factors and oblimin rotation
efa.fit.12 <- psych::fa(survey_dat, nfactors = 12, rotate = 'oblimin')
# Display factor loadings
efa.fit.12$loadings
# Principal axis factoring using 4 factors and oblimin rotation
efa.fit.4 <- psych::fa(survey_dat, nfactors = 4, rotate = 'oblimin')
# Display factor loadings
efa.fit.4$loadings
psych::fa.diagram(efa.fit.4, main = survey_dat)
# Principal axis factoring using 3 factors and oblimin rotation
efa.fit <- psych::fa(survey_dat, nfactors = 3, rotate = 'oblimin')
# Display factor loadings
efa.fit$loadings
psych::fa.diagram(efa.fit.4, main = survey_dat)
psych::fa.diagram(efa.fit.4, main = survey_dat)
psych::fa.diagram(efa.fit, main = survey_dat)
psych::fa.diagram(efa.fit)
