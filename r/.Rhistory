# Produce descriptive stats for org tenure
summary(employees$org_tenure)
# Visualize org tenure distribution
ggplot2::ggplot() +
aes(employees$org_tenure) +
labs(x = "Org Tenure", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
labs(x = "Org Tenure", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
library(ggplot2)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate bernoulli distribution
bernoulli_dist <- rbinom(1000, 1, prob = .5)
# Simulate binomial distribution
# Notice the important difference relative to the Bernoulli simulation (100 trials vs. 1)
binomial_dist <- rbinom(1000, 100, prob = .5)
# Simulate negative binomial distribution
nbinomial_dist <- rnbinom(1000, 100, prob = .5)
# Simulate multinomial distribution with varying probabilities per level
multinomial_dist <- rmultinom(1000, 4, prob = c(.4, .3, .2, .6))
# Simulate poisson distribution
poisson_dist <- rpois(1000, 10)
# Simulate geometric distribution
geometric_dist <- rgeom(1000, prob = .2)
# Create user-defined function (UDF) to simplify probability distribution visualization
# Function arguments: (1) data = object containing random distribution values; (2) type = 'discrete' or 'continuous' probability distribution; and (3) title = name of distribution
dist.viz <- function(data, type, title) {
if (type == "discrete"){
# Discrete distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "count") +
geom_histogram(fill = "#414141") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
} else {
# Continuous distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
}
return(viz)
}
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
p_binomial <- dist.viz(data = binomial_dist, type = "discrete", title = "Binomial")
p_nbinomial <- dist.viz(data = nbinomial_dist, type = "discrete", title = "Negative Binomial")
p_multinomial <- dist.viz(data = multinomial_dist, type = "discrete", title = "Multinomial")
p_poisson <- dist.viz(data = poisson_dist, type = "discrete", title = "Poisson")
p_geometric <- dist.viz(data = geometric_dist, type = "discrete", title = "Geometric")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Simulate chi-square distribution
chisq_dist <- rchisq(1000, df = 5)
# Simulate F distribution
f_dist <- rf(1000, df1 = 5, df2 = 200)
# Call UDF to build visualizations and store to objects
# Note that as long as the arguments are in the order specified in the function (see our UDF definition above), the argument names do not need to be specified. To illustrate, we will drop the argument names from these function calls:
p_normal <- dist.viz(normal_dist, "continuous", "Normal")
p_lnormal <- dist.viz(lnormal_dist, "continuous", "Log-Normal")
p_uniform <- dist.viz(uniform_dist, "continuous", "Uniform")
p_t <- dist.viz(t_dist, "continuous", "Student's T")
p_chisq <- dist.viz(chisq_dist, "continuous", "Chi-Square")
p_f <- dist.viz(f_dist, "continuous", "F")
# Display distribution visualizations
ggpubr::ggarrange(p_normal, p_lnormal, p_uniform, p_t, p_chisq, p_f,
ncol = 3, nrow = 2)
# Set seed for reproducible random distribution
set.seed(1234)
# Generate uniform population distribution with 1000 values ranging from 1 to 100
rand.unif <- runif(1000, min = 1, max = 100)
# Calculate population mean
mean(rand.unif)
# Calculate population variance
N = length(rand.unif)
var(rand.unif) * (N - 1) / N
# Produce histogram to visualize population distribution
ggplot2::ggplot() +
aes(rand.unif) +
labs(x = "x", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# Store sample means with n = 50
x_bars <- sample_means[sample_means$n == 50, "x_bar"]
# Store sample size
n <- length(x_bars)
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# For each n, draw random samples
for (n in sample_n) {
for (draw in 1:samples) {
# Store sample means in data frame
sample_means <- rbind(sample_means, cbind.data.frame(
n = n,
x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
}
}
# Produce histograms to visualize distributions of sample means, grouped by n-count
sample_means %>% ggplot2::ggplot() +
aes(x = x_bar, fill = n) +
labs(x = "x-bar", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
facet_wrap(~n)
# Store sample means with n = 50
x_bars <- sample_means[sample_means$n == 50, "x_bar"]
# Store sample size
n <- length(x_bars)
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
subset(x_bars, x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars))
length(subset(x_bars, x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars))) / n * 100
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
length(subset(x_bars, x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars))) / n * 100
length(subset(x_bars, x_bars < mean(x_bars) + 3 * sd(x_bars) & x_bars > mean(x_bars) - 3 * sd(x_bars))) / n * 100
# Calculate percent of sample means within +/- 3 SEs
length(x_bars[x_bars < mean(x_bars) + 3 * sd(x_bars) & x_bars > mean(x_bars) - 3 * sd(x_bars)]) / n * 100
length(subset(x_bars, x_bars < mean(x_bars) + 3 * sd(x_bars) & x_bars > mean(x_bars) - 3 * sd(x_bars))) / n * 100
# Load data sets
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
status <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/status.csv")
benefits <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/benefits.csv")
demographics <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/demographics.csv")
job <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/job.csv")
payroll <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/payroll.csv")
performance <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/performance.csv")
prior_employment <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/prior_employment.csv")
survey_response <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_response.csv")
tenure <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/tenure.csv")
# Return row and column counts
dim(employees)
# Store original annual comp for sample employee
orig_comp <- employees[employees$employee_id == '2176', 'annual_comp']
subset(employees, employee_id = '2176', select = annual_comp)
subset(employees, employee_id == '2176', select = annual_comp)
employees[employees$employee_id == '2176', 'annual_comp']
subset(employees, employee_id == '2176', select = annual_comp)
subset(employees, is.na(annual_comp), select = c(employee_id, job_title, job_lvl))
# Return relevant employee characteristics where annual comp is missing
employees[is.na(employees$annual_comp), c("employee_id", "job_title", "job_lvl")]
# Force a NA in lieu of annual comp for illustrative purposes
employees[employees$employee_id == '2176', 'annual_comp'] <- NA
# Return relevant employee characteristics where annual comp is missing
employees[is.na(employees$annual_comp), c("employee_id", "job_title", "job_lvl")]
subset(employees, is.na(annual_comp), select = c(employee_id, job_title, job_lvl))
# Load data sets
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
status <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/status.csv")
benefits <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/benefits.csv")
demographics <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/demographics.csv")
job <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/job.csv")
payroll <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/payroll.csv")
performance <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/performance.csv")
prior_employment <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/prior_employment.csv")
survey_response <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_response.csv")
tenure <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/tenure.csv")
# Return row and column counts
dim(employees)
# Store original annual comp for sample employee
orig_comp <- subset(employees, employee_id == '2176', select = annual_comp)
subset(employees, employee_id == '2176', select = annual_comp) <- NA
employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
test = subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
test
View(test)
mean(test, na.rm = TRUE)
mean(as.numeric(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)), na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
ubset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' && job_lvl == 2, select = annual_comp)
mean(subset(employees, job_title == 'Manufacturing Director' && job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
mode(test)
class(test)
str(test)
test2 = employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
str(test1)
str(test2)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
test
test1
test2
mean(test)
apply(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), mean)
sapply(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), mean, na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
subset(employees, employee_id == '2176', select = annual_comp)
employees[employees$employee_id == '2176', 'annual_comp']
# Display absolute difference between original and imputed comp
abs(orig_comp - subset(employees, employee_id == '2176', select = annual_comp))
# Impute missing comp for relevant segment
employees[employees$employee_id == '2176', 'annual_comp'] <- imputed_comp
# Return average annual comp for employees with similar characteristics, excluding employees with missing comp values
imputed_comp <- sapply(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), mean, na.rm = TRUE)
# Impute missing comp for relevant segment
employees[employees$employee_id == '2176', 'annual_comp'] <- imputed_comp
# Display absolute difference between original and imputed comp
abs(orig_comp - subset(employees, employee_id == '2176', select = annual_comp))
# Display absolute difference between original and imputed comp
round(abs(orig_comp - subset(employees, employee_id == '2176', select = annual_comp)), 0)
# Gender one-hot encoding
employees$gender_ohe <- ifelse(employees$gender == 'Female', 1, 0)
subset(employees, select = c(employee_id, gender_ohe))
head(subset(employees, select = c(employee_id, gender_ohe)))
# Preview records
head(employees[, c("employee_id", "gender_ohe")])
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Produce descriptive stats for org tenure
summary(employees$org_tenure)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
#Load library
library(ggplot2)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
ggplot2::labs(x = "Education Level", y = "Annual Compensation") +
ggplot2::theme_bw() +
ggplot2::geom_boxplot()
# Load library
library(ggplot2)
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
ggplot2::labs(x = "Education Level", y = "Annual Compensation") +
ggplot2::theme_bw() +
ggplot2::geom_boxplot()
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Calculate sample variance for annual compensation
var(employees$annual_comp)
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
ggplot2::labs(x = "Education Level", y = "Annual Compensation") +
ggplot2::theme_bw() +
ggplot2::geom_boxplot()
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Produce descriptive stats for org tenure
summary(employees$org_tenure)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
# Load employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
View(employees)
summary(employees$dept)
unique(employees$dept)
employees %>% group_by(dept)
library(dplyr)
employees %>% group_by(dept)
employees %>% %>% group_by(dept) %>% summarise(n = n())
employees %>% group_by(dept) %>% summarise(n = n())
one.way <- aov(annual_comp ~ dept, data = employees)
summary(one.way)
unique(employees$job_title)
unique(employees$ed_field)
one.way <- aov(annual_comp ~ engagement, data = employees)
summary(one.way)
one.way <- aov(annual_comp ~ business_travel, data = employees)
summary(one.way)
one.way <- aov(last_promo ~ engagement, data = employees)
summary(one.way)
one.way <- aov(annual_comp ~ dept, data = employees)
summary(one.way)
one.way <- aov(annual_comp ~ ed_lvl, data = employees)
summary(one.way)
# Two-way ANOVA investigating mean differences in annual comp by education level
two.way <- aov(annual_comp ~ ed_lvl + dept, data = employees)
summary(two.way)
# One-way ANOVA investigating mean differences in annual comp by education level
one.way <- aov(annual_comp ~ stock_opt_lvl, data = employees)
summary(one.way)
# One-way ANOVA investigating mean differences in annual comp by education level
one.way <- aov(annual_comp ~ overtime, data = employees)
summary(one.way)
# One-way ANOVA investigating mean differences in annual comp by education level
one.way <- aov(annual_comp ~ business_travel, data = employees)
summary(one.way)
# One-way ANOVA investigating mean differences in annual comp by education level
one.way <- aov(annual_comp ~ job_sat, data = employees)
summary(one.way)
unique(employees$job_sat)
# Two-way ANOVA investigating mean differences in annual comp by education level
two.way <- aov(annual_comp ~ job_sat + engagement, data = employees)
summary(two.way)
# ANOVA investigating interraction between mean differences in annual comp by job satisfaction x engagement levels
interaction <- aov(annual_comp ~ job_sat * engagement, data = employees)
# ANOVA investigating interraction between mean differences in annual comp by job satisfaction x engagement levels
interaction <- aov(annual_comp ~ job_sat * engagement, data = employees)
summary(interaction)
# ANOVA investigating interraction between mean differences in annual comp by job satisfaction x dept levels
interaction <- aov(annual_comp ~ job_sat * dept, data = employees)
summary(interaction)
# ANOVA investigating interraction between mean differences in annual comp by job satisfaction x dept levels
interaction <- aov(annual_comp ~ job_sat * ed_lvl, data = employees)
summary(interaction)
interaction <- aov(annual_comp ~ ed_lvl * dept, data = employees)
summary(interaction)
interaction <- aov(annual_comp ~ ed_lvl * job_lvl, data = employees)
summary(interaction)
interaction <- aov(annual_comp ~ ed_lvl * job_title, data = employees)
summary(interaction)
interaction <- aov(annual_comp ~ ed_lvl * business_travel, data = employees)
summary(interaction)
# Load employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# One-way ANOVA investigating mean differences in annual comp by job satisfaction
one.way <- aov(annual_comp ~ job_sat, data = employees)
summary(one.way)
#
qqnorm(employees$annual_comp)
qqline(employees$annual_comp)
# One-way ANOVA investigating mean differences in annual comp by job satisfaction
one.way <- aov(annual_comp ~ job_sat, data = employees)
summary(one.way)
# Load library for Levene's test
library(car)
# Levene's test for homogeneity of variance
leveneTest(annual_comp ~ job_sat, data = employees)
# Levene's test for homogeneity of variance
leveneTest(annual_comp ~ as.factor(job_sat), data = employees)
install.packages("car", dependencies = TRUE)
install.packages("car", dependencies = TRUE)
# Load library for Levene's test
library(car)
# Perform Levene's test for homogeneity of variance
leveneTest(annual_comp ~ as.factor(job_sat), data = employees)
# Build the linear model
model  <- lm(annual_comp ~ job_sat, data = employees)
# Create a QQ plot of residuals
ggqqplot(residuals(model))
# Load library for normality plots
library(ggpubr)
# Load library for normality plots
library(ggpubr)
# Build the linear model
model  <- lm(annual_comp ~ job_sat, data = employees)
# Build the linear model
model  <- lm(annual_comp ~ job_sat, data = employees)
# Create a QQ plot of residuals
ggqqplot(residuals(model))
qqplot(model)
# Compute Shapiro-Wilk test of normality
shapiro_test(residuals(model))
?shapiro.test
# Compute Shapiro-Wilk test of normality
shapiro.test(residuals(model))
# Build a linear model
model <- lm(log(annual_comp) ~ job_sat, data = employees)
# Create a Q-Q plot of residuals
ggqqplot(residuals(model))
# Build a linear model
model <- lm(sqrt(annual_comp) ~ job_sat, data = employees)
# Create a Q-Q plot of residuals
ggqqplot(residuals(model))
# Build a linear model
model <- lm(log10(annual_comp) ~ job_sat, data = employees)
# Create a Q-Q plot of residuals
ggqqplot(residuals(model))
# Build a linear model
model <- lm(annual_comp ~ job_sat, data = employees)
# Create a Q-Q plot of residuals
ggqqplot(residuals(model))
plot(employees$annual_comp)
hist(employees$annual_comp)
hist(sqrt(employees$annual_comp))
hist(log(employees$annual_comp))
residuals(model)
# Build a linear model
model <- lm(log(annual_comp) ~ job_sat, data = employees)
# Create a Q-Q plot of residuals
ggqqplot(residuals(model))
?log
# Build a linear model using the natural logarithm of annual comp
model <- lm(log(annual_comp) ~ log(job_sat), data = employees)
# Create a Q-Q plot of residuals
ggqqplot(residuals(model))
# Build a linear model using the natural logarithm of annual comp
ln.model <- lm(log(annual_comp) ~ job_sat, data = employees)
# Build a linear model using the log base 10 of annual comp
log10.model <- lm(log10(annual_comp) ~ job_sat, data = employees)
# Build a linear model using the square root of annual comp
sqrt.model <- lm(sqrt(annual_comp) ~ job_sat, data = employees)
# Store Q-Q plots to viz objects
ln.viz <- ggpubr::ggqqplot(residuals(ln.model))
log10.viz <- ggpubr::ggqqplot(residuals(log10.model))
sqrt.viz <- ggpubr::ggqqplot(residuals(sqrt.model))
# Display Q-Q plots of residuals
ggpubr::ggarrange(ln.viz, log10.viz, sqrt.viz,
ncol = 3, nrow = 2)
# Display Q-Q plots of residuals
ggpubr::ggarrange(ln.viz, log10.viz, sqrt.viz,
ncol = 3, nrow = 1)
# Store Q-Q plots to viz objects
ln.viz <- ggpubr::ggqqplot(residuals(ln.model)) + ggtitle("Plot of length \n by dose")
# Display Q-Q plots of residuals
ggpubr::ggarrange(ln.viz, log10.viz, sqrt.viz,
ncol = 3, nrow = 1)
# Store Q-Q plots to viz objects
ln.viz <- ggpubr::ggqqplot(residuals(ln.model)) + ggtitle("Natural Log Transformation")
# Display Q-Q plots of residuals
ggpubr::ggarrange(ln.viz, log10.viz, sqrt.viz,
ncol = 3, nrow = 1)
log10.viz <- ggpubr::ggqqplot(residuals(log10.model)) + ggtitle("Log Base 10 Transformation")
sqrt.viz <- ggpubr::ggqqplot(residuals(sqrt.model)) + ggtitle("Square Root Transformation")
# Display Q-Q plots of residuals
ggpubr::ggarrange(ln.viz, log10.viz, sqrt.viz,
ncol = 3, nrow = 1)
# Store Q-Q plots to viz objects
ln.viz <- ggpubr::ggqqplot(residuals(ln.model)) + ggtitle("Natural Log")
log10.viz <- ggpubr::ggqqplot(residuals(log10.model)) + ggtitle("Log Base 10")
sqrt.viz <- ggpubr::ggqqplot(residuals(sqrt.model)) + ggtitle("Square Root")
# Display Q-Q plots of residuals
ggpubr::ggarrange(ln.viz, log10.viz, sqrt.viz,
ncol = 3, nrow = 1)
View(log10.model)
