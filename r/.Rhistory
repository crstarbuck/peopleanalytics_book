oversampled_id <- sample(training_dat_os[training_dat_os$active == 1, 'employee_id'], size = 1, replace = TRUE)
# Store observation for sampled employee id
new_obs <- unique(training_dat_os %>% filter(employee_id == oversampled_id))
# Append sampled observation to training data frame
training_dat_os <- rbind(training_dat_os, new_obs)
}
# Return Boolean to validate that classes are equal in the training data
nrow(training_dat_os %>% filter(active == 0)) == nrow(training_dat_os %>% filter(active == 1))
# Load library
library(flextable)
# Fit binomial logistic regression model
glm.fit <- glm(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat, family = binomial)
# Produce tabular summary of regression model output
flextable::as_flextable(glm.fit)
# Calculate class representation delta in training data
training_class_delta <- nrow(training_dat %>% filter(active == 0)) - nrow(training_dat %>% filter(active == 1))
# Copy training data to separate data frame for oversampling
training_dat_os <- training_dat
# Set seed for reproducible results
set.seed(12345)
# Oversample the underrepresented inactive class by training_class_delta to align observation counts with active class
# Note: A loop is not the most efficient -- especially with large data sets -- but it is leveraged here to simplify instruction on SMOTE mechanics
for (i in 1:training_class_delta){
# Sample employee id from underrepresented class
oversampled_id <- sample(training_dat_os[training_dat_os$active == 1, 'employee_id'], size = 1, replace = TRUE)
# Store observation for sampled employee id
new_obs <- unique(training_dat_os %>% filter(employee_id == oversampled_id))
# Append sampled observation to training data frame
training_dat_os <- rbind(training_dat_os, new_obs)
}
# Return Boolean to validate that classes are equal in the training data
nrow(training_dat_os %>% filter(active == 0)) == nrow(training_dat_os %>% filter(active == 1))
# Load library
library(flextable)
# Fit binomial logistic regression model
glm.fit <- glm(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat, family = binomial)
# Produce tabular summary of regression model output
flextable::as_flextable(glm.fit)
# Calculate class representation delta in training data
training_class_delta <- nrow(training_dat %>% filter(active == 0)) - nrow(training_dat %>% filter(active == 1))
# Copy training data to separate data frame for oversampling
training_dat_os <- training_dat
# Set seed for reproducible results
set.seed(123)
# Oversample the underrepresented inactive class by training_class_delta to align observation counts with active class
# Note: A loop is not the most efficient -- especially with large data sets -- but it is leveraged here to simplify instruction on SMOTE mechanics
for (i in 1:training_class_delta){
# Sample employee id from underrepresented class
oversampled_id <- sample(training_dat_os[training_dat_os$active == 1, 'employee_id'], size = 1, replace = TRUE)
# Store observation for sampled employee id
new_obs <- unique(training_dat_os %>% filter(employee_id == oversampled_id))
# Append sampled observation to training data frame
training_dat_os <- rbind(training_dat_os, new_obs)
}
# Return Boolean to validate that classes are equal in the training data
nrow(training_dat_os %>% filter(active == 0)) == nrow(training_dat_os %>% filter(active == 1))
# Load library
library(flextable)
# Fit binomial logistic regression model
glm.fit <- glm(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat, family = binomial)
# Produce tabular summary of regression model output
flextable::as_flextable(glm.fit)
# Fit binomial logistic regression model
glm.os.fit <- glm(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat_os, family = binomial)
# Produce tabular summary of regression model output
flextable::as_flextable(glm.os.fit)
# Calculate class representation delta in training data
training_class_delta <- nrow(training_dat %>% filter(active == 0)) - nrow(training_dat %>% filter(active == 1))
# Copy training data to separate data frame for oversampling
training_dat_os <- training_dat
# Set seed for reproducible results
set.seed(123)
# Oversample the underrepresented inactive class by training_class_delta to align observation counts with active class
# Note: A loop is not the most efficient -- especially with large data sets -- but it is leveraged here to simplify instruction on SMOTE mechanics
for (i in 1:training_class_delta){
# Sample employee id from underrepresented class
oversampled_id <- sample(training_dat_os[training_dat_os$active == 1, 'employee_id'], size = 1, replace = TRUE)
# Store observation for sampled employee id
new_obs <- unique(training_dat_os %>% filter(employee_id == oversampled_id))
# Append sampled observation to training data frame
training_dat_os <- rbind(training_dat_os, new_obs)
}
# Return Boolean to validate that classes are equal in the training data
nrow(training_dat_os %>% filter(active == 0)) == nrow(training_dat_os %>% filter(active == 1))
# Load library
library(flextable)
# Fit binomial logistic regression model
glm.fit <- glm(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat, family = binomial)
# Produce tabular summary of regression model output
flextable::as_flextable(glm.fit)
# Load library
library(randomForest)
# Train RF model using original data
rf.fit <- randomForest::randomForest(active ~ overtime + job_lvl + engagement + interview_rating, data = training_dat)
# Train RF model using oversampled data
rf.os.fit <- randomForest::randomForest(active ~ overtime + job_lvl + engagement + interview_rating, data = training_dat_os)
# Develop function that returns a data frame of model performance statistics
classifier.perf <- function(model, actual, predicted){
# Check for missing values; metrics will be computed on non-missing values only
predicted <- predicted[!is.na(actual)]
actual <- actual[!is.na(actual)]
actual <- actual[!is.na(predicted)]
# Produce counts for model performance metrics
TP <- sum(actual == 1 & predicted == 1) # true positives
TN <- sum(actual == 0 & predicted == 0) # true negatives
FP <- sum(actual == 0 & predicted == 1) # false positives
FN <- sum(actual == 1 & predicted == 0) # false negatives
P <- TP + FN # total positives
N <- FP + TN # total negatives
# Store rates to variables
accuracy <- signif(100 * (sum(actual == predicted) / length(actual)), 3)
sensitivity <- signif(100 * (TP / (TP + FN)), 3)
specificity <- signif(100 * (TN / (TN + FP)), 3)
precision <- signif(100 * (TP / (TP + FP)), 3)
neg_pred_val <- signif(100 * (TN / (TN + FN)), 3)
mdl <- rep(model, times = 5)
stat_nm <- c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val")
stat_vl <- c(accuracy, sensitivity, specificity, precision, neg_pred_val)
# Return model performance statistics in a data frame
return(data.frame(mdl, stat_nm, stat_vl))
}
# Initialize empty data frame for model performance stats
perf.metrics <- NULL
# Predict with logistic regression model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM",
actual = test_dat$active,
predicted = ifelse(predict(glm.fit, test_dat, type = "response") > .5, 1, 0))))
# Predict with logistic regression model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(glm.os.fit, test_dat, type = "response") > .5, 1, 0))))
# Predict with RF model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF",
actual = test_dat$active,
predicted = ifelse(predict(rf.fit, test_dat, type = "response") > .5, 1, 0))))
# Predict with RF model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(rf.os.fit, test_dat, type = "response") > .5, 1, 0))))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::guides(fill = guide_legend(title = "Model"))
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
coord_flip() +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
#ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
# ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::scale_fill_manual(values = c("#003366", "#3399CC", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
# ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::scale_fill_manual(values = c("#003366", "#0033FF", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Initialize empty data frame for model performance stats
perf.metrics <- NULL
# Predict with logistic regression model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM",
actual = test_dat$active,
predicted = ifelse(predict(glm.fit, test_dat, type = "response") > .7, 1, 0))))
# Predict with logistic regression model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(glm.os.fit, test_dat, type = "response") > .7, 1, 0))))
# Predict with RF model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF",
actual = test_dat$active,
predicted = ifelse(predict(rf.fit, test_dat, type = "response") > .7, 1, 0))))
# Predict with RF model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(rf.os.fit, test_dat, type = "response") > .7, 1, 0))))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
# ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::scale_fill_manual(values = c("#003366", "#0033FF", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Initialize empty data frame for model performance stats
perf.metrics <- NULL
# Set probability threshold for classification
prob_threshold <- .7
# Predict with logistic regression model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM",
actual = test_dat$active,
predicted = ifelse(predict(glm.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Predict with logistic regression model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(glm.os.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Predict with RF model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF",
actual = test_dat$active,
predicted = ifelse(predict(rf.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Predict with RF model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(rf.os.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
# ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::scale_fill_manual(values = c("#003366", "#0033FF", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Initialize empty data frame for model performance stats
perf.metrics <- NULL
# Set probability threshold for classification
prob_threshold <- .7
# Predict with logistic regression model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM",
actual = test_dat$active,
predicted = ifelse(predict(glm.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Predict with logistic regression model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "GLM (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(glm.os.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Predict with RF model
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF",
actual = test_dat$active,
predicted = ifelse(predict(rf.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Predict with RF model (SMOTE)
perf.metrics <- rbind(perf.metrics, cbind.data.frame(classifier.perf(
model = "RF (SMOTE)",
actual = test_dat$active,
predicted = ifelse(predict(rf.os.fit, test_dat, type = "response") >= prob_threshold, 1, 0))))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
# ggplot2::scale_fill_brewer(palette = "Blues", direction = -1) +
ggplot2::scale_fill_manual(values = c("#003366", "#0033FF", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
ggplot2::scale_fill_manual(values = c("#003366", "#0033FF", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
# Load library
library(ggplot2)
# Sort performance statistics in df
perf.metrics$stat_nm <- factor(perf.metrics$stat_nm, levels = c("accuracy", "sensitivity", "specificity", "precision", "neg_pred_val"))
# Visualize performance stats by model type
ggplot2::ggplot(perf.metrics,
ggplot2::aes(x = stat_nm, y = stat_vl)) +
ggplot2::labs(x = "Performance Statistic", y = "Performance Value (%)") +
ggplot2::geom_bar(aes(fill = mdl), position = "dodge", stat = "identity") +
ggplot2::theme_bw() +
ggplot2::scale_fill_manual(values = c("#003366", "#0033FF", "#0099FF", "#66CCFF")) +
ggplot2::guides(fill = guide_legend(title = "Model"))
View(perf.metrics)
# Produce variable importance plat
caret::varImpPlot(rf.fit, type = 2)
# Produce variable importance plat
randomForest::varImpPlot(rf.fit, type = 2)
?rpart
# Load library
library(dplyr)
# Load employee data
prediction_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = )
# Load library
library(rpart)
# Load employee data
prediction_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = )
View(prediction_dat)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = prediction_dat)
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
install.packages("rpart.plot", dependencies = TRUE)
library(rpart.plot)
# Load employee data
prediction_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = prediction_dat)
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = train_dat)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat)
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_os_dat)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat)
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat_os)
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat)
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat_os)
rpart.plot(tree)
?rpart
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat_os, method = "class")
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat, method = "class")
rpart.plot(tree)
# Load library
library(rpart)
library(rpart.plot)
tree <- rpart(active ~ overtime + job_lvl +  engagement + interview_rating, data = training_dat_os, method = "class")
rpart.plot(tree)
# Fill vector x with integers
x <- c(1, 2, 3, 4, 5, 100, 200, 300, 400, 500)
# Calculate average of vector x
mean(x)
# Calculate median of vector x
median(x)
# Fill vector x with integers
x <- c(1, 2, 3, 4, 5, 6, 100, 200, 300, 400, 500)
# Calculate average of vector x
mean(x)
# Fill vector x with integers
x <- c(1, 2, 3, 4, 100, 200, 300)
# Calculate average of vector x
mean(x)
# Calculate median of vector x
median(x)
# Fill vector x1 with integers
x1 <- c(1, 2, 3, 100, 200, 300)
# Calculate average and mean of vector x1
mean(x1)
median(x1)
# Calculate average and mean of vector x1
mean(x1)
median(x1)
# Fill vector x1 with integers
x1 <- c(1, 2, 3, 100, 200, 300)
# Calculate mean of vector x1
mean(x1)
# Calculate median of vector x1
median(x1)
# Fill vector x1 with integers
x1 <- c(1, 2, 3, 100, 200, 300)
# Calculate mean of vector x1
mean(x1)
# Calculate median of vector x1
median(x1)
# Create function to calculate statistical mode(s)
stat.mode <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
# Return mode(s) of vector x
stat.mode(x)
# Fill vector x with integers
x <- c(1, 2, 3, 3, 100, 200, 300)
# Calculate average of vector x
mean(x)
# Calculate median of vector x
median(x)
# Fill vector x1 with integers
x1 <- c(1, 2, 3, 100, 200, 300)
# Calculate mean of vector x1
mean(x1)
# Calculate median of vector x1
median(x1)
# Create function to calculate statistical mode(s)
stat.mode <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
# Return mode(s) of vector x
stat.mode(x)
x2 <- c(1, 2, 3, 3, 100, 200, 300, 300)
# Create function to calculate statistical mode(s)
stat.mode <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
# Return mode(s) of vector x
stat.mode(x2)
# Return lowest and highest values of vector x
range(x)
# Calculate range of vector x
max(x, na.rm = TRUE) - min(x, na.rm = TRUE)
