View(employees)
unique(employees$job_title)
unique(employees$dpt)
unique(employees$dept)
unique(employees$ed_field)
employees %>% count(ed_field, sort = TRUE)
library(dplyr)
employees %>% count(ed_field, sort = TRUE)
employees %>% count(job_title, sort = TRUE)
employees %>% count(job_title, sort = TRUE)
employees %>% count(dept, sort = TRUE)
mode(employees$dept)
mode(factor(employees$dept))
# Convert nominal categorical variable to factor
employees$dept <- factor(employees$dept)
# Convert nominal categorical variable to factor
employees$dept <- factor(employees$dept)
# Convert nominal categorical variable to factor
employees$dept <- factor(employees$dept)
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
View(employees)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.model <- multinom(dept ~ overtime + business_travel, data = employees)
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.fit <- multinom(dept ~ overtime + business_travel, data = employees)
# Produce tabular summary for model results using flextable
flextable::as_flextable(multinom.fit)
library(flextable)
# Produce tabular summary for model results using flextable
flextable::as_flextable(multinom.fit)
summary(multinom.fit)
# Summarize results in model object
exp(coef(multinom.fit))
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.fit <- multinom(dept ~ overtime + business_travel, data = employees)
# Return exponentiated coefficients from model object
exp(coef(multinom.fit))
# Calculate z-scores
z_scores <- summary(multinom.fit)$coefficients / summary(multinom.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
(1 - pnorm(abs(z_scores))) * 2
# Produce p-values
(1 - pnorm(abs(z_scores))) * 2
# Transpose and display p-values
data.frame(t(p_values))
# Transpose and display p-values
data.frame(t(round(p_values, 2)))
# Load employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Dummy code active status to 1/0
employees$active <- ifelse(employees$active == 'Yes', 1, 0)
# Fit a logistic regression model
glm.fit <- glm(active ~ interview_rating, data = employees, family = 'binomial')
# Produce tabular summary for model results using flextable
flextable::as_flextable(glm.fit)
# Fit a linear model to illustrate why this should not be done with a binary outcome
lm.fit <- lm(active ~ interview_rating, data = employees)
# Construct plots
p_lm <- ggplot2::ggplot(data = employees, aes(x = interview_rating, y = active)) +
ggplot2::geom_point(color = "grey") +
ggplot2::scale_y_continuous(breaks = c(0, .25, .50, .75, 1, 1.25)) +
ggplot2::geom_function(fun = function(x) {lm.fit$coefficients[[2]]*x + lm.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::labs(title = "Linear", x = "Interviewer Rating", y = "Active") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Create dummy-coded variable for job level 2+
employees$job_lvl2plus <- ifelse(employees$job_lvl > 1, 1, 0)
# Fit a logistic regression model
glm.fit <- glm(active ~ overtime + job_lvl2plus, data = employees, family = 'binomial')
# Produce tabular summary for model results using flextable
flextable::as_flextable(glm.fit)
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.fit <- multinom(dept ~ overtime + business_travel, data = employees)
# Summarize results from model object
summary(multinom.fit)
# Return exponentiated coefficients from model object
exp(coef(multinom.fit))
# Return exponentiated coefficients from model object
data.frame(t(exp(coef(multinom.fit))))
# Calculate z-scores
z_scores <- summary(multinom.fit)$coefficients / summary(multinom.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
# Transpose and display rounded p-values
data.frame(t(round(p_values, 3)))
View(employees)
unique(employees$job_title)
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.fit <- multinom(dept ~ job_title, data = employees)
# Summarize results from model object
summary(multinom.fit)
# Calculate z-scores
z_scores <- summary(multinom.fit)$coefficients / summary(multinom.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
# Transpose and display rounded p-values
data.frame(t(round(p_values, 3)))
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.fit <- multinom(dept ~ overtime, data = employees)
# Summarize results from model object
summary(multinom.fit)
# Calculate z-scores
z_scores <- summary(multinom.fit)$coefficients / summary(multinom.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
# Transpose and display rounded p-values
data.frame(t(round(p_values, 3)))
# Load library
library(nnet)
# Convert dept to factor
employees$dept <- factor(employees$dept)
# Specify reference level
employees$dept <- relevel(employees$dept, ref = "Human Resources")
# Fit multinomial logistic regression model
multinom.fit <- multinom(dept ~ overtime + ed_field, data = employees)
# Summarize results from model object
summary(multinom.fit)
# Calculate z-scores
z_scores <- summary(multinom.fit)$coefficients / summary(multinom.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
# Transpose and display rounded p-values
data.frame(t(round(p_values, 3)))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(exp(coef(multinom.fit))))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(round(exp(coef(multinom.fit)), 2)))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(round(exp(coef(multinom.fit))), 2)
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(round(exp(coef(multinom.fit))), 2)
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(round(exp(coef(multinom.fit)), 2))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(round(exp(coef(multinom.fit))), 2))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(round(exp(coef(multinom.fit)), 2)))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(exp(coef(multinom.fit))))
?flextable
?knit_print.flextable()
View(glm.fit)
# Calculate z-scores
z_scores <- summary(multinom.fit)$coefficients / summary(multinom.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
# Transpose and display rounded p-values
data.frame(t(round(p_values, 3)))
# Return exponentiated coefficients from model object
# Transpose rows to columns for improved readability
data.frame(t(exp(coef(multinom.fit))))
unique(employees$ed_field)
View(employees)
ggplot(employees, aes(fill=dept, y=value, x=ed_field)) +
geom_bar(position="fill", stat="identity")
# Load library
library(ggplot2)
ggplot(employees, aes(fill=dept, y=value, x=ed_field)) +
geom_bar(position="fill", stat="identity")
ggplot(employees, aes(fill=dept, y=count(employee_id), x=ed_field)) +
geom_bar(position="fill", stat="identity")
ggplot(employees, aes(x = ed_field)) +
geom_bar(position="fill", stat="identity")
ggplot(employees, aes(x = ed_field))
ggplot(employees, aes(x = ed_field)) +
geom_bar()
ggplot(employees, aes(x = ed_field, fill = dept)) +
geom_bar()
ggplot2::ggplot(employees, aes(x = ed_field, fill = dept)) +
ggplot2::geom_bar() +
ggplot2::ggplot2::theme_bw() +
ggplot2::ggplot(employees, aes(x = ed_field, fill = dept)) +
ggplot2::geom_bar() +
ggplot2::theme_bw()
ggplot2::ggplot(employees, aes(x = ifelse(ed_field == 'Human Resources', 'HR', ed_field), fill = dept)) +
ggplot2::geom_bar() +
ggplot2::theme_bw()
ggplot2::ggplot(employees, aes(x = ifelse(ed_field == 'Human Resources', 'HR', ed_field), fill = dept)) +
ggplot2::labs(xlab = 'Education Field', ylab = 'Count') +
ggplot2::geom_bar() +
ggplot2::theme_bw()
ggplot2::ggplot(employees, aes(x = ifelse(ed_field == 'Human Resources', 'HR', ed_field), fill = dept)) +
ggplot2::labs(x = 'Education Field', y = 'Count') +
ggplot2::geom_bar() +
ggplot2::theme_bw()
View(z_scores)
# Visualize distribution of educational fields by department
ggplot2::ggplot(employees, aes(x = ifelse(ed_field == 'Human Resources', 'HR', ed_field), fill = dept)) +
ggplot2::labs(x = 'Education Field', y = 'Count') +
ggplot2::guides(fill = guide_legend(title = "Department")) +
ggplot2::geom_bar() +
ggplot2::theme_bw()
# Visualize distribution of educational fields by department
ggplot2::ggplot(employees, aes(x = ifelse(ed_field == 'Human Resources', 'HR', ed_field), fill = dept)) +
ggplot2::labs(x = 'Education Field', y = 'Count') +
ggplot2::guides(fill = guide_legend(title = "Department")) +
ggplot2::geom_bar() +
ggplot2::theme_bw()
employees %>% count(ed_field, dept)
library(dplyr)
employees %>% count(ed_field, dept)
# Visualize distribution of educational fields by department
ggplot2::ggplot(employees, aes(x = overtime, fill = dept)) +
ggplot2::labs(x = 'Overtime', y = 'Count') +
ggplot2::guides(fill = guide_legend(title = "Department")) +
ggplot2::geom_bar() +
ggplot2::theme_bw()
employees %>% count(dept)
employees |> count(dept)
employees |> count(dept)
(4.43 - 1) * 100
(1.74 - 1) * 100
# Load employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Dummy code active status to 1/0
employees$active <- ifelse(employees$active == 'Yes', 1, 0)
# Fit a logistic regression model
glm.fit <- glm(active ~ interview_rating, data = employees, family = 'binomial')
# Produce tabular summary for model results using flextable
flextable::as_flextable(glm.fit)
View(employees)
# Define ordered factor
employees$engagement <- ordered(employees$engagement, levels = c(1, 2, 3, 4, 5))
str(employees$engagement)
?str
View(glm.fit)
View(employees)
?poly
# Fit a ordinal logistic regression model
ord.fit <- poly(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Load library
library(MASS)
# Fit a ordinal logistic regression model
ord.fit <- poly(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Fit a ordinal logistic regression model
ord.fit <- poly(engagement ~ org_tenure, data = employees)
# Fit a ordinal logistic regression model
ord.fit <- poly(engagement ~ as.factor(org_tenure), data = employees, Hess = TRUE)
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Summarize model results
summary(ord.fit)
?polr
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees)
# Summarize model results
summary(ord.fit)
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Summarize model results
summary(ord.fit)
library(brant)
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Summarize model results
summary(ord.fit)
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Test proportional odds assumption using Brant's test
brant(ord.fit)
# Load library
library(MASS)
library(brant)
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Test proportional odds assumption using Brant's test
brant(ord.fit)
x = c(1, 2, 3)
poly(x, 2)
?mode
?str
# Load employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Dummy code active status to 1/0
employees$active <- ifelse(employees$active == 'Yes', 1, 0)
# Fit a logistic regression model
glm.fit <- glm(active ~ interview_rating, data = employees, family = 'binomial')
# Produce tabular summary for model results using flextable
flextable::as_flextable(glm.fit)
# Summarize ordinal logistic regression model
summary(ord.fit)
# Define ordered factor
employees$engagement <- ordered(employees$engagement, levels = c(1, 2, 3, 4, 5))
# Verify structure of engagement variable
str(employees$engagement)
# Load library
library(MASS)
library(brant)
# Fit a ordinal logistic regression model
ord.fit <- polr(engagement ~ org_tenure, data = employees, Hess = TRUE)
# Test proportional odds assumption using Brant's test
brant(ord.fit)
# Summarize ordinal logistic regression model
summary(ord.fit)
?poly
x = c(1, 2, 3)
poly(x, 2)
poly(x, degree = 2)
?str
View(employees)
# Calculate z-scores
z_scores <- summary(ord.fit)$coefficients / summary(ord.fit)$standard.errors
# Produce p-values
p_values <- (1 - pnorm(abs(z_scores))) * 2
# Transpose and display rounded p-values
data.frame(t(round(p_values, 3)))
summary(ord.fit)$coefficients
coef_df <- coef(summary(ord.fit))
p <- pnorm(abs(coef_df[, "t value"]), lower.tail = FALSE) * 2
coef_df <- cbind(coef_df, "p value" = p)
coef_df
# Transpose and display rounded p-values
data.frame(t(round(coef_df, 3)))
coef_df
coef(summary(ord.fit))
coef(summary(ord.fit))
summary(ord.fit)
# Load library
library(equatiomatic)
# Convert model to LaTex regression equation
extract_eq(ord.fit)
round(-.0069, 3)
# Load library
library(dplyr)
# Load employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Subset employees data frame; leads are only applicable for those in sales positions
data <- subset(employees, job_title %in% c('Sales Executive', 'Sales Representative'))
# Regress YTD leads on engagement
slm.fit <- lm(ytd_leads ~ engagement, data)
# Set seed for reproducibility
set.seed(1234)
# Simulate n observations
n <- 20
X <- runif(n, 0, 5)
Y <- 1 + 3*X + rnorm(n, 0, 1)
df.orig <- data.frame(X = X, Y = Y)
# Model data
model <- lm(Y ~ X)
summary(model)
# Visualize model fit to observations
p1 <- ggplot2::ggplot(data = df.orig, aes(x = X, y = Y)) +
ggplot2::geom_point() +
ggplot2::geom_function(fun = function(x) {model$coefficients[[2]]*x + model$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(axis.title.y = element_text(face = "italic"), axis.title.x = element_text(face = "italic"))
# Square root transformation of YTD leads
slm.fit.trans <- lm(sqrt(ytd_leads) ~ engagement, data)
# Natural logarithmic transformation of YTD leads
slm.fit.trans <- lm(log(ytd_leads) ~ engagement, data)
# Scale variables and store standardized data in new data frame
data_std = data.frame(scale(subset(data, select = (c(ytd_sales, engagement, job_lvl, stock_opt_lvl, org_tenure)))))
# Refit model using scaled variables
mlm.fit.scaled <- lm(ytd_sales ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_std)
# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.scaled)
# Partition data into overtime and non-overtime groups
data_ot <- subset(data, overtime == 'Yes')
data_nonot <- subset(data, overtime == 'No')
# Regress transformed YTD sales on a combination of predictors for overtime and non-overtime groups
mlm.fit.ot <- lm(sqrt(ytd_sales) ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_ot)
mlm.fit.nonot <- lm(sqrt(ytd_sales) ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_nonot)
# Regress transformed YTD sales on a combination of predictors for overtime and non-overtime groups
mlm.fit.ot <- lm(sqrt(ytd_sales) ~ job_lvl + stock_opt_lvl + org_tenure, data_ot)
# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.ot)
# Regress transformed YTD sales on a combination of predictors for overtime and non-overtime groups
mlm.fit.ot <- lm(sqrt(ytd_sales) ~ engagement + job_lvl + stock_opt_lvl + org_tenure, data_ot)
# Produce tabular summary with standardized coefficients
flextable::as_flextable(mlm.fit.ot)
# Load library
library(lme4)
lme.fit <- lme4::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
library(lme4, dependencies = TRUE)
install.packages(lme4, dependencies = TRUE)
install.packages(c("tidyverse", "corrplot", "psych", "moments", "ggpubr", "GGally", "sqldf", "caret", "car", "reshape2", "flextable", "lmtest", "equatiomatic", "pwr", "nnet", "MASS", "brant", "lme4"), dependencies = TRUE, repos = "http://cran.us.r-project.org")
install.packages(c("tidyverse", "corrplot", "psych", "moments", "ggpubr", "GGally", "sqldf", "caret", "car", "reshape2", "flextable", "lmtest", "equatiomatic", "pwr", "nnet", "MASS", "brant", "lme4"), dependencies = TRUE, repos = "http://cran.us.r-project.org")
install.packages(c("tidyverse", "corrplot", "psych", "moments", "ggpubr", "GGally", "sqldf", "caret", "car", "reshape2", "flextable", "lmtest", "equatiomatic", "pwr", "nnet", "MASS", "brant", "lme4"), dependencies = TRUE, repos = "http://cran.us.r-project.org")
# Load library
library(lme4)
lme.fit <- lme4::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
# Load library
library(lme4)
lme4::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
summary(lme.fit)
# Load library
library(lme4)
# Fit linear mixed model
lme.fit <- lme4::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
# Summarize model results
summary(lme.fit)
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/data_scientist_tasks.jpeg")
View(data_nonot)
# Load library
library(lme4)
# Fit linear mixed model
lme.fit <- lme4::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
# Summarize model results
summary(lme.fit)
anova(lme.fit)
install.packages("lmerTest", dependencies = TRUE)
library(lmerTest)
# Fit linear mixed model
lme.fit <- lme4::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
# Summarize model results
summary(lme.fit)
anova(lme.fit)
# Fit linear mixed model
lme.fit <- lmerTest::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
# Summarize model results
summary(lme.fit)
# Load library
library(lmerTest)
# Fit linear mixed model
lme.fit <- lmerTest::lmer(sqrt(ytd_sales) ~ engagement + job_lvl + (1 | stock_opt_lvl) + org_tenure, data_ot)
# Summarize model results
summary(lme.fit)
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/data_scientist_tasks.jpeg")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/research_designs.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/bias_variance_tradeoff.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/bias_variance_tradeoff.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/confusion_matrix.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/confusion_matrix.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/confusion_matrix.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/confusion_matrix.png")
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/confusion_matrix.png")
# Load library
library(dplyr)
# Load employee data
turnover <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
View(turnover)
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/decision_tree.png")
View(turnover)
summary(turnover$active)
turnover[turnover$active == 'Yes', ]
nrow(turnover[turnover$active == 'Yes', ])
nrow(turnover[turnover$active == 'No', ])
?SMOTE
library(caret)
?SMOTE
install.packages("DMwR", dependencies = TRUE)
# Load employee data
prediction_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Randomly select 2/3 of employees for the training set
training_ids <- sample(prediction_dat$employee_id, size = nrow(prediction_dat) * 2/3, replace = FALSE)
# Create training data
training_dat <- prediction_dat %>% filter(employee_id %in% training_ids)
# Load library
library(dplyr)
# Load employee data
prediction_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Randomly select 2/3 of employees for the training set
training_ids <- sample(prediction_dat$employee_id, size = nrow(prediction_dat) * 2/3, replace = FALSE)
# Create training data
training_dat <- prediction_dat %>% filter(employee_id %in% training_ids)
# Create test data using remaining observations
test_dat <- prediction_dat %>% filter(!employee_id %in% training_ids)
490 + 980
nrow(training_dat) + nrow(test_dat) == nrow(prediction_dat)
# Validate all observations are accounted for
nrow(training_dat) + nrow(test_dat) == nrow(prediction_dat)
