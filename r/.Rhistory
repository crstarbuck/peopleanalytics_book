ggplot2::theme(plot.title = element_text(hjust = 0.5))
ggplot2::ggplot(test_dat, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
test_dat
ggplot2::ggplot(subset(train_dat, year == 3 & remote == 'Yes'), aes(x = month, y = turnover_rate)) +
ggplot2::geom_point()  +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 3 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*3 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
ggplot2::ggplot(subset(train_dat, year == 4 & remote == 'Yes'), aes(x = month, y = turnover_rate)) +
ggplot2::geom_point()  +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 3 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*4 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Load library
library(dplyr)
# Load employee data
forecasting_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/turnover_trends.csv")
# Create training data
train_dat <- forecasting_dat %>% filter(job == 'People Scientist' & level == 1 & year %in% 1:4)
# Create test data
test_dat <- forecasting_dat %>% filter(job == 'People Scientist' & level == 1 & remote == 'Yes' & year == 5)
# Fit cubic model
train.cube.fit <- lm(turnover_rate ~ year + month + I(month^2) + I(month^3) + remote, data = train_dat)
# Produce tabular summary of regression model output
flextable::as_flextable(train.cube.fit)
# Forecast error rates
forecast.perf(actual = forecast.metrics$actual, predicted = forecast.metrics$predicted)
ggplot2::ggplot(subset(train_dat, year == 4 & remote == 'Yes'), aes(x = month, y = turnover_rate)) +
ggplot2::geom_point()  +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 4 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*4 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
train_dat[train_dat$year == 1, 'turnover_rate']
mean(train_dat[train_dat$year == 1, 'turnover_rate'])
mean(train_dat[train_dat$year == 2, 'turnover_rate'])
mean(train_dat[train_dat$year == 3, 'turnover_rate'])
mean(train_dat[train_dat$year == 4, 'turnover_rate'])
mean(train_dat[train_dat$year == 5, 'turnover_rate'])
mean(forecasting_dat[forecasting_dat$job == 'People Scientist' & forecasting_dat$level == 1 & forecasting_dat$remote == 'Yes' & forecasting_dat$year == 5, 'turnover_rate'])
mean(forecasting_dat[forecasting_dat$job == 'People Scientist' & forecasting_dat$level == 1 & forecasting_dat$remote == 'Yes' & forecasting_dat$year == 1, 'turnover_rate'])
mean(forecasting_dat[forecasting_dat$job == 'People Scientist' & forecasting_dat$level == 1 & forecasting_dat$remote == 'Yes' & forecasting_dat$year == 2, 'turnover_rate'])
mean(forecasting_dat[forecasting_dat$job == 'People Scientist' & forecasting_dat$level == 1 & forecasting_dat$remote == 'Yes' & forecasting_dat$year == 3, 'turnover_rate'])
mean(forecasting_dat[forecasting_dat$job == 'People Scientist' & forecasting_dat$level == 1 & forecasting_dat$remote == 'Yes' & forecasting_dat$year == 4, 'turnover_rate'])
mean(forecasting_dat[forecasting_dat$job == 'People Scientist' & forecasting_dat$level == 1 & forecasting_dat$remote == 'Yes' & forecasting_dat$year == 5, 'turnover_rate'])
# Juxtapose year 4 turnover trend (training data) against fitted model
p_yr4 <- ggplot2::ggplot(subset(train_dat, year == 4 & remote == 'Yes'), aes(x = month, y = turnover_rate)) +
ggplot2::geom_point()  +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 4 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*4 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_polygon(aes(x = month, y = lwr_bound), fill = "red", alpha = 0.2) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_ribbon(data = forecast.metrics, aes(month, ymin = lwr_bound, ymax = upr_bound, fill = "red"), alpha = 0.4) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_ribbon(data = forecast.metrics, aes(month, ymin = lwr_bound, ymax = upr_bound, fill = "grey"), alpha = 0.4) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_ribbon(data = forecast.metrics, aes(month, ymin = lwr_bound, ymax = upr_bound), alpha = 0.4) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_ribbon(data = forecast.metrics, aes(month, ymin = lwr_bound, ymax = upr_bound, fill = "red"), alpha = 0.4) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Juxtapose year 4 turnover trend (training data) against fitted model
p_yr4 <- ggplot2::ggplot(subset(train_dat, year == 4 & remote == 'Yes'), aes(x = month, y = turnover_rate)) +
ggplot2::geom_point()  +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 4 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*4 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_ribbon(data = forecast.metrics, aes(month, ymin = lwr_bound, ymax = upr_bound, fill = "red"), alpha = 0.4) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display distribution visualizations
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
# Fit cubic model
train.cube.fit <- lm(turnover_rate ~ year + month + I(month^2) + I(month^3) + remote, data = train_dat)
# Produce tabular summary of regression model output
flextable::as_flextable(train.cube.fit)
# Subset to respective forecast segment
forecast_segment <- subset(forecasting_dat, job == 'People Scientist' & level == 1 & remote == 'Yes')
train_dat[train$dat$remote == 'Yes', 'turnover_rate']
train_dat[train$dat$remote == 'Yes', 'turnover_rate']
train_dat[train_dat$remote == 'Yes', 'turnover_rate']
mean(train_dat[train_dat$remote == 'Yes' & traindat$year == 1, 'turnover_rate'])
mean(train_dat[train_dat$remote == 'Yes' & train_dat$year == 1, 'turnover_rate'])
train_dat %>% filter(remote == 'Yes' & year == 1) %>% select(turnover_rate)
mean(train_dat[train_dat$remote == 'Yes' & train_dat$year == 1, 'turnover_rate'])
mean(train_dat %>% filter(remote == 'Yes' & year == 1) %>% select(turnover_rate))
train_dat %>% filter(remote == 'Yes' & year == 1) %>% select(turnover_rate)
train_dat %>% filter(remote == 'Yes' & year == 1) %>% summarize(Mean = mean(turnover_rate))
mean(train_dat[train_dat$remote == 'Yes' & train_dat$year == 1, 'turnover_rate'])
train_dat %>% filter(remote == 'Yes' & year == 1) %>% summarize(Mean = mean(turnover_rate))
yr1_avg <- train_dat %>% filter(remote == 'Yes' & year == 1) %>% summarize(Mean = mean(turnover_rate))
yr2_avg <- train_dat %>% filter(remote == 'Yes' & year == 2) %>% summarize(Mean = mean(turnover_rate))
yr3_avg <- train_dat %>% filter(remote == 'Yes' & year == 3) %>% summarize(Mean = mean(turnover_rate))
yr4_avg <- train_dat %>% filter(remote == 'Yes' & year == 4) %>% summarize(Mean = mean(turnover_rate))
yr5_avg <- test_dat %>% summarize(Mean = mean(turnover_rate))
print(c(yr1_avg, yr2_avg, yr3_avg, yr4_avg, yr5_avg))
# Juxtapose year 4 turnover trend (training data) against fitted model
p_yr4 <- ggplot2::ggplot(subset(train_dat, year == 4 & remote == 'Yes'), aes(x = month, y = turnover_rate)) +
ggplot2::geom_point()  +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 4 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*4 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Juxtapose year 5 turnover trend (test data) against fitted model
p_yr5 <- ggplot2::ggplot(forecast.metrics, aes(x = month, y = actual)) +
ggplot2::geom_point() +
ggplot2::scale_x_continuous(breaks = 1:12) +
ggplot2::labs(title = "Year 5 Turnover Trend", x = "Month", y = "Turnover Rate") +
ggplot2::geom_function(fun = function(x) {train.cube.fit$coefficients[[2]]*5 + train.cube.fit$coefficients[[3]]*x + train.cube.fit$coefficients[[4]]*x^2 + train.cube.fit$coefficients[[5]]*x^3 + train.cube.fit$coefficients[[6]] + train.cube.fit$coefficients[[1]]}, colour = "red", linetype = "dashed") +
ggplot2::geom_ribbon(data = forecast.metrics, aes(month, ymin = lwr_bound, ymax = upr_bound, fill = "red"), alpha = 0.4) +
ggplot2::theme_bw() +
ggplot2::theme(legend.position = "none") +
ggplot2::theme(plot.title = element_text(hjust = 0.5))
# Display visuals side-by-side
ggpubr::ggarrange(p_yr4, p_yr5, ncol = 2, nrow = 1)
library(dplyr)
set.seed(123)
# create the variance covariance matrix
sigma <- rbind(c(1,-0.8,-0.7), c(-0.8,1, 0.9), c(-0.7,0.9,1))
# create the mean vector
mu <- c(3, 3.2, 3.4)
# generate the multivariate normal distribution
df <- as.data.frame(mvrnorm(n = 1000, mu = mu, Sigma = sigma))
library(MASS)
# generate the multivariate normal distribution
df <- as.data.frame(mvrnorm(n = 1000, mu = mu, Sigma = sigma))
View(df)
max(df$V1)
n <- 1000
correlations <- replicate(n = 1000, expr = cor(ordsample(n, Marginal, R))[1,2])
library(ordsample)
?ordsample
correlations <- replicate(n = 1000, expr = cor(ordsample(n, Marginal, R))[1,2])
?corrvar
read.csv(file.choose(), header = T)
data <- read.csv(file.choose(), header = T)
data <- data[complete.cases(data), ]
View(data)
write.csv(data, "/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/factor_analysis.csv", row.names = FALSE)
knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/stats_ml_satire.png")
# Load library
library(dplyr)
# Load employee data
prediction_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
View(prediction_dat)
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
View(survey_dat)
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(lavaan)
install.packages("lavaan", dependencies = TRUE)
install.packages("lavaan", dependencies = TRUE)
# Load library
library(lavaan)
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- ' engagement =~ engagement_1 + engagement_2 + engagement_3
# Load library
library(lavaan)
# Load library
library(lavaan)
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- ' engagement =~ engagement_1 + engagement_2 + engagement_3
cfa.fit <- cfa(model, data = pcafit)
summary(cfa.fit, fit.measures = TRUE)
# Load library
library(lavaan)
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- ' engagement =~ engagement_1 + engagement_2 + engagement_3
model <- ' engagement =~ engagement_1 + engagement_2 + engagement_3
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- '
# Load library
library(lavaan)
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- ' engagement =~ engagement_1 + engagement_2 + engagement_3
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- ` engagement =~ engagement_1 + engagement_2 + engagement_3
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- " engagement =~ engagement_1 + engagement_2 + engagement_3
model <- ' engagement =~ engagement_1 + engagement_2 + engagement_3
retention =~ retention_1 + retention_2 + retention_3 '
model
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- paste(' engagement =~ engagement_1 + engagement_2 + engagement_3
retention =~ retention_1 + retention_2 + retention_3 ')
model
cfa.fit <- cfa(model, data = pcafit)
cfa.fit <- cfa(model, data = survey_dat)
summary(cfa.fit, fit.measures = TRUE)
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- paste(engagement =~ engagement_1 + engagement_2 + engagement_3
retention =~ retention_1 + retention_2 + retention_3 )
# Specify model with hypothesized relationships between items and factors
# Each line represents a separate latent factor
model <- paste('engagement =~ engagement_1 + engagement_2 + engagement_3
retention =~ retention_1 + retention_2 + retention_3')
# Fit and summarize the model
cfa.fit <- cfa(model, data = survey_dat)
summary(cfa.fit, fit.measures = TRUE)
# Load library
library(ggally)
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(survey_dat)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("engagement_1", "engagement_2", "engagement_3", "retention_1", "retention_2", "retention_3")))
View(survey_dat)
names(survey_dat$engagement_1) <- "eng_1"
View(survey_dat)
names(survey_dat)['engagement_1'] <- "eng_1"
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("engagement_1", "engagement_2", "engagement_3", "retention_1", "retention_2", "retention_3")))
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Visualize path diagram
graph_sem(model = cfa.fit)
library(tidySEM)
install.packages("tidySEM", dependencies = TRUE)
install.packages("tidySEM", dependencies = TRUE)
install.packages("tidySEM", dependencies = TRUE)
install.packages("tidySEM", dependencies = TRUE)
# Load library
library(tidySEM)
# Load library
library(tidySEM)
install.packages("lavaanPlot", dependencies = TRUE)
# Load library
library(lavaanPlot)
# Visualize path diagram
lavaanPlot(model = fit1, labels = labels1, coefs = TRUE, stand = TRUE, sig = 0.05)
# Visualize path diagram
lavaanPlot(model = cfa.fit, labels = labels1, coefs = TRUE, stand = TRUE, sig = 0.05)
# Visualize path diagram
lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE, sig = 0.05)
# Visualize path diagram
lavaanPlot::lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE)
# Load library
library(dplyr)
# Load survey response data
survey_dat <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_responses.csv")
# Show dimensions of survey data
dim(survey_dat)
# Load library
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3")))
# Load library
library(lavaan)
# Model specification; each line represents a separate latent factor
model <- paste('engagement =~ eng_1 + eng_2 + eng_3
retention =~ ret_1 + ret_2 + ret_3')
# Load library
library(lavaan)
# Model specification; each line represents a separate latent factor
model <- paste('engagement =~ eng_1 + eng_2 + eng_3
retention =~ ret_1 + ret_2 + ret_3')
# Fit the model
cfa.fit <- lavaan::cfa(model, data = survey_dat)
# Load library
library(lavaanPlot)
# Visualize path diagram
lavaanPlot::lavaanPlot(model = cfa.fit, coefs = TRUE, stand = TRUE)
# Summarize the model
summary(cfa.fit, fit.measures = TRUE)
libary(factanal)
install.packages("factanal", dependencies = TRUE)
View(survey_dat)
# Fit model using three factors and varimax factor rotation
efa.fit <- factanal(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), 3, rotation = 'varimax')
# Load library
library(factanal)
# Load library
library(factanal)
library(psych)
# Load library
library(factanal)
# Fit model using three factors and varimax factor rotation
efa.fit <- factanal(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), 3, rotation = 'varimax')
load <- efa.fit$loadings[,1:2]
load
install.packages("stats", dependencies = TRUE)
install.packages("stats", dependencies = TRUE)
install.packages("stats", dependencies = TRUE)
install.packages("stats", dependencies = TRUE)
# Load library
library(stats)
# Fit model using three factors and varimax factor rotation
efa.fit <- stats::factanal(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), 3, rotation = 'varimax')
load <- efa.fit$loadings[,1:2]
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotation = 'varimax')
# Load library
library(psych)
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotation = 'varimax')
?factor.pa
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3)
load <- efa.fit$loadings[,1:2]
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::factor.pa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotate = 'varimax')
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::fa(subset(survey_dat, select = c("eng_1", "eng_2", "eng_3", "ret_1", "ret_2", "ret_3", "culture")), nfactors = 3, rotate = 'varimax')
efa.fit
# Principal axis factoring using three factors and varimax rotation
efa.fit <- psych::fa(survey_dat, nfactors = 3, rotate = 'varimax')
eigen(cor(survey_dat))
# Load library
library(nFactors)
install.packages("nFactors", dependencies = TRUE)
# Load library
library(nFactors)
# Load library
library(nFactors)
ap <- parallel(subject = nrow(survey_dat),var = ncol(survey_dat), rep = 100,cent = .05)
ap
ns <- nFactors::nScree(x = ev$values, aparallel = ap$eigen$qevpea)
# Retrieve eigenvalues
ev <- eigen(cor(survey_dat))
ap <- parallel(subject = nrow(survey_dat),var = ncol(survey_dat), rep = 100, cent = .05)
ns <- nFactors::nScree(x = ev$values, aparallel = ap$eigen$qevpea)
plotnScree(ns)
?bartlett.test
psych::KMO(survey_dat)
# Bartlett's Test of Sphericity
psych::cortest.bartlett(cor(survey_dat), nrow(survey_dat))
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Load library
library(ggplot2)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Create scree plot
ggplot2::qplot(c(1:4), var_explained) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Perform PCA
pca <- prcomp(survey_dat, scale = TRUE)
# Calculate explained variance for each principal component
pca_var = pca$sdev^2 / sum(pca$sdev^2)
# Create scree plot
ggplot2::qplot(c(1:4), var_explained) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Create scree plot
ggplot2::qplot(c(1:4), pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
?qplot
# Create scree plot
qplot(c(1:4), pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
# Create scree plot
ggplot2::qplot(pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
pca_var
# Create scree plot
ggplot2::qplot(pca, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
pca
length(pca)
nrow(pca)
# Create scree plot
ggplot2::qplot(1:19, pca_var) +
ggplot2::geom_line() +
ggplot2::xlab("Principal Component") +
ggplot2::ylab("Variance Explained") +
ggplot2::ylim(0, 1)
