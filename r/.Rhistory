aes(data) +
labs(title = paste(title), x = "x", y = "density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
}
return(viz)
}
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
p_binomial <- dist.viz(data = binomial_dist, type = "discrete", title = "Binomial")
p_nbinomial <- dist.viz(data = nbinomial_dist, type = "discrete", title = "Negative Binomial")
p_multinomial <- dist.viz(data = multinomial_dist, type = "discrete", title = "Multinomial")
p_poisson <- dist.viz(data = poisson_dist, type = "discrete", title = "Poisson")
p_geometric <- dist.viz(data = geometric_dist, type = "discrete", title = "Geometric")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Simulate chi-square distribution
chisq_dist <- rchisq(1000, df = 5)
# Simulate F distribution
f_dist <- rf(1000, df1 = 5, df2 = 200)
# Call UDF to build visualizations and store to objects
# Note that as long as the arguments are in the order specified in the function (see our UDF definition above), the argument names do not need to be specified. To illustrate, we will drop the argument names from these function calls:
p_normal <- dist.viz(normal_dist, "continuous", "Normal")
p_lnormal <- dist.viz(lnormal_dist, "continuous", "Log-Normal")
p_uniform <- dist.viz(uniform_dist, "continuous", "Uniform")
p_t <- dist.viz(t_dist, "continuous", "Student's T")
p_chisq <- dist.viz(chisq_dist, "continuous", "Chi-Square")
p_f <- dist.viz(f_dist, "continuous", "F")
# Display distribution visualizations
ggpubr::ggarrange(p_normal, p_lnormal, p_uniform, p_t, p_chisq, p_f,
ncol = 3, nrow = 2)
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# For each n, draw random samples
for (n in sample_n) {
for (draw in 1:samples) {
# Store sample means in data frame
sample_means <- rbind(sample_means, cbind.data.frame(
n = n,
x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
}
}
# Generate uniform population distribution with 1000 values ranging from 1 to 100
rand.unif <- runif(1000, min = 1, max = 100)
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# For each n, draw random samples
for (n in sample_n) {
for (draw in 1:samples) {
# Store sample means in data frame
sample_means <- rbind(sample_means, cbind.data.frame(
n = n,
x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
}
}
?cliff_delta()
?cliff.delta()
?subset
# Create three vectors containing integers (x), characters (y), and dates (z)
x <- 1:10
y <- c('a','b','c','d','e','f','g','h','i','j')
z <- seq(as.Date("2021-01-01"), as.Date("2021-10-01"), by = 'months')
# Create a data frame with 3 columns (vectors x, y, and z) and 10 rows
df <- data.frame(x, y, z)
df
# Return data in column x in df
df$x
View(df)
subset(df, x >= 7 | y == c('a','b','c'), select = c(z))
df[df$x >= 7 | df$y == c('a','b','c'), "z"]
df[df$x >= 7 | df$y %in% c('a','b','c'), "z"]
subset(df, x >= 7 | y == c('a','b','c'), select = z)
# Load library for data wrangling
library(dplyr)
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Calculate sample variance for annual compensation
var(employees$annual_comp)
# Generate a covariance matrix among select continuous variables
cov(subset(employees, select = c("annual_comp", "age", "org_tenure", "job_tenure", "prior_emplr_cnt", "commute_dist")), use = "complete.obs")
# Generate a correlation matrix among select continuous variables
cor(subset(employees, select = c("annual_comp", "age", "org_tenure", "job_tenure", "prior_emplr_cnt", "commute_dist")), use = "complete.obs")
# Store correlation matrix to object M
M <- cor(subset(employees, select = c("annual_comp", "age", "org_tenure", "job_tenure", "prior_emplr_cnt", "commute_dist")), use = "complete.obs")
# Visualize correlation matrix
corrplot::corrplot.mixed(M, order = 'AOE')
# Visualize correlation matrix
GGally::ggpairs(subset(employees, select = c("annual_comp", "age", "org_tenure", "job_tenure", "prior_emplr_cnt", "commute_dist")))
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# Store sample means with n = 50
x_bars <- sample_means[sample_means$n == 50, "x_bar"]
# Store sample size
n <- length(x_bars)
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Simulate chi-square distribution
chisq_dist <- rchisq(1000, df = 5)
# Simulate F distribution
f_dist <- rf(1000, df1 = 5, df2 = 200)
# Call UDF to build visualizations and store to objects
# Note that as long as the arguments are in the order specified in the function (see our UDF definition above), the argument names do not need to be specified. To illustrate, we will drop the argument names from these function calls:
p_normal <- dist.viz(normal_dist, "continuous", "Normal")
# Set seed for reproducible random distribution
set.seed(1234)
# Generate uniform population distribution with 1000 values ranging from 1 to 100
rand.unif <- runif(1000, min = 1, max = 100)
# Calculate population mean
mean(rand.unif)
# Calculate population variance
N = length(rand.unif)
var(rand.unif) * (N - 1) / N
# Produce histogram to visualize population distribution
ggplot2::ggplot() +
aes(rand.unif) +
labs(x = "x", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Produce descriptive stats for org tenure
summary(employees$org_tenure)
# Visualize org tenure distribution
ggplot2::ggplot() +
aes(employees$org_tenure) +
labs(x = "Org Tenure", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
labs(x = "Org Tenure", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
library(ggplot2)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate bernoulli distribution
bernoulli_dist <- rbinom(1000, 1, prob = .5)
# Simulate binomial distribution
# Notice the important difference relative to the Bernoulli simulation (100 trials vs. 1)
binomial_dist <- rbinom(1000, 100, prob = .5)
# Simulate negative binomial distribution
nbinomial_dist <- rnbinom(1000, 100, prob = .5)
# Simulate multinomial distribution with varying probabilities per level
multinomial_dist <- rmultinom(1000, 4, prob = c(.4, .3, .2, .6))
# Simulate poisson distribution
poisson_dist <- rpois(1000, 10)
# Simulate geometric distribution
geometric_dist <- rgeom(1000, prob = .2)
# Create user-defined function (UDF) to simplify probability distribution visualization
# Function arguments: (1) data = object containing random distribution values; (2) type = 'discrete' or 'continuous' probability distribution; and (3) title = name of distribution
dist.viz <- function(data, type, title) {
if (type == "discrete"){
# Discrete distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "count") +
geom_histogram(fill = "#414141") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
} else {
# Continuous distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
}
return(viz)
}
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
p_binomial <- dist.viz(data = binomial_dist, type = "discrete", title = "Binomial")
p_nbinomial <- dist.viz(data = nbinomial_dist, type = "discrete", title = "Negative Binomial")
p_multinomial <- dist.viz(data = multinomial_dist, type = "discrete", title = "Multinomial")
p_poisson <- dist.viz(data = poisson_dist, type = "discrete", title = "Poisson")
p_geometric <- dist.viz(data = geometric_dist, type = "discrete", title = "Geometric")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Simulate chi-square distribution
chisq_dist <- rchisq(1000, df = 5)
# Simulate F distribution
f_dist <- rf(1000, df1 = 5, df2 = 200)
# Call UDF to build visualizations and store to objects
# Note that as long as the arguments are in the order specified in the function (see our UDF definition above), the argument names do not need to be specified. To illustrate, we will drop the argument names from these function calls:
p_normal <- dist.viz(normal_dist, "continuous", "Normal")
p_lnormal <- dist.viz(lnormal_dist, "continuous", "Log-Normal")
p_uniform <- dist.viz(uniform_dist, "continuous", "Uniform")
p_t <- dist.viz(t_dist, "continuous", "Student's T")
p_chisq <- dist.viz(chisq_dist, "continuous", "Chi-Square")
p_f <- dist.viz(f_dist, "continuous", "F")
# Display distribution visualizations
ggpubr::ggarrange(p_normal, p_lnormal, p_uniform, p_t, p_chisq, p_f,
ncol = 3, nrow = 2)
# Set seed for reproducible random distribution
set.seed(1234)
# Generate uniform population distribution with 1000 values ranging from 1 to 100
rand.unif <- runif(1000, min = 1, max = 100)
# Calculate population mean
mean(rand.unif)
# Calculate population variance
N = length(rand.unif)
var(rand.unif) * (N - 1) / N
# Produce histogram to visualize population distribution
ggplot2::ggplot() +
aes(rand.unif) +
labs(x = "x", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# Store sample means with n = 50
x_bars <- sample_means[sample_means$n == 50, "x_bar"]
# Store sample size
n <- length(x_bars)
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# For each n, draw random samples
for (n in sample_n) {
for (draw in 1:samples) {
# Store sample means in data frame
sample_means <- rbind(sample_means, cbind.data.frame(
n = n,
x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
}
}
# Produce histograms to visualize distributions of sample means, grouped by n-count
sample_means %>% ggplot2::ggplot() +
aes(x = x_bar, fill = n) +
labs(x = "x-bar", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
facet_wrap(~n)
# Store sample means with n = 50
x_bars <- sample_means[sample_means$n == 50, "x_bar"]
# Store sample size
n <- length(x_bars)
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
subset(x_bars, x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars))
length(subset(x_bars, x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars))) / n * 100
# Calculate percent of sample means within +/- 2 SEs
length(x_bars[x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars)]) / n * 100
length(subset(x_bars, x_bars < mean(x_bars) + 2 * sd(x_bars) & x_bars > mean(x_bars) - 2 * sd(x_bars))) / n * 100
length(subset(x_bars, x_bars < mean(x_bars) + 3 * sd(x_bars) & x_bars > mean(x_bars) - 3 * sd(x_bars))) / n * 100
# Calculate percent of sample means within +/- 3 SEs
length(x_bars[x_bars < mean(x_bars) + 3 * sd(x_bars) & x_bars > mean(x_bars) - 3 * sd(x_bars)]) / n * 100
length(subset(x_bars, x_bars < mean(x_bars) + 3 * sd(x_bars) & x_bars > mean(x_bars) - 3 * sd(x_bars))) / n * 100
# Load data sets
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
status <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/status.csv")
benefits <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/benefits.csv")
demographics <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/demographics.csv")
job <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/job.csv")
payroll <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/payroll.csv")
performance <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/performance.csv")
prior_employment <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/prior_employment.csv")
survey_response <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_response.csv")
tenure <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/tenure.csv")
# Return row and column counts
dim(employees)
# Store original annual comp for sample employee
orig_comp <- employees[employees$employee_id == '2176', 'annual_comp']
subset(employees, employee_id = '2176', select = annual_comp)
subset(employees, employee_id == '2176', select = annual_comp)
employees[employees$employee_id == '2176', 'annual_comp']
subset(employees, employee_id == '2176', select = annual_comp)
subset(employees, is.na(annual_comp), select = c(employee_id, job_title, job_lvl))
# Return relevant employee characteristics where annual comp is missing
employees[is.na(employees$annual_comp), c("employee_id", "job_title", "job_lvl")]
# Force a NA in lieu of annual comp for illustrative purposes
employees[employees$employee_id == '2176', 'annual_comp'] <- NA
# Return relevant employee characteristics where annual comp is missing
employees[is.na(employees$annual_comp), c("employee_id", "job_title", "job_lvl")]
subset(employees, is.na(annual_comp), select = c(employee_id, job_title, job_lvl))
# Load data sets
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
status <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/status.csv")
benefits <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/benefits.csv")
demographics <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/demographics.csv")
job <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/job.csv")
payroll <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/payroll.csv")
performance <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/performance.csv")
prior_employment <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/prior_employment.csv")
survey_response <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_response.csv")
tenure <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/tenure.csv")
# Return row and column counts
dim(employees)
# Store original annual comp for sample employee
orig_comp <- subset(employees, employee_id == '2176', select = annual_comp)
subset(employees, employee_id == '2176', select = annual_comp) <- NA
employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
test = subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
test
View(test)
mean(test, na.rm = TRUE)
mean(as.numeric(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)), na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
ubset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' && job_lvl == 2, select = annual_comp)
mean(subset(employees, job_title == 'Manufacturing Director' && job_lvl == 2, select = annual_comp), na.rm = TRUE)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp)
mode(test)
class(test)
str(test)
test2 = employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp']
str(test1)
str(test2)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
mean(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), na.rm = TRUE)
test
test1
test2
mean(test)
apply(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), mean)
sapply(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), mean, na.rm = TRUE)
mean(employees[employees$job_title == 'Manufacturing Director' & employees$job_lvl == 2, 'annual_comp'], na.rm = TRUE)
subset(employees, employee_id == '2176', select = annual_comp)
employees[employees$employee_id == '2176', 'annual_comp']
# Display absolute difference between original and imputed comp
abs(orig_comp - subset(employees, employee_id == '2176', select = annual_comp))
# Impute missing comp for relevant segment
employees[employees$employee_id == '2176', 'annual_comp'] <- imputed_comp
# Return average annual comp for employees with similar characteristics, excluding employees with missing comp values
imputed_comp <- sapply(subset(employees, job_title == 'Manufacturing Director' & job_lvl == 2, select = annual_comp), mean, na.rm = TRUE)
# Impute missing comp for relevant segment
employees[employees$employee_id == '2176', 'annual_comp'] <- imputed_comp
# Display absolute difference between original and imputed comp
abs(orig_comp - subset(employees, employee_id == '2176', select = annual_comp))
# Display absolute difference between original and imputed comp
round(abs(orig_comp - subset(employees, employee_id == '2176', select = annual_comp)), 0)
# Gender one-hot encoding
employees$gender_ohe <- ifelse(employees$gender == 'Female', 1, 0)
subset(employees, select = c(employee_id, gender_ohe))
head(subset(employees, select = c(employee_id, gender_ohe)))
# Preview records
head(employees[, c("employee_id", "gender_ohe")])
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Produce descriptive stats for org tenure
summary(employees$org_tenure)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
#Load library
library(ggplot2)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
ggplot2::labs(x = "Education Level", y = "Annual Compensation") +
ggplot2::theme_bw() +
ggplot2::geom_boxplot()
# Load library
library(ggplot2)
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
ggplot2::labs(x = "Education Level", y = "Annual Compensation") +
ggplot2::theme_bw() +
ggplot2::geom_boxplot()
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Calculate sample variance for annual compensation
var(employees$annual_comp)
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
ggplot2::labs(x = "Education Level", y = "Annual Compensation") +
ggplot2::theme_bw() +
ggplot2::geom_boxplot()
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Produce descriptive stats for org tenure
summary(employees$org_tenure)
# Visualize org tenure distribution
ggplot2::ggplot() +
ggplot2::aes(employees$org_tenure) +
ggplot2::labs(x = "Org Tenure", y = "Density") +
ggplot2::geom_histogram(aes(y = ..density..), fill = "#414141") +
ggplot2::geom_density(fill = "#ADD8E6", alpha = 0.6) +
ggplot2::theme_bw()
