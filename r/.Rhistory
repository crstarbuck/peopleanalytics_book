job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(org_tenure), 2) AS avg_org_tenure
ROUND(AVG(commute_dist), 2) AS avg_commute_dist
FROM
demographics
INNER JOIN
tenure
ON
demographics.employee_id = tenure.employee_id
INNER JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(org_tenure), 2) AS avg_org_tenure,
ROUND(AVG(commute_dist), 2) AS avg_commute_dist
FROM
demographics
INNER JOIN
tenure
ON
demographics.employee_id = tenure.employee_id
INNER JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(org_tenure), 2) AS avg_org_tenure,
ROUND(AVG(commute_dist), 2) AS avg_commute_dist
FROM
demographics
LEFT JOIN
tenure
ON
demographics.employee_id = tenure.employee_id
LEFT JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
# Note: Since employee_id exists in multiple data sets, we must name a specific data set when referencing it
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(commute_dist), 2) AS avg_commute_dist
FROM
demographics
LEFT JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
demographics.employee_id IN (SELECT employee_id FROM tenure WHERE org_tenure > 1)
AND
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
# Note: Since employee_id exists in multiple data sets, we must name a specific data set when referencing it
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(commute_dist), 1) AS avg_commute_dist
FROM
demographics
LEFT JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
demographics.employee_id IN (SELECT employee_id FROM tenure WHERE org_tenure > 1)
AND
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(org_tenure), 1) AS avg_org_tenure,
ROUND(AVG(commute_dist), 1) AS avg_commute_dist
FROM
demographics
LEFT JOIN
tenure
ON
demographics.employee_id = tenure.employee_id
LEFT JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(org_tenure), 1) AS avg_org_tenure,
ROUND(AVG(commute_dist), 1) AS avg_commute_dist
FROM
demographics
INNER JOIN
tenure
ON
demographics.employee_id = tenure.employee_id
INNER JOIN
job
ON
demographics.employee_id = job.employee_id
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(org_tenure), 1) AS avg_org_tenure
FROM
employees
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Store SQL query as a character string
sql_string <- paste("SELECT
job_title,
COUNT(*) AS employee_cnt,
ROUND(AVG(commute_dist), 1) AS avg_commute_dist
FROM
demographics
LEFT JOIN
job
ON
demographics.employee_id = job.employee_id
INNER JOIN
(SELECT employee_id FROM tenure WHERE org_tenure > 1) ids
ON
demographics.employee_id = ids.employee_id
WHERE
dept = 'Research & Development'
GROUP BY
job_title
HAVING
COUNT(*) > 10
ORDER BY
job_title")
# Execute SQL query
sqldf(sql_string)
# Load SQL library
library(sqldf)
# Load data sets
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
status <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/status.csv")
benefits <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/benefits.csv")
demographics <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/demographics.csv")
job <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/job.csv")
payroll <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/payroll.csv")
performance <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/performance.csv")
prior_employment <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/prior_employment.csv")
survey_response <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/survey_response.csv")
tenure <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/tenure.csv")
# Return row and column counts
dim(employees)
# Return descriptives to understand distribution of standard hours
summary(employees$standard_hours)
# Return descriptives to understand distribution of standard hours
summary(employees$standard_hrs)
# Return descriptives to understand distribution of standard hours
summary(employees$perf_rating)
# Load library for data viz
library(ggplot2)
# Create data frame containing two related vectors
x <- 1:10
y <- (1:10)^2
data <- as.data.frame(cbind(x, y))
# Produce line chart
ggplot::ggplot(data, aes(x = x, y = y)) +
geom_line()
# Produce line chart
ggplot2::ggplot(data, aes(x = x, y = y)) +
geom_line()
# Produce line chart
ggplot2::ggplot(data, aes(x = x, y = y)) +
geom_line(size = .4, colour = "blue") + # Reduce line thickness and change color to blue
theme_bw() + # Remove the default grey background
ggtitle("Plot Title \n Split between Two Lines") + # Assign a title
xlab("Variable x Name") + # Label the x-axis
ylab("Variable y Name") + # Label the y-axis
theme(plot.title = element_text(hjust = 0.5)) # Center plot title
# Load library for data wrangling
library(dplyr)
# Read employee data
employees <- read.csv("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv")
# Calculate sample variance for annual compensation
var(employees$annual_comp)
# Produce boxplots to visualize compensation distribution by education level and gender
ggplot2::ggplot(employees, aes(x = as.factor(ed_lvl), y = annual_comp, color = gender)) +
labs(x = "Education Level", y = "Annual Compensation") +
theme_bw() +
geom_boxplot()
# Load library
library(moments)
# Calculate skewness for org tenure, rounded to two significant figures via the round() function
round(moments::skewness(employees$org_tenure), 2)
# Produce histogram to visualize sample distribution
ggplot2::ggplot() +
aes(employees$org_tenure) +
labs(x = "Organization Tenure", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Calculate kurtosis for org tenure, rounded to one significant figure
round(moments::kurtosis(employees$org_tenure), 1)
# Load library for Phi Coefficient
library(psych)
# Set females to 1 and everything else to 0
employees$gender_code <- ifelse(employees$gender == 'Female', 1, 0)
# Set stock options to 1 if level > 0
employees$stock_option_code <- ifelse(employees$stock_opt_lvl > 0, 1, 0)
# Create a 2x2 contingency table
contingency_tbl <- table(employees$gender_code, employees$stock_option_code)
# Calculate the Phi Coefficient between dichotomous variables
psych::phi(contingency_tbl)
# Load library for correlation visuals
library(corrplot)
# Store correlation matrix to object M
M <- cor(employees[, c("annual_comp", "age", "org_tenure", "job_tenure", "prior_emplr_cnt", "commute_dist")], use = "complete.obs")
# Visualize correlation matrix
corrplot::corrplot.mixed(M, order = 'AOE')
# Load library for correlation visuals
library(GGally)
# Visualize correlation matrix
GGally::ggpairs(employees[, c("annual_comp", "age", "org_tenure", "job_tenure", "prior_emplr_cnt", "commute_dist")])
# Visualize org tenure distribution
ggplot2::ggplot() +
aes(employees$org_tenure) +
labs(x = "Org Tenure", y = "Density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw()
# Load library for arranging visuals
library(ggpubr)
# Create user-defined function (UDF) to simplify probability distribution visualization
# Function arguments: (1) data = object containing random distribution values; (2) type = 'discrete' or 'continuous' probability distribution; and (3) title = name of distribution
dist.viz <- function(data, type, title) {
if (type == "discrete"){
# Discrete distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "count") +
geom_histogram(fill = "#414141") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
} else {
# Continuous distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
}
return(viz)
}
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
p_binomial <- dist.viz(data = binomial_dist, type = "discrete", title = "Binomial")
p_nbinomial <- dist.viz(data = nbinomial_dist, type = "discrete", title = "Negative Binomial")
p_poisson <- dist.viz(data = poisson_dist, type = "discrete", title = "Poisson")
p_geometric <- dist.viz(data = geometric_dist, type = "discrete", title = "Geometric")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Load library for arranging visuals
library(ggpubr)
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Create user-defined function (UDF) to simplify probability distribution visualization
# Function arguments: (1) data = object containing random distribution values; (2) type = 'discrete' or 'continuous' probability distribution; and (3) title = name of distribution
dist.viz <- function(data, type, title) {
if (type == "discrete"){
# Discrete distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "count") +
geom_histogram(fill = "#414141") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
} else {
# Continuous distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
}
return(viz)
}
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
p_binomial <- dist.viz(data = binomial_dist, type = "discrete", title = "Binomial")
p_nbinomial <- dist.viz(data = nbinomial_dist, type = "discrete", title = "Negative Binomial")
p_multinomial <- dist.viz(data = multinomial_dist, type = "discrete", title = "Multinomial")
p_poisson <- dist.viz(data = poisson_dist, type = "discrete", title = "Poisson")
p_geometric <- dist.viz(data = geometric_dist, type = "discrete", title = "Geometric")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Simulate bernoulli distribution
bernoulli_dist <- rbinom(1000, 1, prob = .5)
# Simulate binomial distribution
# Notice the important difference relative to the Bernoulli simulation (100 trials vs. 1)
binomial_dist <- rbinom(1000, 100, prob = .5)
# Simulate negative binomial distribution
nbinomial_dist <- rnbinom(1000, 100, prob = .5)
# Simulate multinomial distribution with varying probabilities per level
multinomial_dist <- rmultinom(1000, 4, prob = c(.4, .3, .2, .6))
# Simulate poisson distribution
poisson_dist <- rpois(1000, 10)
# Simulate geometric distribution
geometric_dist <- rgeom(1000, prob = .2)
<br />
# Load library for arranging visuals
library(ggpubr)
# Create user-defined function (UDF) to simplify probability distribution visualization
# Function arguments: (1) data = object containing random distribution values; (2) type = 'discrete' or 'continuous' probability distribution; and (3) title = name of distribution
dist.viz <- function(data, type, title) {
if (type == "discrete"){
# Discrete distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "count") +
geom_histogram(fill = "#414141") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
} else {
# Continuous distribution
viz <- ggplot() +
aes(data) +
labs(title = paste(title), x = "x", y = "density") +
geom_histogram(aes(y = ..density..), fill = "#414141") +
geom_density(fill = "#ADD8E6", alpha = 0.6) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
}
return(viz)
}
# Call UDF to build visualizations and store to objects
p_bernoulli <- dist.viz(data = bernoulli_dist, type = "discrete", title = "Bernoulli")
p_binomial <- dist.viz(data = binomial_dist, type = "discrete", title = "Binomial")
p_nbinomial <- dist.viz(data = nbinomial_dist, type = "discrete", title = "Negative Binomial")
p_multinomial <- dist.viz(data = multinomial_dist, type = "discrete", title = "Multinomial")
p_poisson <- dist.viz(data = poisson_dist, type = "discrete", title = "Poisson")
p_geometric <- dist.viz(data = geometric_dist, type = "discrete", title = "Geometric")
# Display distribution visualizations
ggpubr::ggarrange(p_bernoulli, p_binomial, p_nbinomial, p_multinomial, p_poisson, p_geometric,
ncol = 3, nrow = 2)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Set seed for reproducible random distribution
set.seed(1234)
# Simulate normal distribution
normal_dist <- rnorm(1000, mean = 50, sd = 5)
# Simulate log-normal distribution
lnormal_dist <- rlnorm(1000, meanlog = 0, sdlog = 1)
# Simulate uniform distribution
uniform_dist <- runif(1000, min = 1, max = 100)
# Simulate student's t distribution
t_dist <- rt(1000, df = 5)
# Simulate chi-square distribution
chisq_dist <- rchisq(1000, df = 5)
# Simulate F distribution
f_dist <- rf(1000, df1 = 5, df2 = 200)
# Call UDF to build visualizations and store to objects
# Note that as long as the arguments are in the order specified in the function (see our UDF definition above), the argument names do not need to be specified. To illustrate, we will drop the argument names from these function calls:
p_normal <- dist.viz(normal_dist, "continuous", "Normal")
p_lnormal <- dist.viz(lnormal_dist, "continuous", "Log-Normal")
p_uniform <- dist.viz(uniform_dist, "continuous", "Uniform")
p_t <- dist.viz(t_dist, "continuous", "Student's T")
p_chisq <- dist.viz(chisq_dist, "continuous", "Chi-Square")
p_f <- dist.viz(f_dist, "continuous", "F")
# Display distribution visualizations
ggpubr::ggarrange(p_normal, p_lnormal, p_uniform, p_t, p_chisq, p_f,
ncol = 3, nrow = 2)
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# For each n, draw random samples
for (n in sample_n) {
for (draw in 1:samples) {
# Store sample means in data frame
sample_means <- rbind(sample_means, cbind.data.frame(
n = n,
x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
}
}
# Generate uniform population distribution with 1000 values ranging from 1 to 100
rand.unif <- runif(1000, min = 1, max = 100)
# Define number of samples to draw from population distribution
samples <- 10000
# Populate vector with sample sizes
sample_n <- c(1:5,10,25,50)
# Initialize empty data frame to hold sample means
sample_means = NULL
# Set seed for reproducible random samples
set.seed(456)
# For each n, draw random samples
for (n in sample_n) {
for (draw in 1:samples) {
# Store sample means in data frame
sample_means <- rbind(sample_means, cbind.data.frame(
n = n,
x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
}
}
?cliff_delta()
?cliff.delta()
