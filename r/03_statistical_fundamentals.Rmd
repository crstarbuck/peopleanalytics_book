# Statistical Fundamentals

## Population Parameters

## Sample Statistics


## Descriptive Statistics

* Measures of Central Tendency

  Mean
  
  Perhaps the most intuitive measure of central tendency is the mean, which is often referred to as the average. The mean of a sample is denoted by $\bar{x}$ and is defined by:
  
  $$ \bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{n} $$

The mean of a set of numeric values can be calculated using the mean() function in R:

```{r, message = FALSE}

# Fill vector x with integers
x <- c(1,1,1,2,2,2,3,3,4,50)

# Calculate average of vector x
mean(x)

```

  Median
  
  The median represents the midpoint in a sorted vector of numbers. For vectors with an even number of values, the median is the average of the middle two numbers; it is simply the middle number for vectors with an odd number of values. When the distribution of data is skewed, or there is an extreme value like we observe in vector x, the median is a better measure of central tendency. 
  
  The median() function in R can be used to handle the sorting and midpoint selection:
  
```{r, message = FALSE}

# Calculate median of vector x
median(x)

```
  
  In this example, the median is only 2 compared with the mean of 6.9 (which is not really representative of any of the values in vector x). Large deltas between mean and median values are evidence of outliers.
  
  Mode
  
  The mode is the most frequent number in a set of values.
  
  While mean() and median() are standard functions in R, mode() returns the internal storage mode of the object rather than the statistical mode of the data. We can easily create a function to return the statistical mode(s):
  
```{r, message = FALSE}

# Create function to calculate statistical mode(s)
stat.mode <- function(x) {
  ux <- unique(x)
  tab <- tabulate(match(x, ux))
  ux[tab == max(tab)]
}

# Return mode(s) of vector x
stat.mode(x)

```
  
  In this case, we have a bimodal distribution since both 1 and 2 occur most frequently.
  
  Range
  
  The range is the difference between the maximum and minimum values in a set of numbers. 
  
  The range() function in R returns the minimum and maximum numbers:
  
```{r, message = FALSE}

# Return lowest and highest values of vector x
range(x)

```

We can leverage the max() and min() functions to calculate the difference between these values:

```{r, message = FALSE}

# Calculate range of vector x
max(x, na.rm = TRUE) - min(x, na.rm = TRUE)

```

* Measures of Spread

  Variance
  
  Variance is a measure of the variability around the average value. Variance is calculated using the average of squared differences from the mean.
  
  Variance of a population is defined by:
  
  $$ \sigma^{2} = \frac{\sum (X_{i}-\mu)^{2}}{N} $$
  
  Variance of a sample is defined by:
  
  $$ s^{2} = \frac{\sum (x_{i}-\bar{x})^{2}}{n-1} $$
  
  It is important to note that since differences are squared, the variance is always non-negative. In addition, we cannot compare these squared differences to the arithmetic mean since the units are different. For example, if we calculate the variance of compensation measured in USD, variance should be expressed as USD squared while the mean exists in the original USD unit of measurement.
  
  Standard Deviation
  
  The standard deviation is simply the square root of the variance, as defined by:
  
  $$ s = \sqrt{\frac{\sum (x_{i} - \bar{x})^{2}}{N - 1}} $$
  
  Since a squared value can be converted back to its original units by taking its square root, the standard deviation expresses variability around the mean in the variable's original units.
  
  Quartiles
  
  The Interquartile Range (IQR)...
  
  Covariance

$$ cov_{x,y} = \frac{\sum(x_{i}-\bar{x})(y_{i}-\bar{y})}{N-1} $$

  Correlation

  "Correlation is not causation."

$$ r_{x,y} = \frac{\sum(x_{i}-\bar{x})(y_{i}-\bar{y})}{\sqrt{\sum_(x_{i}-\bar{x})^2\sum_(y_{i}-\bar{y})^2}} $$


## Inferential Statistics

The objective of inferential statistics is to make inferences -- with some degree of confidence -- about a population based on available sample data. Several related concepts underpin this goal and will be covered here.

* Introduction to Probability


* Central Limit Theorem

The Central Limit Theorem (CLT) is a mainstay of statistics and probability and fundamental to understanding the mechanics of inferential analysis techniques we will cover later in this book. The CLT was initially coined by a French-born mathematician named Abraham De Moivre in the 1700s. While initially unpopular, it was later reintroduced and attracted new interest from theorists and academics (Daw & Pearson, 1972). 

The CLT states that the average of independent random variables, when increased in number, tend to follow a normal distribution. The distribution of sample means approaches a normal distribution regardless of the shape of the population distribution from which the samples are drawn. This is important because the normal distribution has properties that can be used to test the likelihood that an observed difference or relationship in a sample is also present in the population.

If we need to estimate the average value of a population, for example, we can lean on the CLT and normal distribution properties to obtain the range of values that are likely to include the true population average. This is how confidence intervals are defined, which enable us to make reasonable inferences about the unknown population parameters based on sample data.

<br />

```{r, echo = FALSE, fig.cap = 'The Empirical Rule', fig.align = 'center'}

knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/normal_distribution.png")

```

<br />

Let's begin with an intuitive example of CLT, which has been inspired by Wheelan (2013). Consider a situation in which one of many buses shuttling 40 basketball players to a tournament finds itself lost. You receive word that a bus of lost people is discovered, and your job is to determine whether this bus is the missing bus of basketball players rather than some other bus of lost people. Consider also that a state fair is occurring the same day as the basketball tournament, and this event also has shuttles transporting groups of 40 people from their vehicles to the event.

Let's assume the mean and standard deviation of the height of these two groups are known; the group of basketball players are, on average, 6’ 5” with a standard deviation of 1”, while state fair attendees are, on average, a much shorter 5’ 4” with a wider standard deviation of 3”. With a known population mean and standard deviation, the standard error (the standard deviation of the sample means) provides the ability to calculate the probability that the sample (the lost bus of people) belongs to the population of interest (basketball players competing in the tournament).

Herein lies the beauty of the CLT: roughly 68 percent of sample means will lie within one standard error of the population mean, roughly 95 percent will lie within two standard errors of the population mean, and roughly 99 percent will lie within three standard errors of the population mean. Therefore, any bus whose members have an average height that is not within two standard errors of the population mean (between 6’ 3” and 6’ 7” in the case of our basketball players) is statistically unlikely to be the bus of basketball players for which we are searching. This is because in less than 5 in 100 cases could we randomly draw a 'reasonably sized' sample of basketball players with an average height so extremely different from the population average. 

Because small samples lend to anamalies, we could -- by chance -- select a single person who happens to fall in the tails (very short or very tall relative to others); however, as the sample size increases, it becomes more and more likely that the observed average reflects the average of the larger population. It would be virtually impossible (in less than 1 in 100 times) to draw a random sample of players from the population with an average height that is not within three standard errors of the population mean (between 6’ 2” and 6’ 8”). Therefore, if we find that the lost bus of people have an average height of 5’ 11”, we should keep looking for our bus of basketball players.

Let's now see the CLT in action by simulating a random uniform population distribution from which we can draw random samples. Remember, the shape of the population distribution does not matter; we could simulate an Exponential, Gamma, Poisson, or other distribution and observe the same behavior.

```{r, fig.cap = "Random Uniform Population Distribution (N = 1000)", fig.align = 'center', message = FALSE}

# Load libraries for data wrangling and viz
library(dplyr)
library(ggplot2)

# Set seed for reproducible random distribution
set.seed(1234)

# Generate uniform population distribution with 1000 values ranging from 1 to 100
rand.unif <- runif(1000, min = 1, max = 100)

# Produce histogram to visualize population distribution
ggplot() + 
  aes(rand.unif) + 
  labs(x = "x", y = "N") + 
  geom_histogram(colour = "white", size = .1, fill = "#262626")

```

As expected, these randomly generated data are uniformly distributed. Next, we will draw 100 random samples of size 1 through 10 and plot the average of each.

```{r, fig.cap = "Distribution of 100 Sample Means (n = 1-10)", fig.align = 'center', message = FALSE}

# Define number of samples to draw from population distribution
samples <- 100

# Populate vector with sample sizes
sample_n <- c(1:10)

# Initialize empty data frame to hold sample means
sample_means = NULL

# Set seed for reproducible random samples
set.seed(456)

# For each n, draw random samples
for (n in sample_n) {
  
  for (draw in 1:samples) {
    
      # Store sample means in data frame
      sample_means <- rbind(sample_means, cbind.data.frame(
                            n = n, 
                            x_bar = mean(sample(rand.unif, n, replace = TRUE, prob = NULL))))
  }
}

# Produce histograms to visualize distributions of sample means
sample_means %>% ggplot() + 
  aes(x = x_bar, fill = n) + 
  labs(x = "x-bar", y = "n") + 
  geom_histogram(colour = "white", size = .1, fill = "#262626") + 
  facet_wrap(~n)

```

Per the CLT, we can see that as n increases, the sample means become more normally distributed.

* Confidence Intervals

  A Confidence Interval (CI) is a range of values that likely includes an unknown population value. A related concept that is fundamental to estimating CIs is the standard error. The standard error (SE) is the standard deviation of sample means. While the standard deviation is a measure of variability for random variables, the variability captured by the SE reflects how representative the sample is of the population. Since sample statistics will approach the actual population parameters as the size of the sample increases, the SE and sample size are inversely related; that is, the SE decreases as the sample size increases. The SE is defined by:
  
  $$ SE = \frac{\sigma}{\sqrt{n}} $$
  
  Let's illustrate the relationship between CIs and standard errors by validating whether the normal distribution properties are characteristic of the data simulated for our CLT example:

```{r, message = FALSE}

# Store sample means with n = 10
x_bars <- sample_means[sample_means$n == 10, "x_bar"]

# Calculate 95% CI (1.96 standard errors above and below the mean)
ci95_upper_bound <- mean(x_bars) + sd(x_bars) * 1.96
ci95_lower_bound <- mean(x_bars) - sd(x_bars) * 1.96

# Calculate percent of sample means within 95% CI
length(x_bars[x_bars > ci95_lower_bound & x_bars < ci95_upper_bound]) / length(x_bars) * 100

```

  As expected, 95% of sample means are within our 95% CI (+/- 1.96 standard errors). 1.96 is a z-score, which is simply the number of standard deviations (or SEs in this case) that correspond to the 95% CI.

  Next, let's look at a 99% CI. We will use a z-score of 2.58 for this:

```{r, message = FALSE}

# Calculate 99% CI (2.58 standard errors above and below the mean)
ci99_upper_bound <- mean(x_bars) + sd(x_bars) * 2.58
ci99_lower_bound <- mean(x_bars) - sd(x_bars) * 2.58

# Calculate percent of sample means within 99% CI
length(x_bars[x_bars > ci99_lower_bound & x_bars < ci99_upper_bound]) / length(x_bars) * 100

```

  All of the sample means are within the 99% CI (+/- 2.58 standard errors), indicating that it would be highly unlikely -- nearly impossible even -- to observe a sample mean `from the same population` that falls outside this interval.
  
* Hypothesis Testing

Hypothesis testing is how we leverage CIs to test whether a significant difference or relationship exists in data. Sir Ronald Fisher invented what is known as the null hypothesis, which states that there is no relationship/difference. The null hypothesis is defined by:

$$ H_0: \mu_A = \mu_B $$

The objective of hypothesis testing is to determine if there is sufficient evidence to reject the null hypothesis in favor of an alternative hypothesis. The null hypothesis always states that there is 'nothing' of significance; disprove me if you can! If we want to test whether an intervention has an effect on an outcome in a population, the null hypothesis states that there is no effect. If we want to test whether there is a difference in average scores between two groups in a population, the null hypothesis states that there is no difference.

An alternative hypothesis may simply state that there is a difference or relationship in the population, or it may specify the expected direction (e.g., Population A has a significantly 'larger' or 'smaller' average value than Population B; Variable A is 'positively' or 'negatively' related to Variable B):

$$ H_A: \mu_A \neq \mu_B $$

$$ H_A: \mu_A < \mu_B $$

$$ H_A: \mu_A > \mu_B $$

  Alpha

  The alpha level of a hypothesis test, denoted by $\alpha$, represents the probability of obtaining observed results due to chance. In other words, $\alpha$ is the probability of rejecting the null hypothesis (and therefore claiming that there is a significant difference or relationship) when in fact we should have failed to reject it because there is insufficient evidence for the alternative hypothesis.
  
  $\alpha$ is often set at .05 but is sometimes set at a more rigorous .01. An $\alpha$ of .05 corresponds to a 95% CI (1 - .05), and .01 to a 99% CI (1 - .01). At the .05 level, we would conclude that a finding is statistically significant if the chance of observing a value at least as extreme as the one observed is less than 1 in 20 if the null hypothesis is true. Note that we observed this behavior with our simulated distribution of sample means. In our example, we found that in 95 of 100 cases, the sample mean was within our 95% CI. While we can draw a more extreme value by chance with repeated attempts, we should only expect a mean outside the 95% CI less than 1 in every 20 times. Moreover, we should only expect a mean outside the 99% CI less than 1 in every 100 times.

  Beta
  
  Another key value is Beta, denoted by $\beta$, which relates to the power of the analysis. Simply put, power reflects our ability to find a difference or relationship if there is one. Power is calculated by 1 - $\beta$.
  
  Type I & II Errors

  A Type I Error is a false positive, wherein we conclude that there is a significant difference or relationship when there is not. A Type II Error is a false negative, wherein we fail to capture a significant finding. $\alpha$ represents our chance of making a Type I Error, while $\beta$ represents our chance of making a Type II Error. I once had a professor who told me that committing a Type I error is a shame, while committing a Type II error is a pity, and I've found this to be a helpful way to remember what each type of error represents.

```{r, echo = FALSE, fig.cap = 'Type I and II Errors', fig.align = 'center'}

knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/hypothesis_testing_errors.png")

```

  P-Values
  
  In statistical tests, the p-value is referenced to determine whether the null hypothesis can be rejected. The p-value represents the probability of obtaining a result at least as extreme as the one observed if the null hypothesis is true. As a general rule, if p < .05, we can confidently reject the null hypothesis and conclude that the observed difference or relationship is likely a noteworthy finding.
  
  While statistical significance helps us understand the probability of observing results by chance when there is actually no difference or effect in the population, it does not tell us anything about the size of the difference or effect. Analysis should never be reduced to inspecting p-values; in fact, p-values have been the subject of much controversy among researchers in recent years. This book will cover how to interpret results of statistical tests to surface the story and determine if there is anything 'practically' significant among statistically significant findings.