--- 
title: "Data Preparation"
site: bookdown::bookdown_site
always_allow_html: true
documentclass: krantz
bibliography: book.bib
fig-caption: yes
link-citations: yes
github-repo: crstarbuck/peopleanalytics-lifecycle-book
pagetitle: "Data Preparation"
description: "An end-to-end guide for successful analytics projects in the social sciences"
---

# Data Preparation


## Data Wrangling


## Feature Engineering

Level one people analytics tends to utilize only the delivered fields from the HRIS (e.g., location, job profile, org tenure, etc.), but a good next step is to derive smarter variables from these fields. These can then be used to slice and dice turnover and engagement data differently, use as inputs in attrition risk models, etc. Below are some ideas to get you started:

  + Number of jobs per unit of tenure (larger proportions tend to see greater career pathing)
  + Office/remote worker (binary variable dummy coded as 1/0)
  + Local/remote manager (binary variable dummy coded as 1/0)
  + Hire/Rehire (binary variable dummy coded as 1/0)
  + Hired/acquired (proxy for culture shock effects)
  + Gender isolation (ratio of employee’s gender to number of the same within immediate work
group)
  + Generation isolation (comparison of age bracket to most frequent generational bracket within
immediate work group)
  + Ethnic isolation (ratio of employee’s ethnicity to number of the same within immediate work
group)
  + Difference between employee and manager age
  + Percentage change between last two performance appraisal scores (per competency and/or
overall)
  + Team and department quit outbreak indicators (ratio of terms over x months relative to average
headcount over x months)
  + Industry experience (binary or length in years)

Remember to compute variables consistent with a need (e.g., is there reason to believe generationally isolated employees are more likely to term?). There may be a time and place for undertaking data mining initiatives with no a priori theories about what may be uncovered; however, more often than not, our efforts should be tied to specific hypotheses the business needs tested, which have sound theoretical underpinnings.




You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap = 'Here is a nice figure!', out.width = '80%', fig.asp = .75, fig.align = 'center'}

par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)

```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}

knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)

```

You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].
