# Measurement & Sampling {#measure-sampl}

## Variable Types

  The framing of variables in research hypotheses guides the treatment of each in our analyses. In this section, we will discuss the function of *independent*, *dependent*, *control*, *moderating*, and *mediating* variables.

### Independent Variables (IV)

  An **Independent Variable (IV)** is a variable which is assumed to have a direct effect on another variable. IVs are sometimes referred to as *predictors*, *factors*, *features*, *antecedents*, or *explanatory* variables.
  
  For example, we may wish to examine whether an inclusion training program given to a random sample of leaders has a positive effect on team-level belonging favorability. In a true experimental design, participation in the inclusion training would be the only difference between the treatment (teams whose leaders who participate in the training) and the control (teams whose leaders who do not participate in the training). In this case, inclusion training participation is the IV (the variable we are manipulating).
  
  IVs are also present in non-experimental designs. For example, we may survey employees and ask them to rate their leader's inclusiveness and also provide self-reported belonging ratings. In this context, leader inclusiveness (rather than an inclusion training) is the IV. If we find that average team-level belonging scores tend to be higher when leader inclusiveness scores are higher, this *may* indicate that leader inclusion has some degree of influence on team-level belonging. Of course, there could be alternative explanations for any observed differences in team-level belonging, which is why experimental designs tend to provide stronger evidence for an IV's effect.

### Dependent Variables (DV)

  A **Dependent Variable (DV)** is a variable that is *dependent* on the IV. DVs are also referred to as *outcome*, *response*, or *criterion* variables.
  
  In our leader inclusion example, team-level belonging is the DV since this variable is assumed to depend on the level of team leaders' inclusiveness. It's important to note that regardless of a study's results, it is the positioning of the variables in the study's hypotheses (rooted in theory) that determines the type of variable. If we hypothesize that leader inclusion training has a positive effect on team-level belonging, but the study finds no such effect, the inclusion intervention is still the IV and team-level belonging the DV.

### Control Variables (CV)

  A **Control Variable (CV)** is a variable that is held constant in research. The unchanging state of a CV allows us to understand the extent to which the IV has a unique and independent effect on the DV.
  
  In an experimental context, control variables represent a researcher's attempt to control for alternative explanations so that the IV's main effect on the DV can be isolated. For example, in our leader inclusion example, in order to be confident that the reason for any observed differences in team-level belonging can be attributed to leader inclusion training rather than other factors that theoretically may explain differences. For example, we should ensure that the two groups are similar with respect to characteristics such as gender and ethnicity, since underrepresented groups (URGs) may have different experiences independent of any training programs. In this case, gender and ethnicity are CVs.
  
  While we control for the effects of alternative explanations by way of the research design in an experiemental context, we will discuss ways to control for these statistically in Chapter \@ref(lm) for correlational designs. CVs are equally important in experimental and non-experimental contexts.

### Moderating Variables

  A **Moderating Variable** influences the strength of the effect of an IV on a DV. Moderating variables are often referred to as *interactions* or *interaction terms* in models.
  
  Moderating variables may augment (strengthen) or attenuate (weaken) the effect one variable has on another. Interactions are widely understood in the context of medications; one drug may independently have a positive effect on one's health but when combined with another medication, the interaction can behave very differently -- and may even be lethal! In our inclusive leadership example, we may find that the strength of the training's effect on team-level belonging varies based on a leader's span of control (SoC). It stands to reason that leaders with a lower SoC may find it easier to cultivate a climate of inclusivity and belonging, while leaders with a higher SoC may have more scope/projects and team dynamics to manage and may find it more difficult to consistently apply strategies covered during the training. 
  
  Interactions between variables are vital to our understanding of nuance and complexity in the dynamics influencing outcomes in organizational settings. Chapter \@ref(lm) will cover how to test for significant interactions.

### Mediating Variables

  A **Mediating Variable** explains the *how* or *why* of an IV's effect on a DV. It may be helpful to think of mediating variables as a "go-between" -- a part of the causal pathway of an effect.
  
  In the case of inclusive leadership training, effects on belonging are likely not the result of the training itself. More likely, the training raised awareness and helped leaders develop strategies to help cultivate team inclusivity. One strategy endorsed during the training may be participative decision making, and the implementation of this strategy may explain **why** the training has a positive effect on team-level belonging. There may be multiple mediators of any observed effect of the intervention on team-level belonging depending on training outcomes.
  
  Mediating variables may fully or partially mediate the relationship between an IV and DV. **Full mediation** indicates that the mediator fully explains the effect; in other words, without the mediator in the model, there is no relationship between an IV and DV. **Partial mediation** indicates that the mediator partially explains the effect; that is, there is still a relationship between an IV and DV without the mediator in the model. Partial mediation indicates that there are additional explanations for *how* or *why* observed effects exist, such as the implementation of additional team inclusion strategies influencing team belonging. In Chapter \@ref(lm), we will discuss how to test for both full and partial mediation.
  
  Translating research hypotheses into conceptual models of hypothesized relationships is helpful in visually representing the function of each variable in the study. Figure \@ref(fig:concept-mdl) illustrates how each type of variable is depicted using our inclusive leadership example:

  <br />
  
```{r concept-mdl, out.width = "75%", echo = FALSE, fig.cap = 'Conceptual Model of Hypothesized Relationships among Variables', fig.align = 'center'}

knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/conceptual_model.png")

```

  <br />
  
## Measurement Scales

  **Measurement scales** are used to categorize and quantify variables. There are two major categorizations -- *discrete* and *continuous* -- and these, together with the research hypotheses, help determine appropriate types of analyses to perform.

### Discrete Variables

  **Discrete variables** are also known as *categorical* or *qualitative* variables. Categorical variables have a finite or countable number of values associated with them, and these can be further categorized as either *nominal* or *ordinal*.

  **Nominal**

  A **nominal** variable is one with two or more categories for which there is no intrinsic ordering to the categories. Examples of nominal variables include office locations, departments, and teams. A **dichotomous variable** is a type of nominal variable which has only two unordered categories. Examples of dichotomous variables include people leader vs. individual contributor, active vs. inactive status, and remote worker vs. non-remote worker.

  **Ordinal**

  An **ordinal** variable is similar to a nominal variable with one important difference: ordinal variables have *ordered* categories. Examples of ordinal variables include education levels, job levels, and survey variables measured on Likert-type scales.

### Continuous Variables

  **Continuous variables** are also known as *quantitative* variables. Continuous variables can assume any real value in some interval, and these can be further categorized as either *interval* or *ratio* variables.

  **Interval**
  
  Variables measured on an **interval** scale have a natural order and a quantifiable difference between values but no absolute zero value. Examples include SAT scores, IQ scores, and temperature measured in Fahrenheit or Celsius (but not Kelvin). In these examples, 0 is either not an option (i.e., SAT and IQ) or does not represent the absence of something (e.g., 0 degrees is a temperature, albeit a cold one!).
  
  **Ratio**

  Variables measured on a **ratio** scale have the same properties as data measured on an interval scale with one important difference: ratio data have an absolute zero value. Examples include compensation, revenue, and sales; a zero in these contexts is possible and would indicate a true absence of something.

## Sampling

  The goal of research is to understand a population based on data from a subset of population members. In practice, it is often not feasible to collect data from every member of a population, so we instead calculate **sample statistics** to estimate **population parameters**.

  Another important concept is the **sampling frame**. While the population represents the entire group of interest, the sampling frame represents the subset of the population to which the researcher has access. In an ideal setting, the population and sampling frame are the same, but they are often different in practice. For example, a professor may be interested in understanding student sentiment about a new school policy but only has access to collect data from students in the courses she teaches. In this case, the entire student body is the population but the students she has access to (those in the courses she teaches) represent the sampling frame. The sample is the subset of the sampling frame that ultimately participates in the research (e.g,. those who complete a survey or participate in a focus group).

### Sampling & Nonsampling Error

  Sampling and nonsampling errors are general categorizations of biases and error in research (Albright & Winston, 2016).
  
  **Sampling error** is the inevitable result of basing inferences on a random sample rather than the entire population. The risk of sampling error decreases as the sample size approaches the population size; however, it is usually not feasible to gain information from the entire population, so sampling error is generally a concern.
  
  There are many types of **nonsampling error** that can invalidate results beyond the sampling procedure, and we will focus on several that are particularly germane to people analytics: *nonresponse bias*, *nontruthful responses*, *measurement error*, and *voluntary response bias*. 
  
  **Nonresponse Bias**
  
  Surveys are a staple in the set of data sources germane to people analytics. While survey data provide unique attitudinal and perceptive signals that can be highly predictive of future behavior and events, surveys tend to be far more susceptible to nonsampling error than other data sources.
  
  As discussed in the context of sampling error, we usually do not have access to information on entire populations of interest, so we must consider the possibility that those for whom we are missing data may have common qualities, perceptions, or opinions that differ from those for whom we do have data. This is known as **nonresponse bias**. For example, if we administer an employee experience survey to the entire organization and recieve a 60% response rate, the reality is that we do not know how the 40% of nonrespondents would have responded. It is possible that nonrespondents represent highly disengaged employees, in which case their responses may have materially influenced results and conclusions in an unfavorable direction. It is also possible that the nonrespondents were really busy, away on vacation, cynical to the confidentiality langage in the communications, or any number of other reasons which may or may not have resulted in significantly different feedback from that of respondents.
  
  Nonresponse bias is not limited to surveys. For example, self-reported demographics such as gender and ethnicity may not be disclosed by all employees in the HR information system (HRIS). This can bias segmentations based on these categorical dimensions. While there are strategies to address this, such as visual ID or applying models trained to infer missing values (which may be necessary to fulfill EEOC reporting requirements), there may still be error in the imputed values.
  
  **Nontruthful Responses**
  
  While high response rates may reduce nonresponse bias, this isn't always something to celebrate. Organizations that incentivize participation in surveys often do so at the risk of people responding in socially desirable ways and providing **nontruthful responses** in order to achieve some defined target. For example, if an employee has an unhealthy relationship with his manager but does not trust that managers will not have access to individual-level responses, the employee may decide to indicate on the survey that everything is highly favorable in order to help the team win the month of casual days leadership promised. This can of course skew and invalidate results.
  
  While survey participation should be strongly encouraged since higher response rates can mitigate the risk of certain types of bias and increase confidence that the survey is representative of the collective organization's sentiments, incentivizing participation can be dangerous.
  
  **Measurement Error**
  
  **Measurement error** relates to errors stemming from confusing questions, survey fatigue, and low-quality scales used to measure multidimensional psychological constructs. The field of **psychometrics** is a vast scientific discipline concerned with the development of assessment tools, measurement instruments, and formalized models to understand latent psychological constructs such as engagement, belonging, purpose, and wellbeing using observable indicators.
  
  The reduction of measurement error is a principal concern to psychometricians. For a deeper treatment of the survey scale development process, see DeVellis (2012). While an exhaustive treatment of psychometrics is beyond the scope of this book, *reliability* and *validity* are two broad sets of methods designed to increase the robustness of psychological instrumentation which will be reviewed in this section.
  
  <br />
  
```{r reli-vali, out.width = "75%", echo = FALSE, fig.cap = 'Reliability and Validity', fig.align = 'center'}

knitr::include_graphics("/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/graphics/reliability_validity.png")

```
  
  <br />
    
  **Reliability** describes the quality of measurement (i.e., the consistency or repeatability of measures). Types of reliability include:
  
  * **Inter-Rater or Inter-Observer Reliability**: the degree to which different raters/observers give consistent estimates of the same phenomenon.
  * **Test-Retest Reliability**: the consistency of a measure from one time to another.
  * **Parallel-Forms Reliability**: the consistency of the results of two tests constructed in the same way from the same content domain.
  * **Internal Consistency Reliability**: the consistency of results across items within a test.

  **Validity** describes how well a concept was translated into a functioning and operating reality (operationalization). Types of validity include:
  
  * **Face validity**: whether the operationalization "on its face" a good translation of the construct.
  * **Content validity**: the operationalization against the relevant content domain for the construct.
  * **Predictive validity**: the operationalization's ability to predict something it should theoretically be able to predict.
  * **Concurrent validity**: the operationalization's ability to distinguish between groups that it should theoretically be able to distinguish between.
  * **Convergent validity**: the degree to which the operationalization is similar to (converges on) other operationalizations to which it theoretically should be similar.
  * **Discriminant validity**: the degree to which the operationalization is not similar to (diverges from) other operationalizations to which it theoretically should be not be similar.

### Sampling Methods

  It is important to understand the centrality of **randomness** in sampling. Randomization protects against subjective biases, self-validates the data, and is the key ingredient that defines the representative means of extracting information (Kahneman, 2011). Sample data that are not representative of the population of interest can lend to anomalies -- mere coincidences. While non-random data can be leveraged for directionally accurate insights, randomness is required to make inferences about a broader population with a reasonable degree of confidence.
  
  Let's consider an example from Kahneman (2011) in which six babies are born in sequence at a hospital. The gender of these babies is of course random and independent; the gender of one does not influence the gender of another. Consider the three possible sequences of girls (G) and boys (B) below:
  
  * BBBGGG
  * GGGGGG
  * BGBBGB
  
  Are these sequences equally likely? Though it may initially be counter-intuitive, since the events are independent and the outcomes (B and G) are (approximately) equally likely, any possible sequence of births is as likely as any other.
  
  Sample size (colloquially referred to as the $n$-count) is also important as this can have a material influence on the representativeness of sample data -- and consequently, the veracity of results and conclusions based on them. As we will explore in Chapter \@ref(inf-stats), as the sample size increases, so too does our confidence that estimates based on sample data reflect population parameters.
  
  To illustrate the effects of sample sizes, let's consider a hypothetical study in which the promotion rate in an organization is found to be lowest in divisions that are primarily software engineers, low diversity, small, and geographically dispersed. Which of these characteristics might offer an explanation? Let's consider that this study also found that the divisions with highest promotion rates have identicial characteristics: software engineers, low diversity, small, and geographically dispersed. 
  Small samples yield extreme results more often than large samples. Small samples neither cause nor prevent outcomes; they merely allow the incidence of the outcome to be much higher (or much lower) than it is in the larger population (Kahneman, 2011). 
  
  **Non-Probability Sampling**
  
  **Non-probability sampling** can help us gain insight into the *possible*. However, we cannot make inferences based on data collected through non-probability sampling methods since the sample is unlikely to be representative of the population.
  
  **Convenience (Accidental) Sampling**
  
  **Convenience sampling** is the most common type of nonprobabilistic sampling. This sampling method involves taking samples that are conveniently located around a specific location (physical or virtual).
  
  For example, if we were to study employee sentiment about new benefit plans by polling employees walking through the lobby of a particular office building one morning, this would represent convenience sampling. Aside from the risk of employees sharing socially desirable responses in such a setting and invalidating the results, a major shortcoming of this approach is that we are only capturing the sentiment of those who happen to walk into one particular building during one limited window of time. This would not capture the voice of employees who are working remotely, working in another office location, on PTO, taking a sick day, attending an offsite conference or meeting, or stuck in traffic and running late.
  
  **Quota Sampling**
  
  **Quota sampling** is a nonprobabilistic sampling method in which researchers for a sample that is representative of a larger population. With quota sampling, researchers assign quotas to a group of people in order to create subgroups of individuals that reflect the characteristics of the population. This is nonprobabilistic since researchers choose the sample rather than randomly selecting it.
  
  For example, if the characteristics of the employee population are known, the researcher polling employees in the office lobby about benefit plans could collect some additional information (e.g., department, job, tenure) in order to achieve a commensurate proportion of each in the sample. If 30% of employees in the larger workforce are in the Engineering department, the researcher could assign a quota -- such as 3 in every 10 participants -- in order to *choose* a sample in which 30% of employees come from the Engineering department.
  
  **Purposive (Judgmental) Sampling**
  
  The main goal of **purposive sampling** is to construct a sample by focusing on particular characteristics of a population that are of interest to the researcher. Purposive sampling is often used in qualitative or mixed methods research contexts in which a smaller sample is sufficient. Since it is a nonprobabilistic sampling method, purposive sampling is highly prone to researcher bias.
  
  For example, the People Team may be interested in understanding what is top-of-mind for employees leading up to an engagement survey in order to design a survey with relevant items. The team may choose people to participate in focus groups in order to surface qualitative themes -- not for the purpose of generalizing findings but to guide survey item selection efforts.
  
  **Probability Sampling** 
  
  **Probability sampling** can help us gain insight into the *probable*. The main difference between non-probability and probability sampling is that non-probability sampling does not involve random selection and probability sampling does. Probability sampling is intended to facilitate inferences since data collected through random selection methods is more likely to be representative of the population and protects against over-indexing on participants with similar qualities in the sample.
  
  **Simple Random Sampling**
  
  **Simple random sampling** is a method in which each member of the population has the same probability of being selected for a sample. An example of simple random sampling is randomly selecting a specified number or percent of employees from the workforce to participate in a survey without regard for tenure, department, level, or other characteristics.
  
  **Stratified Random Sampling**
  
  **Stratified random sampling** is a sampling method in which the population is first divided into *strata*. Then, a simple random sample is taken from each *stratum* -- a homogeneous subset of the population with similar characteristics with regard to the variable of interest. The combined results constitute the sample.
  
  To ensure samples do not comprise a larger proportion of employees from a particular department, education level, tenure band, generational cohort, or other variable deemed useful in explaining differences in response scores, researchers can randomly select members for each stratum based on the proportion in the respective stratum in the larger population. For example, if 30% of all employees are in the Engineering department, the researcher could *randomly* select a calculated number of employees from the Engineering department such that 30% of employees in the sample come from this department.
  
  **Cluster Sampling**
  
  **Cluster sampling** is a sampling method often used in market research in which the population is first divided into clusters. Then, a simple random sample of clusters is taken. All the members of the selected clusters together constitute the sample. Unlike stratified random sampling, it is the clusters that are selected at random â€“ not the individuals. It is hoped that each cluster by itself is representative of the population (i.e., each cluster is heterogeneous).

  For example, employees could be partitioned into clusters based only on their geographic region. Since there is not further partitioning on other variables, each cluster is expected to be heterogeneous on the basis of variables other than geographic region -- that is, unless geography is related to other variables (e.g., call center employees are all located in a company's Pacific Northwest region). By selecting a random set of clusters, the combination of employees across the selected clusters is expected to be representative of the population.
  
  **Systematic Sampling**
  
  **Systematic sampling** involves selecting sample members from a population according to a random starting point and a fixed, periodic interval known as a sampling interval. The sampling interval is computed by taking the population size and dividing it by the desired sample size. The resulting number is the interval at which population members are selected for the sample.
  
  For example, if there are 10,000 employees and our desired sample size is 500, the sampling interval is 20. Therefore, we would select every 20th employee for our sample. It is important that the sequence does not represent a standardized pattern that would bias the data; this process needs to be random. For example, if the employee id generated by the HRIS increases with time, we would expect employees with longer tenure to have lower employee ids while new joiners would have higher employee ids. Ordering employees by employee id prior to selection could bias the sample on the basis of variables related to tenure (e.g., aggressive periods of Engineering hiring).

## Exercises

1. Parameters are descriptions or characteristics of a sample, while statistics are descriptions or characteristics of a population.
   <br />A. True
   <br />B. False
   
2. 100 randomly selected employees in the Marketing department of an organization participated in a survey on career pathing for marketing professionals. What is the sample and what is the population sampled in this case?
   <br />A. Sample: 100 employees who completed the survey, Population: All employees in the organization
   <br />B. Sample: 100 employees who completed the survey, Population: Marketing employees
   <br />C. Sample: All Marketing professionals, Population: All employees in the organization
   <br />D. Sample: All employees in the organization, Population: Employees across all companies globally