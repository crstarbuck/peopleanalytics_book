<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Linear Regression | The People Analytics Companion: An Applied Guide through the People Analytics Lifecycle</title>
  <meta name="description" content="An end-to-end guide for successful analytics projects in the social sciences" />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Linear Regression | The People Analytics Companion: An Applied Guide through the People Analytics Lifecycle" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An end-to-end guide for successful analytics projects in the social sciences" />
  <meta name="github-repo" content="crstarbuck/peopleanalytics-lifecycle-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Linear Regression | The People Analytics Companion: An Applied Guide through the People Analytics Lifecycle" />
  
  <meta name="twitter:description" content="An end-to-end guide for successful analytics projects in the social sciences" />
  

<meta name="author" content="Craig Starbuck" />


<meta name="date" content="2022-04-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="aod.html"/>
<link rel="next" href="glm.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The People Analytics Companion: An Applied Guide through the People Analytics Lifecycle</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting Started</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#guiding-principles"><i class="fa fa-check"></i><b>1.1</b> Guiding Principles</a><ul>
<li class="chapter" data-level="1.1.1" data-path="getting-started.html"><a href="getting-started.html#pro-employee-thinking"><i class="fa fa-check"></i><b>1.1.1</b> Pro Employee Thinking</a></li>
<li class="chapter" data-level="1.1.2" data-path="getting-started.html"><a href="getting-started.html#quality"><i class="fa fa-check"></i><b>1.1.2</b> Quality</a></li>
<li class="chapter" data-level="1.1.3" data-path="getting-started.html"><a href="getting-started.html#prioritization"><i class="fa fa-check"></i><b>1.1.3</b> Prioritization</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#tools"><i class="fa fa-check"></i><b>1.2</b> Tools</a><ul>
<li class="chapter" data-level="1.2.1" data-path="getting-started.html"><a href="getting-started.html#r"><i class="fa fa-check"></i><b>1.2.1</b> R</a></li>
<li class="chapter" data-level="1.2.2" data-path="getting-started.html"><a href="getting-started.html#data"><i class="fa fa-check"></i><b>1.2.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#d-framework"><i class="fa fa-check"></i><b>1.3</b> 4D Framework</a><ul>
<li class="chapter" data-level="1.3.1" data-path="getting-started.html"><a href="getting-started.html#discover"><i class="fa fa-check"></i><b>1.3.1</b> Discover</a></li>
<li class="chapter" data-level="1.3.2" data-path="getting-started.html"><a href="getting-started.html#design"><i class="fa fa-check"></i><b>1.3.2</b> Design</a></li>
<li class="chapter" data-level="1.3.3" data-path="getting-started.html"><a href="getting-started.html#develop"><i class="fa fa-check"></i><b>1.3.3</b> Develop</a></li>
<li class="chapter" data-level="1.3.4" data-path="getting-started.html"><a href="getting-started.html#deliver"><i class="fa fa-check"></i><b>1.3.4</b> Deliver</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="r-intro.html"><a href="r-intro.html"><i class="fa fa-check"></i><b>2</b> Introduction to R</a><ul>
<li class="chapter" data-level="2.1" data-path="r-intro.html"><a href="r-intro.html#getting-started-1"><i class="fa fa-check"></i><b>2.1</b> Getting Started</a></li>
<li class="chapter" data-level="2.2" data-path="r-intro.html"><a href="r-intro.html#vectors"><i class="fa fa-check"></i><b>2.2</b> Vectors</a></li>
<li class="chapter" data-level="2.3" data-path="r-intro.html"><a href="r-intro.html#matrices"><i class="fa fa-check"></i><b>2.3</b> Matrices</a></li>
<li class="chapter" data-level="2.4" data-path="r-intro.html"><a href="r-intro.html#factors"><i class="fa fa-check"></i><b>2.4</b> Factors</a></li>
<li class="chapter" data-level="2.5" data-path="r-intro.html"><a href="r-intro.html#data-frames"><i class="fa fa-check"></i><b>2.5</b> Data Frames</a></li>
<li class="chapter" data-level="2.6" data-path="r-intro.html"><a href="r-intro.html#lists"><i class="fa fa-check"></i><b>2.6</b> Lists</a></li>
<li class="chapter" data-level="2.7" data-path="r-intro.html"><a href="r-intro.html#loops"><i class="fa fa-check"></i><b>2.7</b> Loops</a></li>
<li class="chapter" data-level="2.8" data-path="r-intro.html"><a href="r-intro.html#user-defined-functions-udfs"><i class="fa fa-check"></i><b>2.8</b> User-Defined Functions (UDFs)</a></li>
<li class="chapter" data-level="2.9" data-path="r-intro.html"><a href="r-intro.html#graphics"><i class="fa fa-check"></i><b>2.9</b> Graphics</a></li>
<li class="chapter" data-level="2.10" data-path="r-intro.html"><a href="r-intro.html#review-questions"><i class="fa fa-check"></i><b>2.10</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="measure-sampl.html"><a href="measure-sampl.html"><i class="fa fa-check"></i><b>3</b> Measurement &amp; Sampling</a><ul>
<li class="chapter" data-level="3.1" data-path="measure-sampl.html"><a href="measure-sampl.html#variable-types"><i class="fa fa-check"></i><b>3.1</b> Variable Types</a><ul>
<li class="chapter" data-level="3.1.1" data-path="measure-sampl.html"><a href="measure-sampl.html#independent-variables-iv"><i class="fa fa-check"></i><b>3.1.1</b> Independent Variables (IV)</a></li>
<li class="chapter" data-level="3.1.2" data-path="measure-sampl.html"><a href="measure-sampl.html#dependent-variables-dv"><i class="fa fa-check"></i><b>3.1.2</b> Dependent Variables (DV)</a></li>
<li class="chapter" data-level="3.1.3" data-path="measure-sampl.html"><a href="measure-sampl.html#control-variables-cv"><i class="fa fa-check"></i><b>3.1.3</b> Control Variables (CV)</a></li>
<li class="chapter" data-level="3.1.4" data-path="measure-sampl.html"><a href="measure-sampl.html#moderating-variables"><i class="fa fa-check"></i><b>3.1.4</b> Moderating Variables</a></li>
<li class="chapter" data-level="3.1.5" data-path="measure-sampl.html"><a href="measure-sampl.html#mediating-variables"><i class="fa fa-check"></i><b>3.1.5</b> Mediating Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="measure-sampl.html"><a href="measure-sampl.html#measurement-scales"><i class="fa fa-check"></i><b>3.2</b> Measurement Scales</a><ul>
<li class="chapter" data-level="3.2.1" data-path="measure-sampl.html"><a href="measure-sampl.html#discrete-variables"><i class="fa fa-check"></i><b>3.2.1</b> Discrete Variables</a></li>
<li class="chapter" data-level="3.2.2" data-path="measure-sampl.html"><a href="measure-sampl.html#continuous-variables"><i class="fa fa-check"></i><b>3.2.2</b> Continuous Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="measure-sampl.html"><a href="measure-sampl.html#sampling"><i class="fa fa-check"></i><b>3.3</b> Sampling</a><ul>
<li class="chapter" data-level="3.3.1" data-path="measure-sampl.html"><a href="measure-sampl.html#sampling-nonsampling-error"><i class="fa fa-check"></i><b>3.3.1</b> Sampling &amp; Nonsampling Error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="measure-sampl.html"><a href="measure-sampl.html#review-questions-1"><i class="fa fa-check"></i><b>3.4</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="research.html"><a href="research.html"><i class="fa fa-check"></i><b>4</b> Research Fundamentals</a><ul>
<li class="chapter" data-level="4.1" data-path="research.html"><a href="research.html#research-questions"><i class="fa fa-check"></i><b>4.1</b> Research Questions</a></li>
<li class="chapter" data-level="4.2" data-path="research.html"><a href="research.html#research-hypotheses"><i class="fa fa-check"></i><b>4.2</b> Research Hypotheses</a></li>
<li class="chapter" data-level="4.3" data-path="research.html"><a href="research.html#internal-vs.external-validity"><i class="fa fa-check"></i><b>4.3</b> Internal vs. External Validity</a></li>
<li class="chapter" data-level="4.4" data-path="research.html"><a href="research.html#research-methods"><i class="fa fa-check"></i><b>4.4</b> Research Methods</a></li>
<li class="chapter" data-level="4.5" data-path="research.html"><a href="research.html#research-designs"><i class="fa fa-check"></i><b>4.5</b> Research Designs</a></li>
<li class="chapter" data-level="4.6" data-path="research.html"><a href="research.html#review-questions-2"><i class="fa fa-check"></i><b>4.6</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="desc-stats.html"><a href="desc-stats.html"><i class="fa fa-check"></i><b>5</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="desc-stats.html"><a href="desc-stats.html#univariate-analysis"><i class="fa fa-check"></i><b>5.1</b> Univariate Analysis</a><ul>
<li class="chapter" data-level="5.1.1" data-path="desc-stats.html"><a href="desc-stats.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.1.1</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="5.1.2" data-path="desc-stats.html"><a href="desc-stats.html#measures-of-spread"><i class="fa fa-check"></i><b>5.1.2</b> Measures of Spread</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="desc-stats.html"><a href="desc-stats.html#bivariate-analysis"><i class="fa fa-check"></i><b>5.2</b> Bivariate Analysis</a><ul>
<li class="chapter" data-level="5.2.1" data-path="desc-stats.html"><a href="desc-stats.html#covariance"><i class="fa fa-check"></i><b>5.2.1</b> Covariance</a></li>
<li class="chapter" data-level="5.2.2" data-path="desc-stats.html"><a href="desc-stats.html#correlation"><i class="fa fa-check"></i><b>5.2.2</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="desc-stats.html"><a href="desc-stats.html#review-questions-3"><i class="fa fa-check"></i><b>5.3</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inf-stats.html"><a href="inf-stats.html"><i class="fa fa-check"></i><b>6</b> Statistical Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="inf-stats.html"><a href="inf-stats.html#introduction-to-probability"><i class="fa fa-check"></i><b>6.1</b> Introduction to Probability</a><ul>
<li class="chapter" data-level="6.1.1" data-path="inf-stats.html"><a href="inf-stats.html#probability-distributions"><i class="fa fa-check"></i><b>6.1.1</b> Probability Distributions</a></li>
<li class="chapter" data-level="6.1.2" data-path="inf-stats.html"><a href="inf-stats.html#conditional-probability"><i class="fa fa-check"></i><b>6.1.2</b> Conditional Probability</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="inf-stats.html"><a href="inf-stats.html#central-limit-theorem"><i class="fa fa-check"></i><b>6.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="6.3" data-path="inf-stats.html"><a href="inf-stats.html#confidence-intervals"><i class="fa fa-check"></i><b>6.3</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inf-stats.html"><a href="inf-stats.html#hypothesis-testing"><i class="fa fa-check"></i><b>6.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="6.3.2" data-path="inf-stats.html"><a href="inf-stats.html#alpha"><i class="fa fa-check"></i><b>6.3.2</b> Alpha</a></li>
<li class="chapter" data-level="6.3.3" data-path="inf-stats.html"><a href="inf-stats.html#beta"><i class="fa fa-check"></i><b>6.3.3</b> Beta</a></li>
<li class="chapter" data-level="6.3.4" data-path="inf-stats.html"><a href="inf-stats.html#type-i-ii-errors"><i class="fa fa-check"></i><b>6.3.4</b> Type I &amp; II Errors</a></li>
<li class="chapter" data-level="6.3.5" data-path="inf-stats.html"><a href="inf-stats.html#p-values"><i class="fa fa-check"></i><b>6.3.5</b> <span class="math inline">\(p\)</span>-Values</a></li>
<li class="chapter" data-level="6.3.6" data-path="inf-stats.html"><a href="inf-stats.html#bonferroni-correction"><i class="fa fa-check"></i><b>6.3.6</b> Bonferroni Correction</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inf-stats.html"><a href="inf-stats.html#review-questions-4"><i class="fa fa-check"></i><b>6.4</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html"><i class="fa fa-check"></i><b>7</b> Data Wrangling and Preparation</a><ul>
<li class="chapter" data-level="7.1" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html#data-management"><i class="fa fa-check"></i><b>7.1</b> Data Management</a></li>
<li class="chapter" data-level="7.2" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html#sql"><i class="fa fa-check"></i><b>7.2</b> SQL</a></li>
<li class="chapter" data-level="7.3" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html#data-screening-cleaning"><i class="fa fa-check"></i><b>7.3</b> Data Screening &amp; Cleaning</a></li>
<li class="chapter" data-level="7.4" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html#one-hot-encoding"><i class="fa fa-check"></i><b>7.4</b> One-Hot Encoding</a></li>
<li class="chapter" data-level="7.5" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html#feature-engineering"><i class="fa fa-check"></i><b>7.5</b> Feature Engineering</a></li>
<li class="chapter" data-level="7.6" data-path="data-wrang-prep.html"><a href="data-wrang-prep.html#review-questions-5"><i class="fa fa-check"></i><b>7.6</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="aod.html"><a href="aod.html"><i class="fa fa-check"></i><b>8</b> Analysis of Differences</a><ul>
<li class="chapter" data-level="8.1" data-path="aod.html"><a href="aod.html#parametric-vs.nonparametric-tests"><i class="fa fa-check"></i><b>8.1</b> Parametric vs. Nonparametric Tests</a></li>
<li class="chapter" data-level="8.2" data-path="aod.html"><a href="aod.html#differences-in-discrete-data"><i class="fa fa-check"></i><b>8.2</b> Differences in Discrete Data</a></li>
<li class="chapter" data-level="8.3" data-path="aod.html"><a href="aod.html#differences-in-continuous-data"><i class="fa fa-check"></i><b>8.3</b> Differences in Continuous Data</a></li>
<li class="chapter" data-level="8.4" data-path="aod.html"><a href="aod.html#review-questions-6"><i class="fa fa-check"></i><b>8.4</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>9</b> Linear Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="lm.html"><a href="lm.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="9.2" data-path="lm.html"><a href="lm.html#multiple-linear-regression"><i class="fa fa-check"></i><b>9.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="9.3" data-path="lm.html"><a href="lm.html#fit-linear-model-with-subset-of-important-variables"><i class="fa fa-check"></i><b>9.3</b> Fit Linear Model (with Subset of Important Variables)</a><ul>
<li class="chapter" data-level="9.3.1" data-path="lm.html"><a href="lm.html#moderation"><i class="fa fa-check"></i><b>9.3.1</b> Moderation</a></li>
<li class="chapter" data-level="9.3.2" data-path="lm.html"><a href="lm.html#mediation"><i class="fa fa-check"></i><b>9.3.2</b> Mediation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="lm.html"><a href="lm.html#polynomial-regression"><i class="fa fa-check"></i><b>9.4</b> Polynomial Regression</a></li>
<li class="chapter" data-level="9.5" data-path="lm.html"><a href="lm.html#hierarchical-models"><i class="fa fa-check"></i><b>9.5</b> Hierarchical Models</a></li>
<li class="chapter" data-level="9.6" data-path="lm.html"><a href="lm.html#review-questions-7"><i class="fa fa-check"></i><b>9.6</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>10</b> Generalized Linear Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="glm.html"><a href="glm.html#logistic-regression"><i class="fa fa-check"></i><b>10.1</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="glm.html"><a href="glm.html#binomial-logistic-regression"><i class="fa fa-check"></i><b>10.1.1</b> Binomial Logistic Regression</a></li>
<li class="chapter" data-level="10.1.2" data-path="glm.html"><a href="glm.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>10.1.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="10.1.3" data-path="glm.html"><a href="glm.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>10.1.3</b> Ordinal Logistic Regression</a></li>
<li class="chapter" data-level="10.1.4" data-path="glm.html"><a href="glm.html#proportional-odds-logistic-regression"><i class="fa fa-check"></i><b>10.1.4</b> Proportional Odds Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="glm.html"><a href="glm.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="10.3" data-path="glm.html"><a href="glm.html#review-questions-8"><i class="fa fa-check"></i><b>10.3</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="surv-anal.html"><a href="surv-anal.html"><i class="fa fa-check"></i><b>11</b> Survival Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="surv-anal.html"><a href="surv-anal.html#kaplan-meier-survival-curve"><i class="fa fa-check"></i><b>11.1</b> Kaplan-Meier Survival Curve</a></li>
<li class="chapter" data-level="11.2" data-path="surv-anal.html"><a href="surv-anal.html#proportional-hazards"><i class="fa fa-check"></i><b>11.2</b> Proportional Hazards</a></li>
<li class="chapter" data-level="11.3" data-path="surv-anal.html"><a href="surv-anal.html#review-questions-9"><i class="fa fa-check"></i><b>11.3</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pred-mod.html"><a href="pred-mod.html"><i class="fa fa-check"></i><b>12</b> Predictive Models</a><ul>
<li class="chapter" data-level="12.1" data-path="pred-mod.html"><a href="pred-mod.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>12.1</b> Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="12.2" data-path="pred-mod.html"><a href="pred-mod.html#cross-validation"><i class="fa fa-check"></i><b>12.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="12.3" data-path="pred-mod.html"><a href="pred-mod.html#balancing-classes"><i class="fa fa-check"></i><b>12.3</b> Balancing Classes</a></li>
<li class="chapter" data-level="12.4" data-path="pred-mod.html"><a href="pred-mod.html#model-performance"><i class="fa fa-check"></i><b>12.4</b> Model Performance</a></li>
<li class="chapter" data-level="12.5" data-path="pred-mod.html"><a href="pred-mod.html#automated-machine-learning-automl"><i class="fa fa-check"></i><b>12.5</b> Automated Machine Learning (AutoML)</a></li>
<li class="chapter" data-level="12.6" data-path="pred-mod.html"><a href="pred-mod.html#review-questions-10"><i class="fa fa-check"></i><b>12.6</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="unsup-lrn.html"><a href="unsup-lrn.html"><i class="fa fa-check"></i><b>13</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="13.1" data-path="unsup-lrn.html"><a href="unsup-lrn.html#factor-analysis"><i class="fa fa-check"></i><b>13.1</b> Factor Analysis</a></li>
<li class="chapter" data-level="13.2" data-path="unsup-lrn.html"><a href="unsup-lrn.html#clustering"><i class="fa fa-check"></i><b>13.2</b> Clustering</a></li>
<li class="chapter" data-level="13.3" data-path="unsup-lrn.html"><a href="unsup-lrn.html#review-questions-11"><i class="fa fa-check"></i><b>13.3</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="net-anal.html"><a href="net-anal.html"><i class="fa fa-check"></i><b>14</b> Network Analysis</a><ul>
<li class="chapter" data-level="14.1" data-path="net-anal.html"><a href="net-anal.html#centrality-measures"><i class="fa fa-check"></i><b>14.1</b> Centrality Measures</a></li>
<li class="chapter" data-level="14.2" data-path="net-anal.html"><a href="net-anal.html#review-questions-12"><i class="fa fa-check"></i><b>14.2</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="data-viz.html"><a href="data-viz.html"><i class="fa fa-check"></i><b>15</b> Data Visualization</a><ul>
<li class="chapter" data-level="15.1" data-path="data-viz.html"><a href="data-viz.html#design-guidelines"><i class="fa fa-check"></i><b>15.1</b> Design Guidelines</a></li>
<li class="chapter" data-level="15.2" data-path="data-viz.html"><a href="data-viz.html#visualization-types"><i class="fa fa-check"></i><b>15.2</b> Visualization Types</a><ul>
<li class="chapter" data-level="15.2.1" data-path="data-viz.html"><a href="data-viz.html#tables"><i class="fa fa-check"></i><b>15.2.1</b> Tables</a></li>
<li class="chapter" data-level="15.2.2" data-path="data-viz.html"><a href="data-viz.html#heatmaps"><i class="fa fa-check"></i><b>15.2.2</b> Heatmaps</a></li>
<li class="chapter" data-level="15.2.3" data-path="data-viz.html"><a href="data-viz.html#scatterplots"><i class="fa fa-check"></i><b>15.2.3</b> Scatterplots</a></li>
<li class="chapter" data-level="15.2.4" data-path="data-viz.html"><a href="data-viz.html#line-graphs"><i class="fa fa-check"></i><b>15.2.4</b> Line Graphs</a></li>
<li class="chapter" data-level="15.2.5" data-path="data-viz.html"><a href="data-viz.html#slopegraphs"><i class="fa fa-check"></i><b>15.2.5</b> Slopegraphs</a></li>
<li class="chapter" data-level="15.2.6" data-path="data-viz.html"><a href="data-viz.html#bar-charts"><i class="fa fa-check"></i><b>15.2.6</b> Bar Charts</a></li>
<li class="chapter" data-level="15.2.7" data-path="data-viz.html"><a href="data-viz.html#waterfall-charts"><i class="fa fa-check"></i><b>15.2.7</b> Waterfall Charts</a></li>
<li class="chapter" data-level="15.2.8" data-path="data-viz.html"><a href="data-viz.html#area-charts"><i class="fa fa-check"></i><b>15.2.8</b> Area Charts</a></li>
<li class="chapter" data-level="15.2.9" data-path="data-viz.html"><a href="data-viz.html#pie-charts"><i class="fa fa-check"></i><b>15.2.9</b> Pie Charts</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="data-viz.html"><a href="data-viz.html#review-questions-13"><i class="fa fa-check"></i><b>15.3</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="storytelling.html"><a href="storytelling.html"><i class="fa fa-check"></i><b>16</b> Data Storytelling</a><ul>
<li class="chapter" data-level="16.1" data-path="storytelling.html"><a href="storytelling.html#know-your-audience"><i class="fa fa-check"></i><b>16.1</b> Know Your Audience</a></li>
<li class="chapter" data-level="16.2" data-path="storytelling.html"><a href="storytelling.html#tldr"><i class="fa fa-check"></i><b>16.2</b> TL;DR</a></li>
<li class="chapter" data-level="16.3" data-path="storytelling.html"><a href="storytelling.html#telling-the-story"><i class="fa fa-check"></i><b>16.3</b> Telling the Story</a></li>
<li class="chapter" data-level="16.4" data-path="storytelling.html"><a href="storytelling.html#reference-material"><i class="fa fa-check"></i><b>16.4</b> Reference Material</a></li>
<li class="chapter" data-level="16.5" data-path="storytelling.html"><a href="storytelling.html#review-questions-14"><i class="fa fa-check"></i><b>16.5</b> Review Questions</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="bibli.html"><a href="bibli.html"><i class="fa fa-check"></i><b>17</b> Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The People Analytics Companion</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lm" class="section level1">
<h1><span class="header-section-number">9</span> Linear Regression</h1>
<p>It’s important to draw a distinction between inferential and predictive models. Inferential models are highly interpretable and their utility is largely in understanding the nature and magnitude of the effect variables have on outcomes. Inferential models also lend to quantifying the extent to which we can generalize the observed effects to the larger population from which the sample was drawn. The objective in predictive modeling is to also to learn from patterns in historical data but for the purpose of achieving the most accurate predictions for future events – even at the expense of interpretability. To be clear, this isn’t to say that predictive models cannot be interpreted – they certainly can – but there are relatively few applications for predictive modeling in people analytics because models generally need to be highly interpretable to support action planning.</p>
<p>This chapter is dedicated to inferential modeling to support a working understanding of how to interpret model output and communicate clear, data-driven narratives that respect the nuance and noise characteristic of people data. Chapter <a href="pred-mod.html#pred-mod">12</a> will provide an overview of predictive modeling frameworks.</p>
<p>Regression is perhaps the most important statistical learning technique for people analytics. If you have taken a statistics course at the undergraduate or graduate levels, you have surely already encountered it. Let’s first develop an intuitive understanding of the mechanics of regression.</p>
<p>Imagine we are sitting at a large public park in NYC on a nice fall afternoon. If asked to estimate the annual compensation of the next person to walk by, how would you estimate this in the absence of any additional information? Most would likely estimate the <em>average</em> annual compensation of everyone capable of walking by. Since this would include both residents and visitors, this would be a very large population of people! The obvious limitation with this approach is that among the large group of people capable of walking by, there is likely a significant range of annual compensation values. Many walking by may be children, unemployed, or retirees who earn no annual compensation, while others may be highly compensated senior executives at the pinnacle of their careers. Since the range of annual compensation could be zero to millions of dollars, estimating the average of such a large population is likely going to be highly inaccurate without more information.</p>
<p>Let’s consider that we are sitting outside on a weekday afternoon. Should this influence our annual compensation estimate? It is likely that we can eliminate a large segment of those likely to walk by, as we would expect most children to be in school on a typical fall weekday afternoon. It’s also unlikely that those who are employed and not on vacation will walk by on a fall weekday afternoon. Therefore, factoring in that it is a weekday should limit the size of the population which in turn may reduce the range of annual compensation values for our population of passerbys.</p>
<p>Let’s now consider that the park is open only to invited guests for a symposium on people analytics. Though it may be difficult to believe, a relatively small subset of the population is likely interested in attending such a symposium, so this information will likely be quite helpful in reducing the size of the population who could walk by. This should further reduce the range of annual compensation since we probably have a good idea of the profile of those most likely to attend. This probably also lessens (or altogether eliminates) the importance of the weekday factor in explaining why people vary in the amount of compensation they earn each year. That an important variable may become unimportant in the presence of another variable is a key feature of regression.</p>
<p>Furthermore, let’s consider that only those who reside in NYC and Boise were invited, and that the next person to walk by resides in Boise. Most companies apply a significant cost of living multiplier to the compensation for those in an expensive region such as NYC, resulting in a significant difference in compensation relative to those residing in a much less expensive city like Boise – all else being equal. Therefore, if we can partition attendees into two groups based on their geography, this should limit the range of annual compensation significantly <em>within each</em> – likely making the average compensation in each group a more nuanced and reasonable estimate.</p>
<p>What if we also learn the specific zip code in which the next passerby from Boise resides? The important information is likely captured at the larger city level (NYC vs. Boise), as the compensation for the specific zip codes within each city are unlikely to vary to a significant degree. Assuming this is true, it probably would not make sense to consider both the city name and zip code since they are effectively redundant pieces of information with regard to explaining differences in annual compensation.</p>
<p>What if we learn that the next person to walk by will be wearing a blue shirt? Does this influence your estimate? Unless there is research to suggest shirt color and earnings are related, this information will likely not contribute any significant information to our understanding of why people vary in the amount of compensation they earn and should, therefore, not be considered.</p>
<p>You can probably think of many relevant variables that would help further narrow the range of annual compensation. These may include job, level, years of experience, education, among other factors. The main thing to understand is that for each group of observations with the same characteristics – such as senior analysts with a graduate degree who reside in NYC – there is a distribution of annual compensation. This distribution reflects unexplained variance. That is, we do not have information to explain why the compensation for each and every person is not the same and in social science contexts, it simply is not practical to explain 100 percent of the variance in outcomes. For example, two people may be similar on dozens of factors (experience, education, skills) but one was simply a more effective negotiator when offered the same role and commanded a higher salary. It’s likely we do not have data on salary negotiation ability so this information would leave us with unexplained variance in compensation. The goal is simply to identify the variables that provide the most information in helping us tighten the distribution so that estimating the average value will generally be an accurate estimate for those in the larger population with the same characteristics.</p>
<p>While we can generally improve our estimates with more relevant information (not shirt color or residential zip code in this case), it is important to understand that samples which are too small (<span class="math inline">\(n\)</span> &lt; 30) lend to anomalies; modeling noise in sparse data can result in models that are unlikely to generalize beyond the sample data. For example, if the only people from Boise to attend the people analytics symposium happen to be two ultra wealthy tech entrepreneurs who earn millions each year, it would not be appropriate to use this as the basis for our estimates of all future attendees from Boise. This is a phenomenon known as overfitting that will be covered later in this chapter.</p>
<p>This is the essence of linear regression modeling: find a limited number of variables which independently and/or jointly provide significant information that helps explain (by reducing) variance around the average value. As illustrated in this example, adding additional variables (information) can impact the importance of other variables or may offer no incremental information at all. In the subsequent sections, we will cover how to identify which variables are important and how to quantify the effect they have on the outcome.</p>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">9.1</span> Simple Linear Regression</h2>
<p><strong>Simple linear regression</strong> is a simple technique for estimating the value of a quantitative DV, denoted as <span class="math inline">\(Y\)</span>, on the basis of a single IV, denoted as <span class="math inline">\(X\)</span>. It is assumed that there is an approximately linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Often, this relationship is expressed as <em>regressing</em> <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> and is defined mathematically as:</p>
<p><span class="math display">\[ Y = \beta_0 + \beta_1 X + \epsilon, \]</span></p>
<p>where <span class="math inline">\(\beta_0\)</span> is the expected value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X = 0\)</span> (the <em>intercept</em>), and <span class="math inline">\(\beta_1\)</span> represents the average change in <span class="math inline">\(Y\)</span> for a one-unit increase in <span class="math inline">\(X\)</span> (the <em>slope</em>). <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown <em>parameters</em> or <em>coefficients</em>. The error term, <span class="math inline">\(\epsilon\)</span>, acknowledges that there is variation in <span class="math inline">\(Y\)</span> not accounted for by this simple linear model. In other words, it is highly unlikely that there is a perfectly linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, as additional variables not included in the model are likely influencing <span class="math inline">\(Y\)</span>.</p>
<p>Once we estimate the unknown model coefficients, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we can estimate <span class="math inline">\(Y\)</span> for a particular value of <span class="math inline">\(X\)</span> by calculating:</p>
<p><span class="math display">\[ \hat{y} = \hat{\beta}_0 + \hat{\beta_1}x, \]</span></p>
<p>where <span class="math inline">\(\hat{y}\)</span> represents an estimate of <span class="math inline">\(Y\)</span> for a particular value of <span class="math inline">\(X\)</span> equal to <span class="math inline">\(x\)</span>. The <span class="math inline">\(\hat{}\)</span> symbol is used to denote an estimated value of an unknown coefficient, parameter, or outcome.</p>
<p><span class="math display">\[\beta_0 = \]</span></p>
<p><span class="math display">\[\beta_1 = \]</span></p>
<p><span class="math display">\[RSS = \]</span></p>
<p>In R, we can build (or <em>fit</em>) a simple linear regression model using the <code>lm()</code> function. The syntax is <code>lm(Y ~ X, dataset)</code>. Let’s fit a linear model to regress YTD sales on engagement and use the <code>flextable</code> package to present model results in a more elegant tabular summary than the base R default:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># Load libraries</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(corrplot)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="kw">library</span>(reshape2)</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw">library</span>(flextable)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co"># Load employee data</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9">employees &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;/Users/craig.starbuck/Library/Mobile Documents/com~apple~CloudDocs/Documents/People Analytics Book/GitHub/peopleanalytics_lifecycle_book/data/employees.csv&quot;</span>)</a>
<a class="sourceLine" id="cb1-10" data-line-number="10"></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co"># Subset employees data frame; sales are only applicable for those in sales positions</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12">data &lt;-<span class="st"> </span><span class="kw">subset</span>(employees, job_title <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;Sales Executive&#39;</span>, <span class="st">&#39;Sales Representative&#39;</span>))</a>
<a class="sourceLine" id="cb1-13" data-line-number="13"></a>
<a class="sourceLine" id="cb1-14" data-line-number="14"><span class="co"># Regress YTD sales on engagement</span></a>
<a class="sourceLine" id="cb1-15" data-line-number="15">slm.fit &lt;-<span class="st"> </span><span class="kw">lm</span>(ytd_sales <span class="op">~</span><span class="st"> </span>engagement, data)</a>
<a class="sourceLine" id="cb1-16" data-line-number="16"></a>
<a class="sourceLine" id="cb1-17" data-line-number="17"><span class="co"># Produce tabular summary for model results using flextable</span></a>
<a class="sourceLine" id="cb1-18" data-line-number="18">flextable<span class="op">::</span><span class="kw">as_flextable</span>(slm.fit)</a></code></pre></div>
<template id="110a5b9d-be6c-4b4c-a219-70ee88e423cb"><style>
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-9918772e{}.cl-991077ea{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-991077fe{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-99108c94{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-99108ca8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9910c3ee{width:92.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c402{width:33.4pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c40c{width:52.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c416{width:75.6pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c420{width:81.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c42a{width:54.2pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c434{width:92.7pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c43e{width:54.2pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c448{width:33.4pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c452{width:52.9pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c453{width:81.7pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c45c{width:75.6pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c466{width:81.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c470{width:52.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c47a{width:75.6pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c484{width:33.4pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c48e{width:92.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c498{width:54.2pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c499{width:75.6pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4a2{width:54.2pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4ac{width:52.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4b6{width:92.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4b7{width:81.7pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4c0{width:33.4pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4ca{width:75.6pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4d4{width:81.7pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4de{width:52.9pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4e8{width:33.4pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4e9{width:92.7pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9910c4f2{width:54.2pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table class='cl-9918772e'>
<thead><tr style="overflow-wrap:break-word;"><td class="cl-9910c4d4"><p class="cl-99108c94"><span class="cl-991077ea"></span></p></td><td class="cl-9910c4ca"><p class="cl-99108ca8"><span class="cl-991077ea">Estimate</span></p></td><td class="cl-9910c4e9"><p class="cl-99108ca8"><span class="cl-991077ea">Standard Error</span></p></td><td class="cl-9910c4de"><p class="cl-99108ca8"><span class="cl-991077ea">t value</span></p></td><td class="cl-9910c4f2"><p class="cl-99108ca8"><span class="cl-991077ea">Pr(&gt;|t|)</span></p></td><td class="cl-9910c4e8"><p class="cl-99108c94"><span class="cl-991077ea"></span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-9910c420"><p class="cl-99108c94"><span class="cl-991077ea">(Intercept)</span></p></td><td class="cl-9910c416"><p class="cl-99108ca8"><span class="cl-991077ea">2,431.673</span></p></td><td class="cl-9910c3ee"><p class="cl-99108ca8"><span class="cl-991077ea">10,321.632</span></p></td><td class="cl-9910c40c"><p class="cl-99108ca8"><span class="cl-991077ea">0.236</span></p></td><td class="cl-9910c42a"><p class="cl-99108ca8"><span class="cl-991077ea">0.8139</span></p></td><td class="cl-9910c402"><p class="cl-99108c94"><span class="cl-991077ea"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-9910c453"><p class="cl-99108c94"><span class="cl-991077ea">engagement</span></p></td><td class="cl-9910c45c"><p class="cl-99108ca8"><span class="cl-991077ea">28,002.666</span></p></td><td class="cl-9910c434"><p class="cl-99108ca8"><span class="cl-991077ea">3,696.432</span></p></td><td class="cl-9910c452"><p class="cl-99108ca8"><span class="cl-991077ea">7.576</span></p></td><td class="cl-9910c43e"><p class="cl-99108ca8"><span class="cl-991077ea">0.0000</span></p></td><td class="cl-9910c448"><p class="cl-99108c94"><span class="cl-991077ea">***</span></p></td></tr></tbody><tfoot><tr style="overflow-wrap:break-word;"><td  colspan="6"class="cl-9910c466"><p class="cl-99108ca8"><span class="cl-991077fe">Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05 &lt; '.' &lt; 0.1 &lt; '' &lt; 1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  colspan="6"class="cl-9910c4b7"><p class="cl-99108c94"><span class="cl-991077ea"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td  colspan="6"class="cl-9910c4b7"><p class="cl-99108c94"><span class="cl-991077ea">Residual standard error: 5.274e+04 on 407 degrees of freedom</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  colspan="6"class="cl-9910c4b7"><p class="cl-99108c94"><span class="cl-991077ea">Multiple R-squared: 0.1236, Adjusted R-squared: 0.1214</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  colspan="6"class="cl-9910c4b7"><p class="cl-99108c94"><span class="cl-991077ea">F-statistic: 57.39 on 407 and 1 DF, p-value: 0.0000</span></p></td></tr></tfoot></table></div></template>
<div class="flextable-shadow-host" id="0a2d9584-edd7-4ded-aa04-354c4a9d0bf1"></div>
<script>
var dest = document.getElementById("0a2d9584-edd7-4ded-aa04-354c4a9d0bf1");
var template = document.getElementById("110a5b9d-be6c-4b4c-a219-70ee88e423cb");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>There are several important pieces of information in this output:</p>
<ul>
<li><code>Estimate</code>: <em>Unstandardized</em> Beta coefficient associated with the respective predictor</li>
<li><code>Standard Error</code>: Average distance between the observed and estimated values per the fitted regression line</li>
<li><code>t value</code>: <code>Estimate</code> / <code>Standard Error</code>. Larger values provide more evidence for a non-zero coefficient (relationship) in the population.</li>
<li><code>Pr(&gt;|t|)</code>: <span class="math inline">\(p\)</span>-value for evaluating whether there is sufficient evidence in the sample that the coefficient (relationship) between the respective predictor and response variable is not 0 in the population (i.e., <span class="math inline">\(x\)</span> has a relationship with <span class="math inline">\(y\)</span>)</li>
<li><code>Intercept</code>: Mean value of the response variable when all predictors are equal to 0. Note that the interpretation of the intercept is often nonsensical since many predictors cannot have 0 values (e.g., age, height, weight, IQ).</li>
<li><code>Signif. codes</code>: Symbols to quickly ascertain whether predictors are significant at key levels, such as <span class="math inline">\(p\)</span> &lt; .001 (<em><strong>), <span class="math inline">\(p\)</span> &lt; .01 (</strong>), or <span class="math inline">\(p\)</span> &lt; .05 (</em>).</li>
<li><code>Residual standard error</code>: Measure of model fit which reflects the standard deviation of the residuals (<span class="math inline">\(\sqrt {\sum(y-\hat{y})^2 / df}\)</span>)</li>
<li><code>Degrees of freedom</code>: <span class="math inline">\(n\)</span> - <span class="math inline">\(p\)</span>, where <span class="math inline">\(n\)</span> is the number of observations and <span class="math inline">\(p\)</span> is the number of predictors</li>
<li><code>Multiple R-squared</code>: Percent of variance in <span class="math inline">\(y\)</span> (when multiplied by 100) explained by the predictors in the model. This is also known as the <strong>Coefficient of Determination</strong>. For simple linear regression, this is simply the squared value of Pearson’s <span class="math inline">\(r\)</span> for the bivariate relationship between the predictor and response (execute <code>cor(data$engagement, data$ytd_sales)^2</code> to validate).</li>
<li><code>Adjusted R-squared</code>: Modified version of <span class="math inline">\(R^2\)</span> that adjusts the estimate for non-significant predictors. A large delta between <span class="math inline">\(R^2\)</span> and Adjusted <span class="math inline">\(R^2\)</span> coefficients generally indicates a model containing a larger number of non-significant predictors relative to when <span class="math inline">\(R^2\)</span> and Adjusted <span class="math inline">\(R^2\)</span> values are similar.</li>
<li><code>F-statistic</code>: Statistic used in conjunction with the <code>p-value</code> for testing differences between the specified model and an intercept-only model (a model with no predictors). This test helps us evaluate whether our predictors are helpful in explaining variance in <span class="math inline">\(y\)</span>.</li>
</ul>
<p>The output of this simple linear regression model indicates that for each level increase in engagement, the average increase in YTD sales is 28,003 USD (<span class="math inline">\(\beta\)</span> = 28,003, <span class="math inline">\(t\)</span>(407) = 7.58, <span class="math inline">\(p\)</span> &lt; .001). While it may be tempting to race to a conclusion that employee engagement has a significant influence on business outcomes such as sales, we know that bivariate relationships may be spurious; that is, engagement may be correlated with another variable that is actually influencing sales. In practice, a simple linear model is rarely sufficient for explaining a meaningful percent of variance in a response variable, so additional predictors are often needed to capture the complex and nuanced relationships characteristic of people analytics problems.</p>
<p><strong>Linear Assumptions &amp; High Leverage Checks</strong></p>
<p>From the outset, we must determine if a linear model is appropriate for the data at hand. In other words, is there a linear association between the predictor (or combination of predictors) and the response variable? If the relationship is not linear, proceeding with a linear model may result in invalid inferences and conclusions.</p>
<p>We can evaluate the ‘Residuals vs Fitted’ and ‘Normal Q-Q’ plots in Figure <a href="lm.html#fig:slm-diagnostics">9.1</a> to evaluate the linear assumptions of homoscedasticity, normality, and linearity. In practice, linear assumptions are rarely – if ever – perfectly met, but there must be evidence that the relationships being investigated are <em>generally</em> linear in order to leverage a linear model.</p>
<p>In addition, we can review the Cook’s distance plot in Figure <a href="lm.html#fig:slm-diagnostics">9.1</a> to identify high leverage observations. That is, rows of data that contain different enough values that they may heavily influence the regression line. Cook’s distance provides a measure of how much the values our model estimates for all observations changes if the suspect observation is removed from the data; higher numbers indicate stronger influence. R conveniently labels the three observations with the highest leverage. Since we don’t want a single observation to have material impact on our model, these observations need to be addressed if the Cook’s <span class="math inline">\(d\)</span> value is considerably higher than that of other observations.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:slm-diagnostics"></span>
<img src="The_People_Analytics_Companion_files/figure-html/slm-diagnostics-1.png" alt="Simple Linear Regression Model Diagnostics" width="100%" />
<p class="caption">
Figure 9.1: Simple Linear Regression Model Diagnostics
</p>
</div>
<p>Next, we will produce a histogram to visualize the distribution of model residuals (differences between estimated and observed YTD sales values). In the majority of cases, the residual should be 0 – that is, in most cases the model correctly estimates YTD sales, and there is no difference between estimated and observed values.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">hist</span>(slm.fit<span class="op">$</span>resid, <span class="dt">main =</span> <span class="st">&quot;Distribution of Model Residuals&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Sales Estimate Residuals&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">las =</span> <span class="dv">1</span>, <span class="dt">breaks =</span> <span class="dv">10</span>)</a></code></pre></div>
<p><img src="The_People_Analytics_Companion_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p><strong>Parameter Estimation</strong></p>
<p>Ordinary Least Squares (OLS) is the most common method for estimating unknown parameters in a linear regression model.</p>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2><span class="header-section-number">9.2</span> Multiple Linear Regression</h2>
<p><span class="math display">\[ Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + {...} + \beta_p X_p + \epsilon \]</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># Define a vector of predictors</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">predictors &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;engagement&quot;</span>, <span class="st">&quot;job_lvl&quot;</span>)</a></code></pre></div>
<p><strong>Multicollinearity Diagnostics</strong></p>
<p>Models should be built with predictors that have a strong association with the outcome but not with one another. If predictors are highly correlated with each other, it indicates that they do not provide unique information; they are redundant. While it does not make intuitive sense to use redundant predictors, you should be aware that multicollinearity can cause serious issues with the underlying math. These issues can result in the effects of significant predictors being suppressed, a negative sign/effect showing in the output when a positive association between the predictor and the outcome actually exists (or vice versa), etc. Simply put, if problematic collinearity is not addressed, false conclusions may be drawn from the model output which may lead to bad business decisions.</p>
<p>Kuhn and Johnson (2013) recommend the approach outlined below to address multicollinearity:</p>
<ol style="list-style-type: decimal">
<li>Execute lines 104-109 below. Determine the two predictors associated with the largest absolute pairwise correlation (whether they are positively or negatively related does not matter) – call them predictors A and B. The code below makes this easy as it orders pairs of predictors based on their absolute correlation (from highest to lowest), so you only need to look at the first row in the output.</li>
<li>Execute lines 113-114 below to build a correlation matrix for the predictors. Determine the average absolute correlation between predictor A and the other variables. Do the same for predictor B. The combination of the summary() and abs() functions on line 114 enables an easy evaluation of which predictor is more highly correlated with other predictors (simply compare the <code>mean</code> for the predictors of interest).</li>
<li>If predictor A has a larger average absolute correlation, remove it from the <code>predictors</code> vector; otherwise, remove predictor B. The exception to this rule is when predictors A and B have similar average absolute correlations with all other predictors but the predictor with the slightly higher correlation is a key variable that, if dropped, will prevent you from addressing one or more stated objectives for this assignment (be sure to reread the overall purpose for this assignment if this is unclear).</li>
<li>Repeat steps 1-3 until no absolute correlations are &gt;= .7.</li>
</ol>
<p>All variables for this assignment are numeric (no categorical variables), which means we can simply evaluate correlations among all without any dummy coding. The code below will create a correlation matrix using the predictors specified in the <code>predictors</code> vector initialized at the beginning of this script.</p>
<p>As you iteratively address multicollinearity issues using the aforementioned approach, simply remove from the <code>predictors</code> vector the variable you wish to omit and then execute that line of code again to inform R that the predictors have been updated. You can then re-execute the code below to produce a new correlation matrix with the revised subset of predictors.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">M1 &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">cor</span>(data[ ,<span class="kw">paste</span>(predictors)]), <span class="dv">2</span>) <span class="co"># Build a correlation matrix named M1.</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">M1[M1 <span class="op">==</span><span class="st"> </span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="ot">NA</span> <span class="co"># Drop perfect correlations (e.g., relationships of variables with themselves).</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">M1 &lt;-<span class="st"> </span><span class="kw">na.omit</span>(reshape2<span class="op">::</span><span class="kw">melt</span>(M1)) <span class="co"># Melt the data; convert columns into rows for ease of use.</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4">M1 &lt;-<span class="st"> </span>M1[<span class="kw">order</span>(<span class="op">-</span><span class="kw">abs</span>(M1<span class="op">$</span>value)),] <span class="co"># Sort order the data.</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="kw">colnames</span>(M1) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Variable 1&quot;</span>, <span class="st">&quot;Variable 2&quot;</span>, <span class="st">&quot;Correlation&quot;</span>) <span class="co"># Assign meaningful names to the columns in the matrix.</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">M1 <span class="co"># Display contents of the matrix.</span></a></code></pre></div>
<pre><code>##   Variable 1 Variable 2 Correlation
## 2    job_lvl engagement        0.04
## 3 engagement    job_lvl        0.04</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">M2 &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">cor</span>(data[ ,<span class="kw">paste</span>(predictors)]), <span class="dv">2</span>) <span class="co"># Build a correlation matrix named M2.</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw">summary</span>(<span class="kw">abs</span>(M2)) <span class="co"># Display descriptive stats for the absolute value of each bivariate relationship to inform which variables to drop.</span></a></code></pre></div>
<pre><code>##    engagement      job_lvl    
##  Min.   :0.04   Min.   :0.04  
##  1st Qu.:0.28   1st Qu.:0.28  
##  Median :0.52   Median :0.52  
##  Mean   :0.52   Mean   :0.52  
##  3rd Qu.:0.76   3rd Qu.:0.76  
##  Max.   :1.00   Max.   :1.00</code></pre>
<p>Once multicollinearity has been addressed (no two predictors have an absolute correlation of .7 or higher), execute the code below to ensure the VIF for remaining predictors is below 5 (a sanity check, as it were).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co"># car::vif(mlm(paste(&quot;ytd_sales ~ &quot;, paste(predictors, collapse = &quot;+&quot;)), data))</span></a></code></pre></div>
</div>
<div id="fit-linear-model-with-subset-of-important-variables" class="section level2">
<h2><span class="header-section-number">9.3</span> Fit Linear Model (with Subset of Important Variables)</h2>
<p>The following lines of code will fit a linear regression model using the subset of predictors for which no collinearity problems are present (the result of your work from the prior section).</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># mlm.fit.sub &lt;- lm(paste(&quot;ytd_sales ~ &quot;, paste(predictors, collapse = &quot;+&quot;)), data)</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="co"># summary(lm.fit.sub)</span></a></code></pre></div>
<p>Next, we need to reduce our model to the subset of predictors with statistically significant relationships with SALES. Backward Stepwise Selection is the simplest of all variable selection procedures, and the approach we will use for this assignment. The steps for this procedure are outlined below:</p>
<ol style="list-style-type: decimal">
<li>Remove the predictor with the highest p-value greater than the critical value (.05).</li>
<li>Refit the model (i.e., modify the ‘predictors’ vector to exclude the irrelevant variable, and then re-execute lines 122-123 to refit the linear model and display output), and repeat step 1.</li>
<li>Stop when all p-values are less than the critical value.</li>
</ol>
<p>When you have reduced the model to a subset of predictors that all have statistically significant associations with SALES and no evidence of problematic collinearity, proceed to the final step below.</p>
<p>We will now produce a standardized Estimate for each predictor to evaluate relative importance with respect to SALES. We will accomplish this by scaling both the independent and dependent variables to adjust for differences in the spread of values (R does not produce standardized Estimates by default with the lm() function). Simply run the code below, and the Estimates shown in the output will now reflect standardized Beta coefficients. Adjusting for the different units of measurement, we can now determine which variable has the largest effect on SALES.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co"># mlm.fit.sub.scaled &lt;- lm(paste0(&quot;scale(ytd_sales) ~ scale(&quot;, paste(predictors, collapse = &quot;)+scale(&quot;),&quot;)&quot;), data)</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="co"># summary(mlm.fit.sub.scaled)</span></a></code></pre></div>
<div id="moderation" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Moderation</h3>
</div>
<div id="mediation" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Mediation</h3>
</div>
</div>
<div id="polynomial-regression" class="section level2">
<h2><span class="header-section-number">9.4</span> Polynomial Regression</h2>
</div>
<div id="hierarchical-models" class="section level2">
<h2><span class="header-section-number">9.5</span> Hierarchical Models</h2>
</div>
<div id="review-questions-7" class="section level2">
<h2><span class="header-section-number">9.6</span> Review Questions</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="aod.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["The_People_Analytics_Companion.pdf", "The_People_Analytics_Companion.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
