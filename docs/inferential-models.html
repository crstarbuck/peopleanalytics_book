<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Inferential Models | An Introduction to the People Analytics Lifecycle: With Applications in R and Data Studio</title>
  <meta name="description" content="An end-to-end guide for successful analytics projects in the social sciences" />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Inferential Models | An Introduction to the People Analytics Lifecycle: With Applications in R and Data Studio" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An end-to-end guide for successful analytics projects in the social sciences" />
  <meta name="github-repo" content="crstarbuck/peopleanalytics-lifecycle-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Inferential Models | An Introduction to the People Analytics Lifecycle: With Applications in R and Data Studio" />
  
  <meta name="twitter:description" content="An end-to-end guide for successful analytics projects in the social sciences" />
  

<meta name="author" content="Craig Starbuck" />


<meta name="date" content="2022-01-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analysis-of-differences.html"/>
<link rel="next" href="predictive-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i><b>1</b> Foreword</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>3</b> Getting Started</a><ul>
<li class="chapter" data-level="3.1" data-path="getting-started.html"><a href="getting-started.html#guiding-principles"><i class="fa fa-check"></i><b>3.1</b> Guiding Principles</a></li>
<li class="chapter" data-level="3.2" data-path="getting-started.html"><a href="getting-started.html#tools"><i class="fa fa-check"></i><b>3.2</b> Tools</a></li>
<li class="chapter" data-level="3.3" data-path="getting-started.html"><a href="getting-started.html#d-framework"><i class="fa fa-check"></i><b>3.3</b> 4D Framework</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="research-methods.html"><a href="research-methods.html"><i class="fa fa-check"></i><b>4</b> Research Methods</a></li>
<li class="chapter" data-level="5" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html"><i class="fa fa-check"></i><b>5</b> Statistical Fundamentals</a><ul>
<li class="chapter" data-level="5.1" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#populations-samples"><i class="fa fa-check"></i><b>5.1</b> Populations &amp; Samples</a></li>
<li class="chapter" data-level="5.2" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#univariate-analysis"><i class="fa fa-check"></i><b>5.2</b> Univariate Analysis</a><ul>
<li class="chapter" data-level="5.2.1" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.1</b> Measures of Central Tendency</a></li>
<li class="chapter" data-level="5.2.2" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#measures-of-spread"><i class="fa fa-check"></i><b>5.2.2</b> Measures of Spread</a></li>
<li class="chapter" data-level="5.2.3" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#bivariate-analysis"><i class="fa fa-check"></i><b>5.2.3</b> Bivariate Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#inferential-statistics"><i class="fa fa-check"></i><b>5.3</b> Inferential Statistics</a><ul>
<li class="chapter" data-level="5.3.1" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#introduction-to-probability"><i class="fa fa-check"></i><b>5.3.1</b> Introduction to Probability</a></li>
<li class="chapter" data-level="5.3.2" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#central-limit-theorem"><i class="fa fa-check"></i><b>5.3.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="5.3.3" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#confidence-intervals"><i class="fa fa-check"></i><b>5.3.3</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#exercises"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="measurement-sampling.html"><a href="measurement-sampling.html"><i class="fa fa-check"></i><b>6</b> Measurement &amp; Sampling</a></li>
<li class="chapter" data-level="7" data-path="data-preparation.html"><a href="data-preparation.html"><i class="fa fa-check"></i><b>7</b> Data Preparation</a><ul>
<li class="chapter" data-level="7.1" data-path="data-preparation.html"><a href="data-preparation.html#data-wrangling"><i class="fa fa-check"></i><b>7.1</b> Data Wrangling</a></li>
<li class="chapter" data-level="7.2" data-path="data-preparation.html"><a href="data-preparation.html#feature-engineering"><i class="fa fa-check"></i><b>7.2</b> Feature Engineering</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="analysis-of-differences.html"><a href="analysis-of-differences.html"><i class="fa fa-check"></i><b>8</b> Analysis of Differences</a><ul>
<li class="chapter" data-level="8.1" data-path="analysis-of-differences.html"><a href="analysis-of-differences.html#comparing-2-distributions"><i class="fa fa-check"></i><b>8.1</b> Comparing 2 Distributions</a></li>
<li class="chapter" data-level="8.2" data-path="analysis-of-differences.html"><a href="analysis-of-differences.html#comparing-3-distributions"><i class="fa fa-check"></i><b>8.2</b> Comparing 3+ Distributions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferential-models.html"><a href="inferential-models.html"><i class="fa fa-check"></i><b>9</b> Inferential Models</a><ul>
<li class="chapter" data-level="9.1" data-path="inferential-models.html"><a href="inferential-models.html#regression"><i class="fa fa-check"></i><b>9.1</b> Regression</a></li>
<li class="chapter" data-level="9.2" data-path="inferential-models.html"><a href="inferential-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.2</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="9.2.1" data-path="inferential-models.html"><a href="inferential-models.html#parameter-estimation"><i class="fa fa-check"></i><b>9.2.1</b> Parameter Estimation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="inferential-models.html"><a href="inferential-models.html#multiple-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="9.3.1" data-path="inferential-models.html"><a href="inferential-models.html#moderation"><i class="fa fa-check"></i><b>9.3.1</b> Moderation</a></li>
<li class="chapter" data-level="9.3.2" data-path="inferential-models.html"><a href="inferential-models.html#mediation"><i class="fa fa-check"></i><b>9.3.2</b> Mediation</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="inferential-models.html"><a href="inferential-models.html#polynomial-regression"><i class="fa fa-check"></i><b>9.4</b> Polynomial Regression</a></li>
<li class="chapter" data-level="9.5" data-path="inferential-models.html"><a href="inferential-models.html#logistic-regression"><i class="fa fa-check"></i><b>9.5</b> Logistic Regression</a><ul>
<li class="chapter" data-level="9.5.1" data-path="inferential-models.html"><a href="inferential-models.html#binomial"><i class="fa fa-check"></i><b>9.5.1</b> Binomial</a></li>
<li class="chapter" data-level="9.5.2" data-path="inferential-models.html"><a href="inferential-models.html#multinomial"><i class="fa fa-check"></i><b>9.5.2</b> Multinomial</a></li>
<li class="chapter" data-level="9.5.3" data-path="inferential-models.html"><a href="inferential-models.html#ordinal"><i class="fa fa-check"></i><b>9.5.3</b> Ordinal</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="inferential-models.html"><a href="inferential-models.html#hierarchical-models"><i class="fa fa-check"></i><b>9.6</b> Hierarchical Models</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="predictive-models.html"><a href="predictive-models.html"><i class="fa fa-check"></i><b>10</b> Predictive Models</a><ul>
<li class="chapter" data-level="10.1" data-path="predictive-models.html"><a href="predictive-models.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>10.1</b> Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="10.2" data-path="predictive-models.html"><a href="predictive-models.html#cross-validation"><i class="fa fa-check"></i><b>10.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="10.3" data-path="predictive-models.html"><a href="predictive-models.html#balancing-classes"><i class="fa fa-check"></i><b>10.3</b> Balancing Classes</a></li>
<li class="chapter" data-level="10.4" data-path="predictive-models.html"><a href="predictive-models.html#model-performance"><i class="fa fa-check"></i><b>10.4</b> Model Performance</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="automated-machine-learning-automl.html"><a href="automated-machine-learning-automl.html"><i class="fa fa-check"></i><b>11</b> Automated Machine Learning (AutoML)</a></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning-models.html"><a href="unsupervised-learning-models.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning Models</a><ul>
<li class="chapter" data-level="12.1" data-path="unsupervised-learning-models.html"><a href="unsupervised-learning-models.html#factor-analysis"><i class="fa fa-check"></i><b>12.1</b> Factor Analysis</a></li>
<li class="chapter" data-level="12.2" data-path="unsupervised-learning-models.html"><a href="unsupervised-learning-models.html#clustering"><i class="fa fa-check"></i><b>12.2</b> Clustering</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>13</b> Data Visualization</a></li>
<li class="chapter" data-level="14" data-path="data-storytelling.html"><a href="data-storytelling.html"><i class="fa fa-check"></i><b>14</b> Data Storytelling</a></li>
<li class="chapter" data-level="15" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i><b>15</b> Bibliography</a></li>
<li class="chapter" data-level="16" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>16</b> Appendix</a><ul>
<li class="chapter" data-level="16.1" data-path="appendix.html"><a href="appendix.html#exercise-solutions"><i class="fa fa-check"></i><b>16.1</b> Exercise Solutions</a></li>
<li class="chapter" data-level="16.2" data-path="appendix.html"><a href="appendix.html#d-framework-1"><i class="fa fa-check"></i><b>16.2</b> 4D Framework</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to the People Analytics Lifecycle</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferential-models" class="section level1">
<h1><span class="header-section-number">9</span> Inferential Models</h1>
<p>It’s important to draw a distinction between inferential and predictive models. Inferential models are highly interpretable and their utility is largely in understanding the nature and magnitude of the effect variables have on outcomes. Inferential models also lend to quantifying the extent to which we can generalize the observed effects to the larger population from which the sample was drawn. The objective in predictive modeling is to also to learn from patterns in historical data but for the purpose of achieving the most accurate predictions of future events – even at the expense of interpretability. To be clear, this isn’t to say that predictive models cannot be interpreted – they certainly can – but I’ve seen relatively few applications for predictive modeling in people analytics because models generally need to be highly interpretable to support action planning.</p>
<p>This chapter is dedicated to inferential models to support a working understanding of how to interpret model output and communicate clear, data-driven narratives that respect the nuance and noise characteristic of people data. The following chapter will provide an overview of predictive modeling frameworks.</p>
<div id="regression" class="section level2">
<h2><span class="header-section-number">9.1</span> Regression</h2>
<p>Regression is perhaps the most important statistical learning technique for people analytics. If you have taken a statistics course at the undergraduate or graduate levels, you have surely already encountered it. Before diving into the math to understand the mechanics of regression, let’s develop an intuitive understanding.</p>
<p>Imagine we are sitting at a large public park in NYC on a nice fall afternoon. If asked to estimate the annual compensation of the next person to walk by, in the absence of any additional information how would you estimate this? Most would likely estimate the <i>average</i> annual compensation of everyone capable of walking by. Since this would include both residents and visitors, this would be a very large group of people! The obvious limitation with this approach is that among the large group of people capable of walking by, there is likely a significant range of annual compensation values. Many walking by may be children, unemployed, or retirees who earn no annual compensation, while others may be highly compensated senior executives at the pinnacle of their careers. Since the range of annual compensation could be zero to billions of dollars, estimating the average of such a large population is likely going to be highly inaccurate without more information about who may walk by.</p>
<p>Let’s consider that we are sitting outside on a weekday afternoon. Should this influence our annual compensation estimate? It is likely that we can eliminate a large segment of those likely to walk by, as we would expect most children to be in school on a typical fall weekday afternoon. It’s also unlikely that those who are employed and not on vacation will walk by on a fall weekday afternoon. Therefore, factoring in that it is a weekday should limit the size of the population which in turn may reduce the range of annual compensation values for our population of passerbys.</p>
<p>Let’s now consider that the park is open only to invited guests for a symposium on people analytics. Though it may be difficult to believe, a relatively small subset of the population is likely interested in attending such a symposium, so this information will likely be very helpful in reducing the size of the population who could walk by, which should further reduce the range of annual compensation since we probably have a good idea of the profile of those most likely to attend. This probably also lessens (or altogether eliminates) the importance of the weekday factor in explaining why people vary in the amount of compensation they earn each year.</p>
<p>Furthermore, let’s consider that only those who reside in NYC and Boise were invited, and that the next person to walk by resides in Boise. Most companies apply a significant cost of living multiplier to the compensation for those in an expensive region such as NYC, resulting in a significant difference in compensation relative to those residing in a much less expensive city like Boise – all else being equal. Therefore, if we can partition attendees into two groups based on their geography, this should limit the range of annual compensation significantly <i>within each</i> – likely making the average compensation amount in each group a more nuanced and reasonable estimate.</p>
<p>What if we also learn the specific zip code in which the next passerby from Boise resides? The important information is likely captured in the larger city label (NYC vs. Boise), and the compensation for the specific zip codes within each city are unlikely to vary to a significant degree. Assuming this is true, it probably would not make sense to consider both the city name and zip code since they are effectively redundant pieces of information with regard to explaining differences in annual compensation.</p>
<p>What if we learn that the next person to walk by will be wearing a blue shirt? Does this influence your estimate? Unless there is research to suggest shirt color and earnings are related, this information will likely not contribute any significant information to our understanding of why people vary in the amount of compensation they earn annually and should, therefore, not be considered.</p>
<p>You can probably think of many relevant variables that would help further narrow the range of annual compensation. These may include job, level, years of experience, education, location, among other factors. The main thing to understand is that for each group of observations with the same characteristics – such as senior analysts with a graduate degree who reside in NYC – there is a distribution of annual compensation. This distribution reflects unexplained variance. That is, we do not have information to explain why the compensation for each and every person is not the same and in social science contexts, it simply is not practical to explain 100 percent of the variance in outcomes. Two people may be similar on hundreds of factors (experience, education, skills) but one was simply a more effective negotiator when offered the same role and commanded a higher salary. It’s likely we do not have data on salary negotiation ability so this information would leave us with unexplained variance in compensation. The goal is simply to identify the variables that provide the most information in helping us tighten the distribution so that estimating the average value will generally be an accurate estimate for those in the larger population with the same characteristics.</p>
<p>While we can generally improve our estimates with more relevant information (not shirt color or residential zip code in this case), it is important to understand that samples which are too small (n &lt; 30) lend to anomalies; modeling noise in sparse data can result in models that are unlikely to generalize beyond the sample data. For example, if the only people from Boise to attend the people analytics symposium happen to be two ultra wealthy tech entrepreneurs who earn millions each year, it would not be appropriate to use this as the basis for our estimates of all future attendees from Boise. This is a phenomenon known as overfitting that will be covered later in this chapter.</p>
<p>This is the essence of regression modeling: find a limited number of variables which independently or jointly provide significant information that helps explain (by reducing) variance around the average value. As illustrated in this example, adding additional variables (information) can impact the importance of other variables or may offer no incremental information at all. In the subsequent sections, we will cover how to identify which variables are important and how to quantify the effect they have on the outcome.</p>
</div>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">9.2</span> Simple Linear Regression</h2>
<div id="parameter-estimation" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Parameter Estimation</h3>
<p>Ordinary Least Squares (OLS) is the most common method for estimating unknown parameters in a linear regression model.</p>
</div>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2><span class="header-section-number">9.3</span> Multiple Linear Regression</h2>
<div id="moderation" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Moderation</h3>
</div>
<div id="mediation" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Mediation</h3>
</div>
</div>
<div id="polynomial-regression" class="section level2">
<h2><span class="header-section-number">9.4</span> Polynomial Regression</h2>
</div>
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">9.5</span> Logistic Regression</h2>
<p>Logistic regression is an excellent tool when the outcome is categorical. Logistic regression allows us to model the probability of different classes – a type of modeling often referred to as classification. The context for classification can be binomial for two classes (e.g., active/inactive, promoted/not promoted), multinomial for multiple unordered classes (e.g., skills, job families), or ordinal for multiple ordered classes (e.g., survey items measured on a Likert scale, performance level).</p>
<div id="binomial" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Binomial</h3>
</div>
<div id="multinomial" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Multinomial</h3>
</div>
<div id="ordinal" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Ordinal</h3>
<p>Proportional Odds Logistic Regression</p>
</div>
</div>
<div id="hierarchical-models" class="section level2">
<h2><span class="header-section-number">9.6</span> Hierarchical Models</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analysis-of-differences.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="predictive-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/r/07_inferential_models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
